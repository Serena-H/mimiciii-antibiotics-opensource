{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clinical variable retrieval codebase.\n",
    "each querey is referencing a sql querey linked in my github for ALL patients in the database, then generating a dataframe, then paring that dataframe down to only the patients/icustay_id in our cohort. \n",
    "* 5-16-19 heavily streamlined, can now change global variables at top of page which will correspond to all variables. added all code into functions and made a composite function to run each variable. \n",
    "* each variable is also deleted to reduce rolling memory usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overall workflow of this notebook:\n",
    "1) extract vitals first\n",
    "\n",
    "2) limit patients to those with appropriate vitals going forward. (final_pt_df_v)\n",
    "\n",
    "3) extract all other clinical variables \n",
    " * after extracting all patients first, filter to those patints in minimum vitals list\n",
    " * save and delete after extracting to reduce unnescessary memory load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_note_: the sql scripts are currently setup to drop a materialized view if exists and create a new materialized view with every run.\n",
    " one could setup this workflow so that these views are only created once by removing this part in each sql script, or simply querying the view name instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import psycopg2\n",
    "import collections\n",
    "import asyncio\n",
    "import getpass\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "import os,sys,re\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1024,\n",
    "        'height': 768,\n",
    "        'scroll': True,\n",
    "})\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 59.7 ms\n"
     ]
    }
   ],
   "source": [
    "# note, all server information is stored in a config.py file that is present in the .gitignore\n",
    "import config \n",
    "conn = psycopg2.connect(dbname=config.dbname, user=config.user, host=config.host, port=config.port,password=config.password)\n",
    "cur=conn.cursor()\n",
    "\n",
    "query_schema = 'SET search_path to ' + \"mimiciii\" + ';'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.13 s\n"
     ]
    }
   ],
   "source": [
    "from parameters import repository_path\n",
    "os.chdir(repository_path)\n",
    "wd= os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 112 ms\n"
     ]
    }
   ],
   "source": [
    "#patients of interest from rotation_cohort_generation\n",
    "from parameters import final_pt_df, date, repository_path\n",
    "\n",
    "#patients of interest from rotation_cohort_generation\n",
    "final_pt_df2 = final_pt_df\n",
    "del(final_pt_df)\n",
    "\n",
    "patients= list(final_pt_df2['subject_id'].unique())\n",
    "hadm_id= list(final_pt_df2['hadm_id'].unique())\n",
    "icustay_id= list(final_pt_df2['icustay_id'].unique())\n",
    "icustay_id= [int(x) for x in icustay_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 697 µs\n"
     ]
    }
   ],
   "source": [
    "# # run if already have a final_pt_df_v stored (which is ensuring pts have adequate vitals to be considered suspected of BI)\n",
    "# from parameters import final_pt_df_v\n",
    "# final_pt_df2= final_pt_df_v\n",
    "# icustay_id_vitals= list(final_pt_df_v['icustay_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C_neg/A_partial    7966\n",
       "C_neg/A_full       7504\n",
       "C_pos/A_full       2478\n",
       "C_pos/A_partial    1971\n",
       "Name: final_bin, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.83 ms\n"
     ]
    }
   ],
   "source": [
    "final_pt_df2['final_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access MIMIC database and convert it to dataframe in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 74.2 ms\n"
     ]
    }
   ],
   "source": [
    "#input the sql_exe_show object and get dataframe for only patients in patient list out. \n",
    "def sql_exe_show(sql_sentence):\n",
    "    cur.execute(sql_sentence)\n",
    "    rows = cur.fetchall()\n",
    "    col = []\n",
    "    for i in range(len(cur.description)):\n",
    "        col.append(cur.description[i][0])\n",
    "    table = pd.DataFrame(rows,columns=col)\n",
    "    return table\n",
    "\n",
    "def sql_to_df_icu(sql_exe_show_obj):\n",
    "    sql_exe_show_df= pd.DataFrame(data=sql_exe_show_obj)\n",
    "    sql_exe_show_df=sql_exe_show_df[sql_exe_show_df['icustay_id'].isin(icustay_id)]\n",
    "    return sql_exe_show_df\n",
    "\n",
    "def sql_to_df_patients(sql_exe_show_obj):\n",
    "    sql_exe_show_df= pd.DataFrame(data=sql_exe_show_obj)\n",
    "    sql_exe_show_df=sql_exe_show_df[sql_exe_show_df['subject_id'].isin(patients)]\n",
    "    return sql_exe_show_df\n",
    "\n",
    "def sql_to_df_hadm(sql_exe_show_obj):\n",
    "    sql_exe_show_df= pd.DataFrame(data=sql_exe_show_obj)\n",
    "    sql_exe_show_df=sql_exe_show_df[sql_exe_show_df['hadm_id'].isin(hadm_id)]\n",
    "    return sql_exe_show_df\n",
    "\n",
    "def clinvar_fxn(var_name, path, subject_id_override=False):\n",
    "    f= open(path, 'r')\n",
    "    var = f.read()\n",
    "    cur.execute('rollback')\n",
    "    cur.execute(var)\n",
    "    \n",
    "    if subject_id_override==True:\n",
    "        df= sql_to_df_patients(sql_exe_show('select * from %s;' %(var_name)))\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        try:\n",
    "            df= sql_to_df_icu(sql_exe_show('select * from %s;' %(var_name)))\n",
    "        except KeyError or NameError:\n",
    "            try:      \n",
    "                df= sql_to_df_hadm(sql_exe_show('select * from %s;' %(var_name)))\n",
    "            except KeyError or NameError:\n",
    "                df= sql_to_df_patients(sql_exe_show('select * from %s;' %(var_name)))\n",
    "\n",
    "    print(df.shape)\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting clinical data for our patients\n",
    "* clinical data window= (t0+x)- t0+y\n",
    " * lower_window: x, set this to offset the t_0 for lower bound of the clinical time window\n",
    " * upper_window: y, set this to set the upper bound of the clinical time window.\n",
    "* folder: folder name for data to be stored in\n",
    "* date: date attached in file name of all files associated with this data\n",
    "* time_col: the time column used to restrict data to the clinical data window.\n",
    "* patient_df: the cohort dataframe used, default: final_pt_df2\n",
    "* save_boolean: # do you want to save the files generated?\n",
    "    * if yes, save_boolean=True\n",
    "    * else save_boolean=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 948 µs\n"
     ]
    }
   ],
   "source": [
    "from parameters import lower_window, upper_window, folder, date, time_col, time_var, patient_df, save_boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# important functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.5 ms\n"
     ]
    }
   ],
   "source": [
    "def time_window_filter(df, final_pt_df2,timecol,upper_window, lower_window, time_var='t_0'):\n",
    "    \"\"\"\n",
    "    will take in any df and filter to only values between lower_window and upper_window. \n",
    "    values = the difference between timecol-timevar. \n",
    "        most commonly this is charttime- t_0 (or first in ICU ABrx meeting criteria)\n",
    "    will add delta and t_0 to df as well which are used lateron.git\n",
    "    \"\"\"\n",
    "    #global upper_window, lower_window \n",
    "    \n",
    "    try:\n",
    "        df= pd.merge(df, final_pt_df2[['icustay_id',time_var]], left_on= 'icustay_id', right_on = 'icustay_id') #n=240317\n",
    "        df['delta']= pd.to_datetime(df[timecol]) - pd.to_datetime(df[time_var])\n",
    "        df_after_t0= df.loc[df.loc[:,'delta']>= pd.Timedelta(days=lower_window),:]\n",
    "        df_after_t0= df_after_t0.loc[df_after_t0.loc[:,'delta']<= pd.Timedelta(days=upper_window),:]\n",
    "    except KeyError or NameError:\n",
    "        df= pd.merge(df, final_pt_df2[['hadm_id',time_var]], left_on= 'hadm_id', right_on = 'hadm_id') #n=240317\n",
    "        df['delta']= pd.to_datetime(df[timecol]) - pd.to_datetime(df[time_var])\n",
    "        df_after_t0= df.loc[df.loc[:,'delta']>= pd.Timedelta(days=lower_window),:]\n",
    "        df_after_t0= df_after_t0.loc[df_after_t0.loc[:,'delta']<= pd.Timedelta(days=upper_window),:]\n",
    "    return(df_after_t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# variable extraction below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vital Sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-- This query pivots the vital signs for the first 24 hours of a patient's stay\n",
    "##-- Vital signs include heart rate, blood pressure, respiration rate, and temperature\n",
    "\n",
    "vitals_all_nosummary_df= clinvar_fxn(\n",
    "    'vitals_all_nosummary',\n",
    "    str(repository_path)+'/src/SQL/vitals_all_nosummary.sql'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22340510, 7)\n",
      "time: 17min\n"
     ]
    }
   ],
   "source": [
    "##-- This query pivots the vital signs for the first 24 hours of a patient's stay\n",
    "##-- Vital signs include heart rate, blood pressure, respiration rate, and temperature\n",
    "\n",
    "vitals_all_nosummary_df= clinvar_fxn(\n",
    "    'vitals_all_nosummary',\n",
    "    str(repository_path)+'/src/SQL/vitals_all_nosummary.sql'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14min 14s\n"
     ]
    }
   ],
   "source": [
    "# trying to select the data from the materialized view\n",
    "# vitals_all_nosummary_sql = query_schema + \"\"\"\n",
    "# SELECT *\n",
    "# FROM public.vitals_all_nosummary\n",
    "# \"\"\"\n",
    "\n",
    "# #admissions\n",
    "# vitals_all_nosummary_df=pd.read_sql_query(vitals_all_nosummary_sql,conn)\n",
    "# vitals_all_nosummary_df= vitals_all_nosummary_df[vitals_all_nosummary_df['icustay_id'].isin(icustay_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>valueuom</th>\n",
       "      <th>vitalid</th>\n",
       "      <th>valuenum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>150750</td>\n",
       "      <td>220597</td>\n",
       "      <td>2149-11-11 00:00:00</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>MeanArtPress</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>150750</td>\n",
       "      <td>220597</td>\n",
       "      <td>2149-11-11 19:00:00</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>MeanArtPress</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>150750</td>\n",
       "      <td>220597</td>\n",
       "      <td>2149-11-11 19:45:00</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>MeanArtPress</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>150750</td>\n",
       "      <td>220597</td>\n",
       "      <td>2149-11-11 20:00:00</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>MeanArtPress</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21</td>\n",
       "      <td>111970</td>\n",
       "      <td>216859</td>\n",
       "      <td>2135-02-01 15:30:00</td>\n",
       "      <td>mmHg</td>\n",
       "      <td>MeanArtPress</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  hadm_id  icustay_id           charttime valueuom       vitalid  \\\n",
       "3           9   150750      220597 2149-11-11 00:00:00     mmHg  MeanArtPress   \n",
       "4           9   150750      220597 2149-11-11 19:00:00     mmHg  MeanArtPress   \n",
       "5           9   150750      220597 2149-11-11 19:45:00     mmHg  MeanArtPress   \n",
       "6           9   150750      220597 2149-11-11 20:00:00     mmHg  MeanArtPress   \n",
       "9          21   111970      216859 2135-02-01 15:30:00     mmHg  MeanArtPress   \n",
       "\n",
       "   valuenum  \n",
       "3      81.0  \n",
       "4      72.0  \n",
       "5      76.0  \n",
       "6      99.0  \n",
       "9      61.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 172 ms\n"
     ]
    }
   ],
   "source": [
    "vitals_all_nosummary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtering to patients with bare minimum vital numbers\n",
    "previously we found that 3% or so of patients don't have baseline vitals counts. this is filtering the patients to only those who have this baseline value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "#using origional criteria to find pts who have atleast 1 spo2 reading within 3 days of t_0\n",
    "\n",
    "#The idea is that this should be the bare minimum amount of data for a patient, and without it, it's likely the physicians did not suspect an infection in these patients. \n",
    "##NOTE: this should not change when the clinical timewindow of analysis interest changes. \n",
    "\n",
    "vitals_filter = time_window_filter(vitals_all_nosummary_df, final_pt_df2, time_col,time_var='t_0', lower_window=0,upper_window=3 )\n",
    "\n",
    "vitals_filter= vitals_filter.loc[\n",
    "    vitals_filter['vitalid'].notnull(),:]\n",
    "\n",
    "icustay_id_vitals = (vitals_filter.loc[\n",
    "    vitals_filter.loc[:,'vitalid']=='SpO2','icustay_id'\n",
    "        ].unique())\n",
    "\n",
    "subject_id_vitals=list(final_pt_df2.loc[final_pt_df2.loc[:,'icustay_id'].isin(icustay_id_vitals),'subject_id'])\n",
    "hadm_id_vitals= list(final_pt_df2.loc[final_pt_df2.loc[:,'icustay_id'].isin(icustay_id_vitals),'hadm_id'])\n",
    "icustay_id_vitals= list(final_pt_df2.loc[final_pt_df2.loc[:,'icustay_id'].isin(icustay_id_vitals),'icustay_id'])\n",
    "del(vitals_filter)\n",
    "\n",
    "##saving the patient database and reassigning patient set to the patient set with minimum vitals\n",
    "\n",
    "final_pt_df2_v=final_pt_df2.loc[final_pt_df2.loc[:,'icustay_id'].isin(icustay_id_vitals),:]\n",
    "if save_boolean==True:\n",
    "    #pd.DataFrame(final_pt_df2_v).to_csv(\"/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling/data/raw/csv/%s_final_pt_df2_v.csv\" %date) #final cohort database n=11493 subject_id’s (7/6/18)\n",
    "    pd.DataFrame(final_pt_df2_v).to_csv((str(repository_path)+ '/data/{}_final_pt_df_v.csv'.format(date)), index=False)\n",
    "    final_pt_df2=final_pt_df2_v.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C_neg/A_partial    7867\n",
       "C_neg/A_full       7401\n",
       "C_pos/A_full       2438\n",
       "C_pos/A_partial    1927\n",
       "Name: final_bin, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.5 ms\n"
     ]
    }
   ],
   "source": [
    "final_pt_df2=final_pt_df2_v\n",
    "final_pt_df2_v['final_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filtering, subset, and composite functions to be used for the rest of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.22 ms\n"
     ]
    }
   ],
   "source": [
    "def df_subset(df):\n",
    "    \"\"\"\n",
    "    redundancy check to ensure all df are filtered to cohort with minimum vitals \n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = df.loc[df.loc[:,'icustay_id'].isin(icustay_id_vitals),:]\n",
    "    except KeyError or NameError:\n",
    "        try:\n",
    "            df = df.loc[df.loc[:,'hadm_id'].isin(hadm_id_vitals),:]\n",
    "        except KeyError or NameError:\n",
    "            df = df.loc[df.loc[:,'subject_id'].isin(subject_id_vitals),:]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 103 ms\n"
     ]
    }
   ],
   "source": [
    "def filter_subset_save(df, savename=None, return_df=False, save=False, time_filter_override=False):\n",
    "    \n",
    "    \"\"\"\n",
    "    composite function, performs 1: time_window_filter() and 2:df_subset() to the input dataframe. this function links them together for simplifying code needed after each sql and formatting query. \n",
    "    return_df specifies if any output is spit out.\n",
    "    save specifies if the file will be saved with teh savename.\n",
    "    \n",
    "    fxn was created on 5/16/19 and validated against the normal pipeline.\n",
    "    \"\"\"\n",
    "    \n",
    "    global date,folder,final_pt_df2, lower_window, upper_window, time_var, timecol, time_var\n",
    "\n",
    "    if time_filter_override==False:\n",
    "        time_filtered= time_window_filter(df, final_pt_df2, timecol=time_col ,time_var=time_var, lower_window=lower_window, upper_window=upper_window)\n",
    "    else:\n",
    "        time_filtered=df\n",
    "        \n",
    "    time_and_subseted= df_subset(time_filtered)\n",
    "    \n",
    "    if save==True:\n",
    "        #os.chdir('/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling')\n",
    "        if folder != None:\n",
    "             address=str(repository_path)+'/data/raw/%s/'%(folder)\n",
    "        else:\n",
    "            address = str(repository_path)+'/data/raw/'\n",
    "        if not os.path.exists(address):\n",
    "            print(address)\n",
    "            os.makedirs(address)\n",
    "            \n",
    "        pd.DataFrame(time_and_subseted).to_csv(address+'/%s_%s.csv' %(date, savename))       \n",
    "    else: pass\n",
    "    \n",
    "    if return_df==False:\n",
    "        del(df, time_filtered, time_and_subseted)\n",
    "    \n",
    "    else:\n",
    "        return(time_and_subseted)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/raw/48_hr_window/\n",
      "time: 3min 44s\n"
     ]
    }
   ],
   "source": [
    "filter_subset_save(vitals_all_nosummary_df, savename=\"vitals_all_nosummary\", save=save_boolean, return_df=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 18.7 ms\n"
     ]
    }
   ],
   "source": [
    "del(vitals_all_nosummary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## elixhauser comobridities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26825, 33)\n",
      "time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "elixhauser_nosummary_df= clinvar_fxn(\n",
    "    'elixhauser_quan',\n",
    "    str(repository_path)+'/src/SQL/elixhauser_quan.sql', \n",
    "    subject_id_override=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now next task: redo same as above, BUT EXCLUDE CURRENT ROW FROM CUMMAX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31.6 ms\n"
     ]
    }
   ],
   "source": [
    "def elix(shift=False):\n",
    "    elix_var=list(elixhauser_nosummary_df)[3:]\n",
    "    elixhauser_nosummary_df2=elixhauser_nosummary_df.copy()\n",
    "\n",
    "    elixhauser_nosummary_df2[elix_var]=(elixhauser_nosummary_df\n",
    "                                            .sort_values('stay_num', ascending=True) #sorts values so stay_num is ascending\n",
    "                                            .groupby('subject_id', as_index=False)[elix_var] #groups by subject id and filters only elixhauser variable columns\n",
    "                                            .agg('cummax') #takes a cummulitive max for every row\n",
    "                                       )\n",
    "\n",
    "    if shift==True:\n",
    "        #now shifting the values up by 1 so the cumulitive max doesn't consider the current values: (note: couldn't get this to work in the fxn above)\n",
    "        elixhauser_nosummary_df2[elix_var]=(elixhauser_nosummary_df\n",
    "                                                .sort_values('stay_num', ascending=True) #sorts values so stay_num is ascending\n",
    "                                                .groupby('subject_id', as_index=False)[elix_var] #groups by subject id and filters only elixhauser variable columns\n",
    "                                                .shift(fill_value=np.nan)[:-1]) #shifts the cummulitive max up by 1 so the first row is na. \n",
    "\n",
    "    #restricting to hadm in use\n",
    "    elixhauser_nosummary_df3= elixhauser_nosummary_df2[elixhauser_nosummary_df2['hadm_id'].isin(hadm_id)]\n",
    "    \n",
    "    #adding icustay_id\n",
    "    elixhauser_nosummary_df3=pd.merge(elixhauser_nosummary_df3, final_pt_df2[['hadm_id','icustay_id']], how=\"left\", left_on='hadm_id',right_on='hadm_id')\n",
    "    \n",
    "    return(elixhauser_nosummary_df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "elixhauser_df=elix(shift=False)\n",
    "cancer_elix=elixhauser_df[['subject_id','hadm_id','icustay_id']].copy()\n",
    "cancer_elix['value']=elixhauser_df.loc[:,['lymphoma',\"solid_tumor\",\"metastatic_cancer\"]].max(axis=1)\n",
    "#adding columns\n",
    "cancer_elix['label']= 'cancer_elix'\n",
    "cancer_elix['delta']= 0\n",
    "cancer_elix['delta']= pd.to_timedelta(cancer_elix['delta'], unit='d')\n",
    "cancer_elix['uom']= 'pos/neg category'\n",
    "\n",
    "filter_subset_save(cancer_elix, savename=\"cancer_elix\", save=save_boolean, return_df=False,time_filter_override=True) #filtering to ppl with sufficient vitals\n",
    "del(elixhauser_df,cancer_elix)\n",
    "\n",
    "elixhauser_df=elix(shift=True)\n",
    "elix_var=list(elixhauser_df)[3:-1]\n",
    "sum_elix=elixhauser_df[['subject_id','hadm_id','icustay_id']].copy()\n",
    "sum_elix['value']=elixhauser_df.loc[:,elix_var].sum(axis=1)\n",
    "#adding columns\n",
    "sum_elix['label']= 'sum_elix'\n",
    "sum_elix['delta']= 0\n",
    "sum_elix['delta']= pd.to_timedelta(sum_elix['delta'], unit='d')\n",
    "sum_elix['uom']= 'elixhauser_comorb_sum'\n",
    "\n",
    "filter_subset_save(sum_elix, savename=\"sum_elix\", save=save_boolean, return_df=False,time_filter_override=True) #filtering to ppl with sufficient vitals\n",
    "del(elixhauser_df,sum_elix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 112 ms\n"
     ]
    }
   ],
   "source": [
    "def demographics():\n",
    "    \"\"\"\n",
    "    wrapping demographics code into a fxn. basically combines ethinicity, age, gender and race into one df. \n",
    "    \"\"\"\n",
    "    global final_pt_df2\n",
    "    pt_info_sql = query_schema + \"\"\"\n",
    "    SELECT SUBJECT_ID, INSURANCE, LANGUAGE, RELIGION, MARITAL_STATUS, ETHNICITY\n",
    "    from mimiciii.admissions\n",
    "    ORDER BY subject_id DESC\n",
    "    \"\"\"\n",
    "\n",
    "    pt_info_df=pd.read_sql_query(pt_info_sql,conn) #361711 patients with sterile culture -> 374643 with addn of bal and broncho... 7/16/18\n",
    "    \n",
    "    ethnicity_df=(pt_info_df.loc[\n",
    "    pt_info_df.loc[:,\"subject_id\"].isin(\n",
    "        final_pt_df2['subject_id'].tolist()),:]).drop_duplicates(['subject_id','ethnicity'])\n",
    "    ethnicity_df= ethnicity_df[['subject_id','ethnicity']].sort_values('ethnicity', ascending=False).groupby('subject_id', as_index=False).first()\n",
    "    \n",
    "    #gender and age\n",
    "    pt_info_sql = query_schema + \"\"\"\n",
    "    SELECT icu.icustay_id,\n",
    "        icu.subject_id,\n",
    "        (extract( epoch from icu.intime-pd.dob))/60/60/24/365.25 as age,\n",
    "        pd.gender\n",
    "    FROM  mimiciii.icustays icu\n",
    "    LEFT JOIN mimiciii.patients pd\n",
    "        ON pd.subject_id = icu.subject_id\n",
    "    \"\"\"\n",
    "    \n",
    "    #admissions\n",
    "    pt_info_df=pd.read_sql_query(pt_info_sql,conn) #361711 patients with sterile culture -> 374643 with addn of bal and broncho... 7/16/18\n",
    "    \n",
    "    #combining gender, race\n",
    "    pt_info_df=(pt_info_df.loc[\n",
    "        pt_info_df.loc[:,\"subject_id\"].isin(\n",
    "            final_pt_df2['subject_id'].tolist()),:]).drop_duplicates(['subject_id','gender'])\n",
    "    pt_info_df=(pt_info_df.loc[pt_info_df.loc[:,\"icustay_id\"].isin(icustay_id),:])\n",
    "    pt_info_df= pd.merge(pt_info_df, ethnicity_df, left_on='subject_id', right_on='subject_id', how='left' )\n",
    "\n",
    "    #combining age, gender and race. \n",
    "    pt_info_df=pd.merge(pt_info_df, final_pt_df2[['icustay_id','t_0']])\n",
    "\n",
    "    pt_info_df[pt_info_df['age']>89]['age']=90\n",
    "    \n",
    "    age_df=pd.melt(pt_info_df, id_vars=['icustay_id','subject_id','t_0'])\n",
    "    age_df=age_df.rename(index=str, columns={'variable':'label'})\n",
    "\n",
    "    age_df['delta']=pd.to_timedelta('0 days')\n",
    "    age_df['uom']=\"N/A\"\n",
    "    age_df.loc[age_df.loc[:,'label']=='first_admit_age','uom']='years'\n",
    "\n",
    "    age_df= age_df.loc[age_df.loc[:,\"icustay_id\"].isin(icustay_id),:]\n",
    "\n",
    "    ###using regular expressions to reduce the # of ethinicities\n",
    "    age_df.loc[(age_df.loc[:,\"label\"]=='ethnicity') & (age_df.loc[:,\"value\"].str.contains(r'.*?BLACK')),'value']=\"black\"\n",
    "    age_df.loc[(age_df.loc[:,\"label\"]=='ethnicity') & (age_df.loc[:,\"value\"].str.contains(r'.*?HISPANIC|PORTUGUESE')),'value']=\"hispanic\"\n",
    "    age_df.loc[(age_df.loc[:,\"label\"]=='ethnicity') & (age_df.loc[:,\"value\"].str.contains(r'.*?WHITE')),'value']=\"white/nonhispanic\"\n",
    "    age_df.loc[(age_df.loc[:,\"label\"]=='ethnicity') & (age_df.loc[:,\"value\"].str.contains(r'.*?ASIAN')),'value']='asian'\n",
    "    age_df.loc[(age_df.loc[:,\"label\"]=='ethnicity') & (age_df.loc[:,\"value\"].str.contains(r'(UNKNOWN|MULTI|UNABLE|DECLINE|OTHER)')),'value']='unknown/other'\n",
    "    age_df.loc[(age_df.loc[:,\"label\"]=='ethnicity') & (age_df.loc[:,\"value\"].str.contains(r'[AZ]+')),'value']=\"unknown/other\" #lumping all other low n values into other\n",
    "    return(age_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/ipykernel_launcher.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.75 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/ipykernel_launcher.py:60: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n"
     ]
    }
   ],
   "source": [
    "age_df= demographics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>t_0</th>\n",
       "      <th>label</th>\n",
       "      <th>value</th>\n",
       "      <th>delta</th>\n",
       "      <th>uom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>280836</td>\n",
       "      <td>268</td>\n",
       "      <td>2198-02-16</td>\n",
       "      <td>age</td>\n",
       "      <td>65.9849</td>\n",
       "      <td>0 days</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206613</td>\n",
       "      <td>269</td>\n",
       "      <td>2170-11-05</td>\n",
       "      <td>age</td>\n",
       "      <td>40.0998</td>\n",
       "      <td>0 days</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>219649</td>\n",
       "      <td>275</td>\n",
       "      <td>2170-10-08</td>\n",
       "      <td>age</td>\n",
       "      <td>82.1642</td>\n",
       "      <td>0 days</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204407</td>\n",
       "      <td>279</td>\n",
       "      <td>2164-06-15</td>\n",
       "      <td>age</td>\n",
       "      <td>74.294</td>\n",
       "      <td>0 days</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>257572</td>\n",
       "      <td>281</td>\n",
       "      <td>2101-10-18</td>\n",
       "      <td>age</td>\n",
       "      <td>60.0142</td>\n",
       "      <td>0 days</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   icustay_id  subject_id         t_0 label    value  delta  uom\n",
       "0      280836         268  2198-02-16   age  65.9849 0 days  N/A\n",
       "1      206613         269  2170-11-05   age  40.0998 0 days  N/A\n",
       "2      219649         275  2170-10-08   age  82.1642 0 days  N/A\n",
       "3      204407         279  2164-06-15   age   74.294 0 days  N/A\n",
       "4      257572         281  2101-10-18   age  60.0142 0 days  N/A"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.43 ms\n"
     ]
    }
   ],
   "source": [
    "age_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 717 ms\n"
     ]
    }
   ],
   "source": [
    "filter_subset_save(age_df, savename=\"pt_info\", save=save_boolean, return_df=False, time_filter_override=True)\n",
    "del(age_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15893, 18)\n",
      "time: 37.4 s\n"
     ]
    }
   ],
   "source": [
    "#prereq to weight and height\n",
    "echo_df= clinvar_fxn(\n",
    "    'echodata',\n",
    "    str(repository_path)+'/src/SQL/echodata.sql' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19919, 6)\n",
      "time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "# -- This query extracts weights for adult ICU patients on their first ICU day.\n",
    "# -- It does *not* use any information after the first ICU day, as weight is\n",
    "# -- sometimes used to monitor fluid balance.\n",
    "\n",
    "weightfirstday_df= clinvar_fxn(\n",
    "    'weightfirstday',\n",
    "    str(repository_path)+'/src/SQL/weightfirstday.sql' \n",
    ")\n",
    "weightfirstday_df['uom']='kg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "filter_subset_save(weightfirstday_df, savename=\"weightfirstday\", save=save_boolean, return_df=False, time_filter_override=True)\n",
    "del(weightfirstday_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19919, 4)\n",
      "time: 5.85 s\n"
     ]
    }
   ],
   "source": [
    "# -- This query extracts heights for adult ICU patients.\n",
    "# -- It uses all information from the patient's first ICU day.\n",
    "# -- This is done for consistency with other queries - it's not necessarily needed.\n",
    "# -- Height is unlikely to change throughout a patient's stay.\n",
    "heightfirstday_df= clinvar_fxn(\n",
    "    'heightfirstday',\n",
    "    str(repository_path)+'/src/SQL/heightfirstday.sql' \n",
    ")\n",
    "\n",
    "heightfirstday_df['uom']='cm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 110 ms\n"
     ]
    }
   ],
   "source": [
    "filter_subset_save(heightfirstday_df, savename=\"heightfirstday\", save=save_boolean, return_df=False, time_filter_override=True)\n",
    "del(heightfirstday_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.61 ms\n"
     ]
    }
   ],
   "source": [
    "del(echo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5673182, 6)\n",
      "time: 3min 39s\n"
     ]
    }
   ],
   "source": [
    "# -- This query pivots lab values for all patients, then filtered to those in my cohort.\n",
    "# -- Have confirmed that the unit of measurement is always the same: null or the correct unit\n",
    "\n",
    "labs_all_nosummary_df= clinvar_fxn(\n",
    "    'labs_all_nosummary',\n",
    "    str(repository_path)+'/src/SQL/labs_all_nosummary.sql'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 40.8 ms\n"
     ]
    }
   ],
   "source": [
    "#importing unit of mesurements:\n",
    "def uom_sql_import(file_path):\n",
    "    if isinstance(file_path, str)== True:\n",
    "        f = open(Path(file_path), 'r')\n",
    "    else:\n",
    "        f = open(Path(str(file_path)), 'r')\n",
    "\n",
    "    SQL = open(file_path,'r').read()\n",
    "    SQL_df= pd.read_sql_query(SQL,conn)   \n",
    "    return(SQL_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    334371.000000\n",
       "mean         11.596203\n",
       "std           8.901332\n",
       "min           0.090000\n",
       "25%           6.900000\n",
       "50%          10.100000\n",
       "75%          14.300000\n",
       "max         471.700000\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.5 s\n"
     ]
    }
   ],
   "source": [
    "lab_uom= uom_sql_import(Path(str(repository_path)+'/src/SQL/labs_uom.sql'))\n",
    "labs_all_nosummary_df = pd.merge(labs_all_nosummary_df, lab_uom, left_on='label', right_on='label')\n",
    "\n",
    "labs_all_nosummary_df[labs_all_nosummary_df['label']=='LYMPHO%']#.value_counts() #4-15-19: what is this, is this exploring absolute lymphocyte %?\n",
    "#labs_all_nosummary_df['label'].value_counts()\n",
    "\n",
    "labs_all_nosummary_df[labs_all_nosummary_df['label']=='WBC']['valuenum'].describe()\n",
    "#labs_all_nosummary_df[labs_all_nosummary_df['label']=='PLATELET']['valuenum'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.5 s\n"
     ]
    }
   ],
   "source": [
    "filter_subset_save(labs_all_nosummary_df, savename=\"labs_all_nosummary\", save=save_boolean, return_df=False, time_filter_override=False)\n",
    "del(labs_all_nosummary_df)\n",
    "del(lab_uom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glasgow Coma Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19919, 9)\n",
      "time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "#modified on 8/28/18 to have the days annotation.\n",
    "##--8/28/18: added in epoch as days, in order to help determine btwn t_0 and 72 hour for pts.\n",
    "gcsall_days_df= clinvar_fxn(\n",
    "    'gcsall_days', \n",
    "    str(repository_path)+'/src/SQL/gcsall_days.sql' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29.9 ms\n"
     ]
    }
   ],
   "source": [
    "#adding in icu_admit time and filtereing time_var to time window.\n",
    "def gcs_72(gcsall_days_df,final_pt_df2, time_var='t_0', lower_window=0, upper_window=3):\n",
    "    \"\"\"\n",
    "    written a while back, aims to adding in icu_admit time and filtereing time_var to time window.\n",
    "    will use this with time_filter_override=True in my filter_subset_save()\n",
    "    \"\"\"\n",
    "    \n",
    "    ##merging gcsall_days_df with final_pt df in order to append on icustay_id, the time var, and ICU_admit\n",
    "    gcsall_days_df_merge= pd.merge(\n",
    "    gcsall_days_df,\n",
    "    final_pt_df2[['icustay_id','icu_admit',time_var]],\n",
    "    left_on='icustay_id',\n",
    "    right_on='icustay_id')\n",
    "\n",
    "    gcsall_days_df_merge['day'] = gcsall_days_df_merge['day']-1 #putting the epoch days so that 0 = the first day\n",
    "    \n",
    "    #approximating the charttime of the time associated with each gcs score\n",
    "    gcsall_days_df_merge['approx_charttime']=pd.to_timedelta((gcsall_days_df_merge['day'])*24, unit='h') + pd.to_datetime(gcsall_days_df_merge['icu_admit'])\n",
    "    \n",
    "    # day # + ICU_admission day.\n",
    "    gcsall_days_df_merge['admit_plus_day']= (\n",
    "        pd.to_datetime(gcsall_days_df_merge['icu_admit'])\n",
    "        + pd.to_timedelta(gcsall_days_df_merge['day'], unit='D')\n",
    "    )\n",
    "    \n",
    "    #difference between the admission+epoch day - time_var.\n",
    "    gcsall_days_df_merge['delta']= (\n",
    "        pd.to_datetime(gcsall_days_df_merge['admit_plus_day']) - pd.to_datetime(gcsall_days_df_merge[time_var])\n",
    "    )\n",
    "    \n",
    "    #filtering day windows\n",
    "    gcsall_days_df_merge_72= (\n",
    "        gcsall_days_df_merge.loc[gcsall_days_df_merge.loc[:,'delta']>= pd.Timedelta(days=lower_window),:])\n",
    "    gcsall_days_df_merge_72= (\n",
    "        gcsall_days_df_merge_72.loc[gcsall_days_df_merge_72.loc[:,'delta']<= pd.Timedelta(days=upper_window),:])\n",
    "    return(gcsall_days_df_merge_72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 758 ms\n"
     ]
    }
   ],
   "source": [
    "gcs72_df = gcs_72(gcsall_days_df,final_pt_df2, time_var=time_var, lower_window=lower_window,upper_window=upper_window )\n",
    "gcs72_df['uom']='GCS_score' #adding in uom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 219 ms\n"
     ]
    }
   ],
   "source": [
    "filter_subset_save(gcs72_df, savename=\"gcs\", save=save_boolean, return_df=False, time_filter_override=True)\n",
    "del(gcs72_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renal replacement therapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the sql code for this was not equipped to join all of the charttimes together. so i decided to do it in python below.\n",
    "the rrt_all_df code above was only a 1 or 0 if patient had RRT during their entire icu stay. \n",
    "\n",
    "- step 1: run all sql codes\n",
    "- 2: filter on only the t_0 to t_72 hour rows\n",
    "- 3: filter on the 1223 patients who have a positive value\n",
    "- 4: get the earliest incidence of rrt for each 1223 patients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 205 ms\n"
     ]
    }
   ],
   "source": [
    "def rrt_runmerge():\n",
    "    \"\"\"\n",
    "    wrapping a lot of scripting into a function. grabs the 5 different rrt datas, filters them to timewindow, and merges them into 1 dataframe.\n",
    "    \"\"\"\n",
    "    global date,folder, patient_df,lower_window, upper_window, time_var, time_var, time_col\n",
    "    \n",
    "    ###5 sql queries to grab raw data\n",
    "    \n",
    "    #mv_ce\n",
    "    f = open(str(repository_path)+'/src/SQL/rtt_mv_ce.sql' , 'r')  \n",
    "    rrtSQL_mv_ce = f.read()\n",
    "    rrtSQL_mv_ce_sql = query_schema + rrtSQL_mv_ce.format(tuple(patients))\n",
    "    rrtSQL_mv_ce_df=pd.read_sql_query(rrtSQL_mv_ce_sql,conn)    \n",
    "    #cv\n",
    "    f = open(str(repository_path)+'/src/SQL/rtt_cv.sql' , 'r') \n",
    "    rrtSQL_cv = f.read()\n",
    "    rrtSQL_cv_sql = query_schema + rrtSQL_cv.format(tuple(patients))\n",
    "    rrtSQL_cv_df=pd.read_sql_query(rrtSQL_cv_sql,conn)          \n",
    "    #mv_ie\n",
    "    f = open(str(repository_path)+'/src/SQL/rtt_mv_ie.sql' , 'r') \n",
    "    rrtSQL_mv_ie = f.read()\n",
    "    rrtSQL_mv_ie_sql = query_schema + rrtSQL_mv_ie.format(tuple(patients))\n",
    "    rrtSQL_mv_ie_df=pd.read_sql_query(rrtSQL_mv_ie_sql,conn)      \n",
    "    rrtSQL_mv_ie_df['charttime']= rrtSQL_mv_ie_df['starttime']\n",
    "    rrtSQL_mv_ie_df=rrtSQL_mv_ie_df.drop('starttime', axis=1)\n",
    "    #mv_de\n",
    "    f = open(str(repository_path)+'/src/SQL/rtt_mv_de.sql' , 'r') \n",
    "    rrtSQL_mv_de = f.read()\n",
    "    rrtSQL_mv_de_sql = query_schema + rrtSQL_mv_de.format(tuple(patients))\n",
    "    rrtSQL_mv_de_df=pd.read_sql_query(rrtSQL_mv_de_sql,conn)      \n",
    "    #mv_pe\n",
    "    f = open(str(repository_path)+'/src/SQL/rtt_mv_pe.sql' , 'r') \n",
    "    rrtSQL_mv_pe = f.read()\n",
    "    rrtSQL_mv_pe_sql = query_schema + rrtSQL_mv_pe.format(tuple(patients))\n",
    "    rrtSQL_mv_pe_df=pd.read_sql_query(rrtSQL_mv_pe_sql,conn)          \n",
    "    rrtSQL_mv_pe_df['charttime']= rrtSQL_mv_pe_df['starttime']\n",
    "    rrtSQL_mv_pe_df=rrtSQL_mv_pe_df.drop('starttime', axis=1)\n",
    "    \n",
    "    ### timewindow filtering\n",
    "\n",
    "    def hour_72_window_rrt(df, final_pt_df2,timecol='charttime',time_var='t_0', lower_window=0, upper_window=3 ):\n",
    "        ##modified to make more generalizable to easily accomidate PA cohort but default to my origional cohort.\n",
    "        ##filters rrt to within timewindow  between timecol- time_var\n",
    "\n",
    "        df= pd.merge(final_pt_df2[['icustay_id',time_var]], df, left_on= 'icustay_id', right_on = 'icustay_id', how='left') #n=240317\n",
    "        df['delta']= pd.to_datetime(df[timecol]) - pd.to_datetime(df[time_var])\n",
    "        df_after_t0= df.loc[df.loc[:,'delta']>= pd.Timedelta(days=lower_window),:]\n",
    "        df_after_t0= df_after_t0.loc[df_after_t0.loc[:,'delta']<= pd.Timedelta(days=upper_window),:] \n",
    "        #df_after_t0= df_after_t0.loc[df_after_t0.loc[:,'rrt']==1,:].groupby('icustay_id')['charttime'].min()\n",
    "        return(pd.DataFrame(df_after_t0))#.reset_index())\n",
    "    \n",
    "    rrtSQL_mv_ce_pt =hour_72_window_rrt(rrtSQL_mv_ce_df, patient_df, timecol=time_col,time_var=time_var, lower_window=lower_window,upper_window=upper_window)\n",
    "    rrtSQL_cv_pt =hour_72_window_rrt(rrtSQL_cv_df, patient_df, timecol=time_col,time_var=time_var, lower_window=lower_window,upper_window=upper_window)\n",
    "    rrtSQL_mv_ie_pt =hour_72_window_rrt(rrtSQL_mv_ie_df, patient_df, timecol=time_col,time_var=time_var, lower_window=lower_window,upper_window=upper_window)\n",
    "    rrtSQL_mv_de_pt =hour_72_window_rrt(rrtSQL_mv_de_df, patient_df, timecol=time_col,time_var=time_var, lower_window=lower_window,upper_window=upper_window)\n",
    "    rrtSQL_mv_pe_pt =hour_72_window_rrt(rrtSQL_mv_pe_df, patient_df, timecol=time_col,time_var=time_var, lower_window=lower_window,upper_window=upper_window)\n",
    "    \n",
    "    ### merging all 5 filtered rrt_df together\n",
    "    \n",
    "    def rrt_merging(rrtSQL_mv_ce_pt, rrtSQL_cv_pt, rrtSQL_mv_ie_pt, rrtSQL_mv_de_pt, rrtSQL_mv_pe_pt, timecol='charttime',time_var='t_0'):\n",
    "        ###returns an aggregate y/n of if patient had positive rrt within timewindow. \n",
    "\n",
    "        rrt_merged_pt= pd.concat([rrtSQL_mv_ce_pt, rrtSQL_cv_pt, rrtSQL_mv_ie_pt, rrtSQL_mv_de_pt, rrtSQL_mv_pe_pt])\n",
    "\n",
    "        #making a 1 if has positive rrt within timewindow:\n",
    "        rrt_merged_pt= pd.DataFrame(rrt_merged_pt.loc[rrt_merged_pt.loc[:,'rrt']==1,:].groupby('icustay_id')[timecol].min().reset_index())\n",
    "        rrt_merged_pt['rrt']=1\n",
    "\n",
    "        rrt_merged_allpt_df= pd.merge(final_pt_df2[['icustay_id',time_var]], rrt_merged_pt, left_on= 'icustay_id', right_on = 'icustay_id', how='left') #n=240317\n",
    "        rrt_merged_allpt_df=rrt_merged_allpt_df.rename(index=str, columns={timecol:\"first_charttime\"})\n",
    "\n",
    "        rrt_merged_allpt_df['uom']='category' #adding a uom category\n",
    "        rrt_merged_allpt_df.loc[rrt_merged_allpt_df.loc[:,'rrt'].isnull(),'rrt']='0'\n",
    "\n",
    "        return(rrt_merged_allpt_df)\n",
    "\n",
    "\n",
    "    rrt_merged_allpt_df= rrt_merging(rrtSQL_mv_ce_pt, rrtSQL_cv_pt, rrtSQL_mv_ie_pt, rrtSQL_mv_de_pt, rrtSQL_mv_pe_pt, timecol=time_col,time_var=time_var)\n",
    "    return(rrt_merged_allpt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 29.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/ipykernel_launcher.py:63: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rrt_merged_allpt_df= rrt_runmerge()\n",
    "filter_subset_save(rrt_merged_allpt_df, savename=\"rrt_merged\", save=save_boolean, return_df=False, time_filter_override=True)\n",
    "del(rrt_merged_allpt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTI related variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1109441, 12)\n",
      "time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "uti_all_df= clinvar_fxn(\n",
    "    'uti_all',\n",
    "    str(repository_path)+'/src/SQL/gcsall_days.sql' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.61 s\n"
     ]
    }
   ],
   "source": [
    "filter_subset_save(uti_all_df, savename=\"uti_all\", save=save_boolean, return_df=False, time_filter_override=False)\n",
    "del(uti_all_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blood Gas Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 32.7 ms\n"
     ]
    }
   ],
   "source": [
    "def PaO2(bg_all_nosummary_df):\n",
    "    \"\"\"\n",
    "    overview: replaces the PO2 label with PaO2 on all instances (defined as sharing icustay_id and charttime being equal)\n",
    "        where the specimen label == 'ART'\n",
    "        \n",
    "    input: bloodgas dataframe with values annotated. \n",
    "    output: bloodgas dataframe with values annotated where PO2 label is replaced with PaO2 according to above criteria\n",
    "    \"\"\"\n",
    "    \n",
    "    #making a unique varaible to search for and mark all rows where time and icustay_id has an art flag\n",
    "    bg_all_nosummary_df['unique_var']= bg_all_nosummary_df['icustay_id'].map(str) +  bg_all_nosummary_df['charttime'].map(str)\n",
    "\n",
    "    #making subset dataframe for label == SPECIMEN \n",
    "    bg_all_nosummary_specimen= bg_all_nosummary_df.loc[bg_all_nosummary_df.loc[:,'label']=='SPECIMEN',:]\n",
    "    \n",
    "    #all ART related rows: unique_var for all rows where label== SPECIMEN\n",
    "    bg_all_nosummary_ART = bg_all_nosummary_specimen[bg_all_nosummary_specimen['value']=='ART'] \n",
    "    bg_all_nosummary_ART_list= list(bg_all_nosummary_ART['unique_var'].unique())\n",
    "\n",
    "    #two criteria needed to change the PO2 to PaO2 label.\n",
    "    criteria1=(bg_all_nosummary_df['label'] == 'PO2')\n",
    "    criteria2=(bg_all_nosummary_df['unique_var'].isin(bg_all_nosummary_ART_list))\n",
    "    \n",
    "    #making changes\n",
    "    bg_all_nosummary_df.loc[(criteria2 & criteria1),'label']= 'PaO2'\n",
    "    \n",
    "    return(bg_all_nosummary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2774898, 8)\n",
      "time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "bg_all_nosummary_df= clinvar_fxn(\n",
    "    'bg_all_nosummary',\n",
    "    str(repository_path)+'/src/SQL/bg_all_nosummary.sql' \n",
    "    ) \n",
    "bg_all_nosummary_df = PaO2(bg_all_nosummary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22 s\n"
     ]
    }
   ],
   "source": [
    "filter_subset_save(bg_all_nosummary_df, savename=\"bg_all_nosummary\", save=save_boolean, return_df=False, time_filter_override=False)\n",
    "del(bg_all_nosummary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vaso_active therapies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71511, 4)\n",
      "(5793, 7)\n",
      "(71889, 7)\n",
      "(15274, 7)\n",
      "(4757, 7)\n",
      "(15270, 7)\n",
      "(51967, 7)\n",
      "time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "# 10/12/18 added amountuom as amount_uom, rateuom as rate_uom to many lines of the sql code.\n",
    "\n",
    "weightdurations_df= clinvar_fxn(\n",
    "    'weightdurations',\n",
    "    str(repository_path)+'/src/SQL/weightdurations.sql'  ##added to vasoactive_meds due to dependency of SQL code\n",
    ")\n",
    "#\n",
    "epi_dose_df= clinvar_fxn(\n",
    "    'epinephrine_dose',\n",
    "    str(repository_path)+'/src/SQL/epinephrine_dose.sql' \n",
    ")\n",
    "#\n",
    "norepi_dose_df= clinvar_fxn(\n",
    "    'norepinephrine_dose',\n",
    "    str(repository_path)+'/src/SQL/norepinephrine_dose.sql' \n",
    ")\n",
    "#\n",
    "dopamine_dose_df= clinvar_fxn(\n",
    "    'dopamine_dose',\n",
    "    str(repository_path)+'/src/SQL/dopamine_dose.sql' \n",
    ")\n",
    "#\n",
    "dobutamine_dose_df= clinvar_fxn(\n",
    "    'dobutamine_dose',\n",
    "    str(repository_path)+'/src/SQL/dobutamine_dose.sql' \n",
    ")\n",
    "#\n",
    "vasopressin_dose_df= clinvar_fxn(\n",
    "    'vasopressin_dose',\n",
    "    str(repository_path)+'/src/SQL/vasopressin_dose.sql' \n",
    ")\n",
    "\n",
    "#removing units/hour, as these are not appropriate\n",
    "vasopressin_dose_df= vasopressin_dose_df.loc[~vasopressin_dose_df.loc[:,'rate_uom'].isin(['Uhr','units/hour']),:]\n",
    "#\n",
    "phenylephrine_dose_df= clinvar_fxn(\n",
    "    'phenylephrine_dose',\n",
    "    str(repository_path)+'/src/SQL/phenylephrine_dose.sql' \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 448 ms\n"
     ]
    }
   ],
   "source": [
    "#adding an identification label column and merging them into 1 df. \n",
    "epi_dose_df['label']='epinephrine'\n",
    "norepi_dose_df['label']='norepinephrine'\n",
    "dopamine_dose_df['label']='dopamine'\n",
    "dobutamine_dose_df['label']='dobutamine'\n",
    "vasopressin_dose_df['label']='vasopressin'\n",
    "phenylephrine_dose_df['label']='phenylephrine'\n",
    "vaso_dose_df = pd.concat([epi_dose_df, norepi_dose_df, dopamine_dose_df, dobutamine_dose_df, vasopressin_dose_df,phenylephrine_dose_df ])\n",
    "\n",
    "#rename starttime to charttime\n",
    "vaso_dose_df.rename(index=str, columns={'starttime':\"charttime\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.54 s\n"
     ]
    }
   ],
   "source": [
    "filter_subset_save(vaso_dose_df, savename=\"vaso_dose\", save=save_boolean, return_df=False, time_filter_override=False)\n",
    "del(vaso_dose_df)\n",
    "del(epi_dose_df, norepi_dose_df, dopamine_dose_df, dobutamine_dose_df, vasopressin_dose_df,phenylephrine_dose_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ventilator settings and categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1078506, 6)\n",
      "time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "#ventsettings_df = pd.read_csv('/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling/src/csv/15082018_ventsettings_df.csv', index_col=0)\n",
    "ventsettings_df= clinvar_fxn(\n",
    "    'ventsettings',\n",
    "    str(repository_path)+'/src/SQL/ventsettings.sql' \n",
    ")\n",
    "#going from wide format to long:\n",
    "#pd.melt(ventsettings_df, id_vars=['icustay_id','charttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 53.9 ms\n"
     ]
    }
   ],
   "source": [
    "def vent_data(vent_df,time_var='t_0', lower_window=0, upper_window=3 ):\n",
    "    df= pd.merge(vent_df,\n",
    "                final_pt_df2[['icustay_id',time_var]],\n",
    "                left_on='icustay_id',\n",
    "                right_on= 'icustay_id',\n",
    "                how='left')\n",
    "    df['delta']= pd.to_datetime(df['charttime']) - pd.to_datetime(df[time_var])\n",
    "    df_timewindow= df.loc[df.loc[:,'delta']>= pd.Timedelta(days=lower_window),:]\n",
    "    df_timewindow= df_timewindow.loc[df_timewindow.loc[:,'delta']<= pd.Timedelta(days=upper_window),:] \n",
    "    df_timewindow['day']= df_timewindow['delta'].apply(lambda x: pd.to_timedelta(x,unit='d').days) #day #\n",
    "      \n",
    "    return(df_timewindow)\n",
    "\n",
    "#df_timewindow =vent_data(ventsettings_df,time_var='first_pos_else_neg_ssc', lower_window=-1, upper_window=1 )\n",
    "\n",
    "def vent_day_categorizer(vent_df,time_var='t_0', lower_window=0, upper_window=3 ):\n",
    "    \n",
    "    df_timewindow =vent_data(vent_df,time_var=time_var, lower_window=lower_window, upper_window=upper_window)\n",
    "    \n",
    "    df_timewindow_perday=df_timewindow.groupby(['icustay_id','day'], as_index=False)[['mechvent','oxygentherapy']].agg({'mechvent':'max', 'oxygentherapy':'max'})\n",
    "\n",
    "    conditions= [\n",
    "        (df_timewindow_perday['mechvent']==1),\n",
    "        ((df_timewindow_perday['oxygentherapy']==1) & (df_timewindow_perday['mechvent']==0)),\n",
    "        (df_timewindow_perday['oxygentherapy']==0 & (df_timewindow_perday['mechvent']==0))]\n",
    "\n",
    "    choices=['Mech', 'Oxygen', 'None']\n",
    "    #\n",
    "    df_timewindow_perday['value']= np.select(conditions, choices, default='error:no_value_filled')\n",
    "    df_timewindow_perday['value']\n",
    "    df_timewindow_perday=df_timewindow_perday.reset_index()\n",
    "    df_timewindow_perday['uom']= 'mech/O2/none category'\n",
    "    df_timewindow_perday= df_timewindow_perday.drop(['mechvent','oxygentherapy','index'], axis=1)\n",
    "    df_timewindow_perday=pd.merge(df_timewindow_perday, final_pt_df2[['icustay_id',time_var]] )\n",
    "    return(df_timewindow_perday)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.14 s\n"
     ]
    }
   ],
   "source": [
    "#ventcategory_df = vent_categorization(final_pt_df2, ventsettings_df, time_var='first_pos_else_neg_ssc' )\n",
    "ventcategory_df= vent_day_categorizer(ventsettings_df,time_var=time_var, lower_window=lower_window, upper_window=upper_window)\n",
    "#ventcount_df = vent_count(final_pt_df2,ventsettings_df, time_var='first_pos_else_neg_ssc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 251 ms\n"
     ]
    }
   ],
   "source": [
    "filter_subset_save(ventcategory_df, savename=\"ventcategory\", save=save_boolean, return_df=False, time_filter_override=True)\n",
    "#del(ventcategory_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>day</th>\n",
       "      <th>value</th>\n",
       "      <th>uom</th>\n",
       "      <th>t_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200001.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Oxygen</td>\n",
       "      <td>mech/O2/none category</td>\n",
       "      <td>2181-11-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200001.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Oxygen</td>\n",
       "      <td>mech/O2/none category</td>\n",
       "      <td>2181-11-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200003.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mech</td>\n",
       "      <td>mech/O2/none category</td>\n",
       "      <td>2199-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200003.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mech</td>\n",
       "      <td>mech/O2/none category</td>\n",
       "      <td>2199-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200012.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Oxygen</td>\n",
       "      <td>mech/O2/none category</td>\n",
       "      <td>2153-12-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   icustay_id  day   value                    uom         t_0\n",
       "0    200001.0    0  Oxygen  mech/O2/none category  2181-11-26\n",
       "1    200001.0    1  Oxygen  mech/O2/none category  2181-11-26\n",
       "2    200003.0    0    Mech  mech/O2/none category  2199-08-04\n",
       "3    200003.0    1    Mech  mech/O2/none category  2199-08-04\n",
       "4    200012.0    0  Oxygen  mech/O2/none category  2153-12-23"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 27.2 ms\n"
     ]
    }
   ],
   "source": [
    "ventcategory_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# daily SOFA score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running yiheng's sql codes to capture daily sofa_score. ideally i coulda just used my data above but she had this written already so i'll use this.\n",
    "\n",
    "link to her github: https://github.com/yihengpan/fluid_management/tree/master/sofa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how we generate the sofa table:\n",
    "\n",
    "\n",
    "sofa <- scorecalc <- scorecomp <- vaso_cv    <-icu_18\n",
    "                                             \n",
    "                                             <-wt      <-icu_18\n",
    "                                             <-echo2\n",
    "                                          \n",
    "                               <- vaso_mv    <-icu_18\n",
    "                               <- pafi2      <-bloodgas_pan_aterial <- bloodgas_pan  <-icu_18\n",
    "                                             <-ventelurations\n",
    "                               <- vitals_pan <-icu_18\n",
    "                               <- labs_pan   <-icu_18\n",
    "                               <- uo_pan     <-icu_18\n",
    "                               <- gcs_pan    <-icu_18\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33300, 3)\n",
      "(19919, 2)\n",
      "(294454, 33)\n",
      "(241035, 39)\n",
      "time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "sofa_path= str(repository_path)+'/src/SQL/sofa'\n",
    "var='wt'\n",
    "wt_df= clinvar_fxn(\n",
    "    var,\n",
    "    Path(sofa_path+'/%s.sql' %(var))\n",
    ")\n",
    "\n",
    "var='echo2'\n",
    "echo2_df= clinvar_fxn(\n",
    "    var,\n",
    "    Path(sofa_path+'/%s.sql' %(var))\n",
    ")\n",
    "\n",
    "var='bloodgas_pan'\n",
    "bloodgas_pan_df= clinvar_fxn(\n",
    "    var,\n",
    "    Path(sofa_path+'/%s.sql' %(var))\n",
    ")\n",
    "\n",
    "var='bloodgas_pan_arterial'\n",
    "bloodgas_pan_art_df= clinvar_fxn(\n",
    "    var,\n",
    "    Path(sofa_path+'/%s.sql' %(var))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8209, 6)\n",
      "(8209, 6)\n",
      "(11257, 6)\n",
      "(241035, 5)\n",
      "(76566, 4)\n",
      "(116400, 42)\n",
      "(111927, 5)\n",
      "(19692, 9)\n",
      "(133916, 14)\n",
      "(133916, 20)\n",
      "(125866, 23)\n",
      "time: 8min 19s\n"
     ]
    }
   ],
   "source": [
    "#vaso_mv, vaso_cv,pafi2, vitals_pan, labs_pan, uo_pan, gcs_pan\n",
    "sofa_path= str(repository_path)+'/src/SQL/sofa'\n",
    "var='vaso_mv'\n",
    "vaso_mv_df= clinvar_fxn(\n",
    "    var,\n",
    "    Path(sofa_path+'/%s.sql' %(var))\n",
    ")\n",
    "\n",
    "var='vaso_mv'\n",
    "vaso_mv_df= clinvar_fxn(\n",
    "    var,\n",
    "    Path(sofa_path+'/%s.sql' %(var))\n",
    ")\n",
    "\n",
    "var='vaso_cv'\n",
    "vaso_cv_df= clinvar_fxn(\n",
    "    var,\n",
    "    Path(sofa_path+'/%s.sql' %(var))\n",
    ")\n",
    "\n",
    "var='pafi1'\n",
    "pafi1_df= clinvar_fxn(\n",
    "    var,\n",
    "    Path(sofa_path+'/%s.sql' %(var))\n",
    ")\n",
    "\n",
    "var='pafi2'\n",
    "pafi2_df= clinvar_fxn(\n",
    "    var,\n",
    "    Path(sofa_path+'/%s.sql' %(var))\n",
    ")\n",
    "\n",
    "\n",
    "var='labs_pan'\n",
    "labs_pan_df= clinvar_fxn(\n",
    "    var,\n",
    "    Path(sofa_path+'/%s.sql' %(var))\n",
    ")\n",
    "\n",
    "var='uo_pan'\n",
    "uo_pan_df= clinvar_fxn(\n",
    "    var,\n",
    "    Path(sofa_path+'/%s.sql' %(var))\n",
    ")\n",
    "\n",
    "var='gcs_pan'\n",
    "gcs_pan_df= clinvar_fxn(\n",
    "    var,\n",
    "    Path(sofa_path+'/%s.sql' %(var))\n",
    ")\n",
    "\n",
    "###\n",
    "\n",
    "var='scorecomp'\n",
    "scorecomp_df= clinvar_fxn(\n",
    "    var,\n",
    "    Path(sofa_path+'/%s.sql' %(var))\n",
    ")\n",
    "\n",
    "var='scorecalc'\n",
    "scorecalc_df= clinvar_fxn(\n",
    "    var,\n",
    "    Path(sofa_path+'/%s.sql' %(var))\n",
    ")\n",
    "\n",
    "var='sofa_pan'\n",
    "sofa_pan_df= clinvar_fxn(\n",
    "    var,\n",
    "    Path(sofa_path+'/%s.sql' %(var))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>ssc_charttime</th>\n",
       "      <th>ssc_id</th>\n",
       "      <th>icu_admit</th>\n",
       "      <th>ab_id</th>\n",
       "      <th>ab_start</th>\n",
       "      <th>ab_end</th>\n",
       "      <th>ab_ssc_delta</th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_end</th>\n",
       "      <th>...</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>dod_hosp</th>\n",
       "      <th>dod_ssn</th>\n",
       "      <th>ab_course</th>\n",
       "      <th>org_list</th>\n",
       "      <th>spec_type_list</th>\n",
       "      <th>first_pos_else_neg_ssc</th>\n",
       "      <th>sc_result</th>\n",
       "      <th>final_bin</th>\n",
       "      <th>hadm_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>294638</td>\n",
       "      <td>2191-03-16 00:00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>2191-03-16 00:29:31</td>\n",
       "      <td>1213116</td>\n",
       "      <td>2191-03-16</td>\n",
       "      <td>2191-03-22</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>2191-03-16</td>\n",
       "      <td>2191-03-22</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>full</td>\n",
       "      <td>STAPH AUREUS COAG +</td>\n",
       "      <td>BLOOD CULTURE</td>\n",
       "      <td>2191-03-16 00:00:00</td>\n",
       "      <td>positive</td>\n",
       "      <td>C_pos/A_full</td>\n",
       "      <td>185777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220597</td>\n",
       "      <td>2149-11-10 09:40:00</td>\n",
       "      <td>45</td>\n",
       "      <td>2149-11-09 13:07:02</td>\n",
       "      <td>2089126</td>\n",
       "      <td>2149-11-10</td>\n",
       "      <td>2149-11-15</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>2149-11-10</td>\n",
       "      <td>2149-11-15</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2149-11-14</td>\n",
       "      <td>2149-11-14</td>\n",
       "      <td>full</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2149-11-10 09:40:00</td>\n",
       "      <td>negative</td>\n",
       "      <td>C_neg/A_full</td>\n",
       "      <td>150750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232669</td>\n",
       "      <td>2104-08-11 00:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>2104-08-08 02:08:17</td>\n",
       "      <td>616189</td>\n",
       "      <td>2104-08-11</td>\n",
       "      <td>2104-08-12</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>2104-08-11</td>\n",
       "      <td>2104-08-12</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>2104-08-20</td>\n",
       "      <td>2104-08-20</td>\n",
       "      <td>partial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2104-08-11 00:00:00</td>\n",
       "      <td>negative</td>\n",
       "      <td>C_neg/A_partial</td>\n",
       "      <td>112213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>273430</td>\n",
       "      <td>2108-08-05 20:42:00</td>\n",
       "      <td>69</td>\n",
       "      <td>2108-08-05 16:26:09</td>\n",
       "      <td>2572274</td>\n",
       "      <td>2108-08-06</td>\n",
       "      <td>2108-08-08</td>\n",
       "      <td>1 days 00:00:00.000000000</td>\n",
       "      <td>2108-08-06</td>\n",
       "      <td>2108-08-08</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2109-08-18</td>\n",
       "      <td>partial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2108-08-05 20:42:00</td>\n",
       "      <td>negative</td>\n",
       "      <td>C_neg/A_partial</td>\n",
       "      <td>109235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>217847</td>\n",
       "      <td>2134-09-11 09:35:00</td>\n",
       "      <td>70</td>\n",
       "      <td>2134-09-11 20:50:04</td>\n",
       "      <td>1388217</td>\n",
       "      <td>2134-09-12</td>\n",
       "      <td>2134-09-13</td>\n",
       "      <td>1 days 00:00:00.000000000</td>\n",
       "      <td>2134-09-12</td>\n",
       "      <td>2134-09-13</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>2135-02-08</td>\n",
       "      <td>2135-02-08</td>\n",
       "      <td>full</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2134-09-11 09:35:00</td>\n",
       "      <td>negative</td>\n",
       "      <td>C_neg/A_full</td>\n",
       "      <td>109451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   icustay_id        ssc_charttime  ssc_id            icu_admit    ab_id  \\\n",
       "0      294638  2191-03-16 00:00:00      22  2191-03-16 00:29:31  1213116   \n",
       "1      220597  2149-11-10 09:40:00      45  2149-11-09 13:07:02  2089126   \n",
       "2      232669  2104-08-11 00:00:00      60  2104-08-08 02:08:17   616189   \n",
       "3      273430  2108-08-05 20:42:00      69  2108-08-05 16:26:09  2572274   \n",
       "4      217847  2134-09-11 09:35:00      70  2134-09-11 20:50:04  1388217   \n",
       "\n",
       "     ab_start      ab_end               ab_ssc_delta         t_0       t_end  \\\n",
       "0  2191-03-16  2191-03-22  0 days 00:00:00.000000000  2191-03-16  2191-03-22   \n",
       "1  2149-11-10  2149-11-15  0 days 00:00:00.000000000  2149-11-10  2149-11-15   \n",
       "2  2104-08-11  2104-08-12  0 days 00:00:00.000000000  2104-08-11  2104-08-12   \n",
       "3  2108-08-06  2108-08-08  1 days 00:00:00.000000000  2108-08-06  2108-08-08   \n",
       "4  2134-09-12  2134-09-13  1 days 00:00:00.000000000  2134-09-12  2134-09-13   \n",
       "\n",
       "   ... subject_id    dod_hosp     dod_ssn  ab_course             org_list  \\\n",
       "0  ...          4         NaN         NaN       full  STAPH AUREUS COAG +   \n",
       "1  ...          9  2149-11-14  2149-11-14       full                  NaN   \n",
       "2  ...         12  2104-08-20  2104-08-20    partial                  NaN   \n",
       "3  ...         19         NaN  2109-08-18    partial                  NaN   \n",
       "4  ...         21  2135-02-08  2135-02-08       full                  NaN   \n",
       "\n",
       "  spec_type_list first_pos_else_neg_ssc sc_result        final_bin hadm_id  \n",
       "0  BLOOD CULTURE    2191-03-16 00:00:00  positive     C_pos/A_full  185777  \n",
       "1            NaN    2149-11-10 09:40:00  negative     C_neg/A_full  150750  \n",
       "2            NaN    2104-08-11 00:00:00  negative  C_neg/A_partial  112213  \n",
       "3            NaN    2108-08-05 20:42:00  negative  C_neg/A_partial  109235  \n",
       "4            NaN    2134-09-11 09:35:00  negative     C_neg/A_full  109451  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 37.5 ms\n"
     ]
    }
   ],
   "source": [
    "final_pt_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>day</th>\n",
       "      <th>sofa</th>\n",
       "      <th>respiration</th>\n",
       "      <th>pao2fio2_vent_min</th>\n",
       "      <th>pao2fio2_novent_min</th>\n",
       "      <th>coagulation</th>\n",
       "      <th>platelet_min</th>\n",
       "      <th>...</th>\n",
       "      <th>rate_dopamine</th>\n",
       "      <th>rate_epinephrine</th>\n",
       "      <th>rate_norepinephrine</th>\n",
       "      <th>rate_dobutamine</th>\n",
       "      <th>meanbp_min</th>\n",
       "      <th>cns</th>\n",
       "      <th>mingcs</th>\n",
       "      <th>renal</th>\n",
       "      <th>creatinine_max</th>\n",
       "      <th>urineoutput</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>185777</td>\n",
       "      <td>294638</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>185777</td>\n",
       "      <td>294638</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9</td>\n",
       "      <td>150750</td>\n",
       "      <td>220597</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>887.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>150750</td>\n",
       "      <td>220597</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2628.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>9</td>\n",
       "      <td>150750</td>\n",
       "      <td>220597</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2330.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject_id  hadm_id  icustay_id  day  sofa  respiration  \\\n",
       "6            4   185777      294638  1.0     2          NaN   \n",
       "7            4   185777      294638  2.0     0          NaN   \n",
       "12           9   150750      220597  1.0     5          3.0   \n",
       "13           9   150750      220597  2.0     5          3.0   \n",
       "14           9   150750      220597  3.0     5          3.0   \n",
       "\n",
       "    pao2fio2_vent_min  pao2fio2_novent_min  coagulation  platelet_min  ...  \\\n",
       "6                 NaN                  NaN          0.0         201.0  ...   \n",
       "7                 NaN                  NaN          0.0         258.0  ...   \n",
       "12              125.0                  NaN          0.0         249.0  ...   \n",
       "13              150.0                  NaN          0.0         221.0  ...   \n",
       "14              170.0                  NaN          0.0         261.0  ...   \n",
       "\n",
       "    rate_dopamine  rate_epinephrine  rate_norepinephrine  rate_dobutamine  \\\n",
       "6             NaN               NaN                  NaN              NaN   \n",
       "7             NaN               NaN                  NaN              NaN   \n",
       "12            NaN               NaN                  NaN              NaN   \n",
       "13            NaN               NaN                  NaN              NaN   \n",
       "14            NaN               NaN                  NaN              NaN   \n",
       "\n",
       "    meanbp_min  cns  mingcs  renal  creatinine_max  urineoutput  \n",
       "6         69.0  0.0    15.0    0.0             0.5       2150.0  \n",
       "7         93.0  NaN     NaN    0.0             0.4        900.0  \n",
       "12        67.0  NaN     NaN    1.0             1.4        887.0  \n",
       "13        73.0  0.0    15.0    2.0             2.0       2628.0  \n",
       "14        72.0  NaN     NaN    2.0             2.0       2330.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 22.1 ms\n"
     ]
    }
   ],
   "source": [
    "sofa_pan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 42.2 ms\n"
     ]
    }
   ],
   "source": [
    "#deleting these to clear up memory \n",
    "\n",
    "del(vaso_cv_df, vaso_mv_df, labs_pan_df, gcs_pan_df, scorecalc_df, scorecomp_df, uo_pan_df, pafi1_df, pafi2_df, bloodgas_pan_art_df, echo2_df, wt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18998 18773\n",
      "time: 4.18 ms\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "sofa_pan_df['hadm_id'].nunique(), #8707\n",
    "final_pt_df2['hadm_id'].nunique() #8731\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19884 19626\n",
      "time: 3.12 ms\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "sofa_pan_df['icustay_id'].nunique(), #8707\n",
    "final_pt_df2['icustay_id'].nunique() #8731\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18773"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.26 ms\n"
     ]
    }
   ],
   "source": [
    "sofa_pan_df['hadm_id'].nunique() #8707\n",
    "final_pt_df2['hadm_id'].nunique() #8731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 39.4 ms\n"
     ]
    }
   ],
   "source": [
    "#adding in t_0 & icuadmit date\n",
    "def sofa_day_window_filter(sofa_pan_df, time_var= 't_0', lower_window= 0, upper_window=3): #'t_0'):\n",
    "    import datetime\n",
    "    '''\n",
    "    #Yihangpan wrote a sql script and materialized view \"sofa_pan\" which gives the sofa score for each day in icu for each patient. \n",
    "    #since the sofa_pan has days after admission but not chartdates, I need to use day # to find the associated t_0 to t_0+72 for each patient. \n",
    "    # the challenge was that I had to relate day# in sofa_pan to my t_0 date. the day # was based on the days after icu admission, where day1 = the first day (day=0)= 0 to 24 hours post admission.\n",
    "    #To do this, I added day# (where day 0 is the first day) to icu admission date. \n",
    "    #I then filtered on only the rows where this icuadmin + day# was between t_0 and t_0 + 72 hours. \n",
    "\n",
    "    #since t_0 has only day resolution, and for that I ignored hours and only took the date (rounded down all hours/minutes/seconds). this is similar to how i made the t_0 date. \n",
    "    #the problem this creates is that it widens the potential time window, so it theoretically can contain up to 95.99 hours, since hours on day 1 were collapsed to 0. \n",
    "\n",
    "    \n",
    "    input: \n",
    "        sofa_pan_df: daily sofa scores captured from sofa_pan_sql.\n",
    "        optional:\n",
    "            time_var: the time variable we want to base the window off of\n",
    "            window_bottom= 0, time_var- window_bottom (days + time_var) = first daily sofa score to capture\n",
    "            window_top= 0, time_var- window_top (days + time_var) = last daily sofa score to capture \n",
    "    \n",
    "    output: sofa_pan_sql annotated with days and filtered to time window set by window_bottom and window_top. \n",
    "    '''\n",
    "    #reducing to minimum vital patients\n",
    "    sofa_pan_df=sofa_pan_df.loc[sofa_pan_df.loc[:,\"icustay_id\"].isin(icustay_id_vitals),:].copy()\n",
    "\n",
    "    ##merging sofa_pan with final_pt df in order to append on icustay_id, the time var, and ICU_admit\n",
    "    \n",
    "    sofa_df_merged= pd.merge(sofa_pan_df,\n",
    "                             final_pt_df2[['icustay_id',time_var,'icu_admit']],\n",
    "                             left_on= 'icustay_id',\n",
    "                             right_on = 'icustay_id',\n",
    "                             how='left') #n=240317\n",
    "\n",
    "    #sofa_df_merged['admit_t0_rounded'] = pd.to_datetime(sofa_df_merged['ICU_admit']).dt.round('1440min')\n",
    "    \n",
    "    sofa_df_merged['day'] = sofa_df_merged['day']-1 #putting the epoch days so that 0 = the first day\n",
    "    \n",
    "    #approximating the charttime of the time associated with each sofa score. adding on days to icuadmit. \n",
    "    sofa_df_merged['approx_charttime']=pd.to_timedelta((sofa_df_merged['day'])*24, unit='h') + pd.to_datetime(sofa_df_merged['icu_admit'])\n",
    "\n",
    "    #rounding down the charttime to the day, so hours and minutes are ignored (just like t_0)\n",
    "    sofa_df_merged['floor_charttime'] = sofa_df_merged['approx_charttime'].apply(lambda dt: datetime.datetime(dt.year, dt.month, dt.day, 24*(dt.hour//24))) \n",
    "    \n",
    "    sofa_df_merged['floor_time_var'] = pd.to_datetime(sofa_df_merged[time_var]).apply(lambda dt: datetime.datetime(dt.year, dt.month, dt.day, 24*(dt.hour//24))) \n",
    "    \n",
    "    sofa_df_window= sofa_df_merged.loc[\n",
    "        (sofa_df_merged['floor_charttime'].between(\n",
    "            (pd.to_datetime(sofa_df_merged['floor_time_var'])+ pd.to_timedelta(lower_window, unit='d')),\n",
    "            (pd.to_datetime(sofa_df_merged['floor_time_var'])+ pd.to_timedelta(upper_window, unit='d')+ pd.to_timedelta(1, unit='h')) #added 1hr timebuffer incase between is set as less than greater than\n",
    "        )),:]\n",
    "    \n",
    "    return(sofa_df_window)\n",
    "    #return(sofa_df_window.drop(['floor_time_var','floor_charttime'], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43631\n",
      "time: 2.37 s\n"
     ]
    }
   ],
   "source": [
    "sofa_df_window= sofa_day_window_filter(sofa_pan_df, time_var= time_var, lower_window= lower_window, upper_window=upper_window)\n",
    "sofa_df_window.sort_values(['icustay_id','day','sofa','rate_dopamine','rate_epinephrine','rate_norepinephrine','rate_dobutamine'],\n",
    "                          ascending=[True, True, False, False, False, False, False], inplace=True\n",
    "                          )\n",
    "sofa_df_window.drop_duplicates(['icustay_id','day','sofa'], inplace=True)\n",
    "print(len(sofa_df_window))\n",
    "\n",
    "filter_subset_save(sofa_df_window, savename=\"sofa\", save=save_boolean, return_df=False, time_filter_override=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end of extraction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
