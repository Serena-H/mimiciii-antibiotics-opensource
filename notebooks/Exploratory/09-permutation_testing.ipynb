{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, accuracy_score, auc, precision_recall_fscore_support, pairwise, f1_score, log_loss, make_scorer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "\n",
    "#importin xg boost and all needed otherstuff\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier #conda install -c conda-forge xgboost to install\n",
    "##adding these, lets see if it helps with xgboost crash\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "#reducing warnings that are super common in my model\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.simplefilter(action='ignore') #ignore all warnings\n",
    "\n",
    "RANDOM_STATE = 15485867\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1024,\n",
    "        'height': 768,\n",
    "        'scroll': True,\n",
    "})\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.12 s\n"
     ]
    }
   ],
   "source": [
    "#patients of interest from rotation_cohort_generation\n",
    "from parameters import final_pt_df_v, date, repository_path, lower_window, upper_window, folder, date, time_col, time_var, patient_df\n",
    "\n",
    "#patients of interest from rotation_cohort_generation\n",
    "final_pt_df2 = final_pt_df_v #pd.read_csv('/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling/data/raw/csv/%s_final_pt_df2.csv'%(most_updated_patient_df), index_col=0)\n",
    "del(final_pt_df_v)\n",
    "\n",
    "patients= list(final_pt_df2['subject_id'].unique())\n",
    "hadm_id= list(final_pt_df2['hadm_id'].unique())\n",
    "icustay_id= list(final_pt_df2['icustay_id'].unique())\n",
    "icustay_id= [int(x) for x in icustay_id]\n",
    "\n",
    "save_boolean=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing x and y train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.64 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def data_import(allFiles):\n",
    "    \"\"\"\n",
    "    function to import x_train, x_test, y_train, and y_test using glob of the data/final folder.\n",
    "    \"\"\"\n",
    "    for name in allFiles:\n",
    "        if 'test' in name:\n",
    "            if 'x_' in name:\n",
    "                x_test = pd.read_csv(name,  index_col=0)\n",
    "            else:\n",
    "                 y_test = pd.read_csv(name,  index_col=0)\n",
    "        elif 'train' in name:\n",
    "            if 'x_' in name:\n",
    "                x_train = pd.read_csv(name,  index_col=0)\n",
    "            else:\n",
    "                 y_train = pd.read_csv(name,  index_col=0)\n",
    "    return(x_train, x_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 416 ms\n"
     ]
    }
   ],
   "source": [
    "#importing x and y train and test\n",
    "\n",
    "allFiles_24 = glob.glob(str(repository_path)+ '/data/final/%s/'%('24_hr_window') + \"*.csv\")\n",
    "allFiles_48 = glob.glob(str(repository_path)+ '/data/final/%s/'%('48_hr_window') + \"*.csv\")\n",
    "allFiles_72 = glob.glob(str(repository_path)+ '/data/final/%s/'%('72_hr_window') + \"*.csv\")\n",
    "\n",
    "x_train_24, x_test_24, y_train_24, y_test_24= data_import(allFiles_24)\n",
    "x_train_48, x_test_48, y_train_48, y_test_48= data_import(allFiles_48)\n",
    "x_train_72, x_test_72, y_train_72, y_test_72= data_import(allFiles_72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importing all models and storing them in dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.63 ms\n"
     ]
    }
   ],
   "source": [
    "def load_model(filename, timewindow):\n",
    "    import pickle\n",
    "    loaded_modle= pickle.load(open(filename, 'rb'))\n",
    "    return(loaded_modle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 550 ms\n"
     ]
    }
   ],
   "source": [
    "models_24 = glob.glob(str(repository_path)+ '/models/%s/'%('24_hr_window')+'*')\n",
    "models_48 = glob.glob(str(repository_path)+ '/models/%s/'%('48_hr_window')+'*')\n",
    "models_72 = glob.glob(str(repository_path)+ '/models/%s/'%('72_hr_window')+'*')\n",
    "\n",
    "models_24_dic={}\n",
    "models_48_dic={}\n",
    "models_72_dic={}\n",
    "\n",
    "for model in models_24:\n",
    "    models_24_dic.update( {model.strip('.sav').split('_')[-1] : load_model(model, '24_hr_window')} )\n",
    "    \n",
    "for model in models_48:\n",
    "    models_48_dic.update( {model.strip('.sav').split('_')[-1] : load_model(model, '48_hr_window')} )\n",
    "\n",
    "for model in models_72:\n",
    "    models_72_dic.update( {model.strip('.sav').split('_')[-1] : load_model(model, '72_hr_window')} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## permutation stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can control for dependent variables by stratifying the output and only permuting within each stratum. (Yeh 2000, Noreen 1989)\n",
    "* In this case, we’ll stratify each $o^i_A$,$o^j_B$\n",
    "* Let $o_A = {o^1_A, ... , o^n_A}$ and $o_B = {o^1_B, ... , o^n_B}$ be the output of the two systems on the same input.\n",
    "* Start with $X= o_A and Y=o_B$\n",
    "* Repeat R times: randomly flip each $o^i_A, o^j_B$  between X and Y with probability $\\frac{1}{2}$. Calculate $t(X,Y)$.\n",
    "* Let r be the number of times that $t(X,Y)≥t(o_A,o_B)$\n",
    "* As R → $∞$, $\\frac{r+1}{R+1}$ approaches the significance level.\n",
    "\n",
    "--taken from presentation: Statistical Hypothesis Tests for NLP or: Approximate Randomization for Fun and Profit by William Morgan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Null hypothesis: there is no difference between our model using N=72hr of data vs our model using N=24hr of data\n",
    "\n",
    "* We’ll run two systems on the same input and see how their output differs.\n",
    "\n",
    "* In the binary comparison case, with threshold 0.05, validity tells us that we’ll falsely reject the null hypothesis (make a type I error) 5% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 43.1 ms\n"
     ]
    }
   ],
   "source": [
    "def perm_test_fxn(out1,out2, absolute=False, verbose=True, N=1000):\n",
    "    row = len(out1)\n",
    "\n",
    "    mean1 = np.mean(out1);\n",
    "    mean2 = np.mean(out2)\n",
    "\n",
    "    pmean1 = [0] *N; pmean2 = [0] *N #initializing array of size N that will be replaced in loop\n",
    "    perm1 = out1;\n",
    "    perm2 = out2;\n",
    "\n",
    "    for i in range(N):\n",
    "        coins = np.random.rand(row);\n",
    "        ind1 = 0.5 <=coins;\n",
    "        ind2 = 0.5 >coins;\n",
    "        #assinging random indicies to be from out1 and out2. \n",
    "        \n",
    "        #initialization\n",
    "#         perm1 = out1\n",
    "#         perm2 = out2\n",
    "#         perm1 = np.random.rand(row)\n",
    "#         perm2 = np.random.rand(row)\n",
    "        perm1 = np.ones(row)\n",
    "        perm2 = np.ones(row)\n",
    "        \n",
    "        #assiging values from the resampled pair\n",
    "        perm1[ind1] =out1[ind1];\n",
    "        perm1[ind2] =out2[ind2];\n",
    "        perm2[ind1] =out2[ind1];\n",
    "        perm2[ind2] =out1[ind2];\n",
    "        \n",
    "        pmean1[i] = np.mean(perm1)\n",
    "        pmean2[i] = np.mean(perm2)\n",
    "        \n",
    "    if absolute==False:\n",
    "        p = rsig((np.array(pmean1) - np.array(pmean2)), (np.array(mean1) - np.array(mean2)) )\n",
    "    else:\n",
    "        p = rsig(abs(np.array(pmean1) - np.array(pmean2)), abs(np.array(mean1) - np.array(mean2)) ); # one side test\n",
    "\n",
    "    if verbose==True:\n",
    "        print('rand paired sig test on mean p=%f\\n' % (p))\n",
    "    return (p);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.3 ms\n"
     ]
    }
   ],
   "source": [
    "sum(out2==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf 72,24hr, dif: 0.236, 0.238, -0.002\n",
      "rand paired sig test on mean p=0.322336\n",
      "\n",
      "knn 72,24hr, dif: 0.186, 0.185, 0.001\n",
      "rand paired sig test on mean p=0.643871\n",
      "\n",
      "logreg 72,24hr, dif: 0.232, 0.235, -0.003\n",
      "rand paired sig test on mean p=0.036393\n",
      "\n",
      "xgboost 72,24hr, dif: 0.231, 0.236, -0.005\n",
      "rand paired sig test on mean p=0.004399\n",
      "\n",
      "ensemble 72,24hr, dif: 0.233, 0.236, -0.004\n",
      "rand paired sig test on mean p=0.009998\n",
      "\n",
      "svc 72,24hr, dif: 0.230, 0.236, -0.006\n",
      "rand paired sig test on mean p=0.000400\n",
      "\n",
      "time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "model_names=[]\n",
    "mean_72=[]\n",
    "mean_24=[]\n",
    "delta_mean=[]\n",
    "p_list=[]\n",
    "for key in models_72_dic.keys():\n",
    "    out1=models_72_dic[key].predict_proba(np.array(x_test_72))[:,1]\n",
    "    out2=models_24_dic[key].predict_proba(np.array(x_test_24))[:,1]\n",
    "    print(\"%s 72,24hr, dif: %.3f, %.3f, %.3f\"% (key, np.mean(out1),np.mean(out2), np.mean(out1)-np.mean(out2)))\n",
    "    model_names.append(key)\n",
    "    mean_72.append(np.mean(out1))\n",
    "    mean_24.append(np.mean(out2))\n",
    "    delta_mean.append(np.mean(out1)-np.mean(out2))\n",
    "    p=perm_test_fxn(out1,out2, absolute=True, verbose=True, N=5000)\n",
    "    p_list.append(p)\n",
    "\n",
    "delta_dic={'model':model_names,\n",
    "           'mean_72':mean_72,\n",
    "           'mean_24':mean_24,\n",
    "           'mean_delta':delta_mean,\n",
    "           'resample_p':p_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_72</th>\n",
       "      <th>mean_24</th>\n",
       "      <th>mean_delta</th>\n",
       "      <th>resample_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ensemble</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svc</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  mean_72  mean_24  mean_delta  resample_p\n",
       "0        rf    0.236    0.238      -0.002       0.322\n",
       "1       knn    0.186    0.185       0.001       0.644\n",
       "2    logreg    0.232    0.235      -0.003       0.036\n",
       "3   xgboost    0.231    0.236      -0.005       0.004\n",
       "4  ensemble    0.233    0.236      -0.004       0.010\n",
       "5       svc    0.230    0.236      -0.006       0.000"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.2 ms\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(delta_dic).round(3) #run with initializing to rand or 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_72</th>\n",
       "      <th>mean_24</th>\n",
       "      <th>mean_delta</th>\n",
       "      <th>resample_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.238</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>0.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.235</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.231</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ensemble</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svc</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  mean_72  mean_24  mean_delta  resample_p\n",
       "0        rf    0.236    0.238      -0.002       0.329\n",
       "1       knn    0.186    0.185       0.001       0.654\n",
       "2    logreg    0.232    0.235      -0.003       0.033\n",
       "3   xgboost    0.231    0.236      -0.005       0.002\n",
       "4  ensemble    0.233    0.236      -0.004       0.008\n",
       "5       svc    0.230    0.236      -0.006       0.000"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.7 ms\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(delta_dic).round(3) #run with initializing to rand or 1's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* using abs or not:\n",
    " * here we are comparing the difference in means between (meanP(model_72) - meanP(model_24))=mean_model_diff and each resample of (meanP(perm1) - meanP(perm2))=perm_diff[i]\n",
    " * we count the # of times the perm_diff >= man_model_diff = count(permdiff)\n",
    " * we then (count(perm_diff)+1)/ #resamples+1 = p.\n",
    " * so if we use absolute value of the differences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mean_72</th>\n",
       "      <th>mean_24</th>\n",
       "      <th>mean_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.236315</td>\n",
       "      <td>0.237831</td>\n",
       "      <td>-0.001516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.186090</td>\n",
       "      <td>0.185406</td>\n",
       "      <td>0.000684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logreg</td>\n",
       "      <td>0.231815</td>\n",
       "      <td>0.235129</td>\n",
       "      <td>-0.003314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.231334</td>\n",
       "      <td>0.236067</td>\n",
       "      <td>-0.004733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ensemble</td>\n",
       "      <td>0.232640</td>\n",
       "      <td>0.236308</td>\n",
       "      <td>-0.003668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>svc</td>\n",
       "      <td>0.230368</td>\n",
       "      <td>0.236199</td>\n",
       "      <td>-0.005831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model   mean_72   mean_24  mean_delta\n",
       "0        rf  0.236315  0.237831   -0.001516\n",
       "1       knn  0.186090  0.185406    0.000684\n",
       "2    logreg  0.231815  0.235129   -0.003314\n",
       "3   xgboost  0.231334  0.236067   -0.004733\n",
       "4  ensemble  0.232640  0.236308   -0.003668\n",
       "5       svc  0.230368  0.236199   -0.005831"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.5 ms\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(delta_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf 72,24hr, dif: 0.236, 0.238, -0.002\n",
      "knn 72,24hr, dif: 0.186, 0.185, 0.001\n",
      "logreg 72,24hr, dif: 0.232, 0.235, -0.003\n",
      "xgboost 72,24hr, dif: 0.231, 0.236, -0.005\n",
      "ensemble 72,24hr, dif: 0.233, 0.236, -0.004\n",
      "svc 72,24hr, dif: 0.230, 0.236, -0.006\n",
      "time: 5.22 s\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/models/72_hr_window/finalized_svc.sav'])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.12 ms\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf', 'knn', 'logreg', 'xgboost', 'ensemble', 'svc']"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.15 ms\n"
     ]
    }
   ],
   "source": [
    "list(models_72_dic.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.2 ms\n"
     ]
    }
   ],
   "source": [
    "def rsig(perm_diff, mean_model_diff):\n",
    "\n",
    "    R = len(perm_diff)\n",
    "    r = sum(perm_diff >= mean_model_diff)\n",
    "#     print('R,r: ', R,r)\n",
    "    p = (r+1.)/(R+1.)\n",
    "#     print('p: ', p)\n",
    "    ## p = r/R\n",
    "    return (p);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 61.5 ms\n"
     ]
    }
   ],
   "source": [
    "def perm_test_fxn2(out1,out2):\n",
    "    '''same as perm_test_fxn but more verbose for bugfixing'''\n",
    "\n",
    "    N=5\n",
    "    row = len(out1)\n",
    "\n",
    "    mean1 = np.mean(out1);\n",
    "    mean2 = np.mean(out2)\n",
    "\n",
    "    pmean1 = [0] *N; pmean2 = [0] *N #initializing array of size N that will be replaced in loop\n",
    "    perm1 = out1;\n",
    "    perm2 = out2;\n",
    "\n",
    "    for i in range(N):\n",
    "        coins = np.random.rand(row);\n",
    "    #     print('coins: ', coins)\n",
    "        print('lencoins, out1',len(coins), print(len(perm1)))\n",
    "        ## only pick one half \n",
    "\n",
    "        ind1 = 0.5 <=coins;\n",
    "        ind2 = 0.5 >coins;\n",
    "        print('coins: ', coins)\n",
    "        print('ind1: ', ind1)\n",
    "        print('ind2', ind2)\n",
    "        #the lines above are a way of picking random indicies to sample from \n",
    "        \n",
    "        perm1 = np.ones(row)\n",
    "        perm2 = np.ones(row)\n",
    "\n",
    "        perm1[ind1] =out1[ind1];\n",
    "        perm1[ind2] =out2[ind2];\n",
    "\n",
    "        perm2[ind1] =out2[ind1];\n",
    "        perm2[ind2] =out1[ind2];\n",
    "\n",
    "        pmean1[i] = np.mean(perm1)\n",
    "        pmean2[i] = np.mean(perm2)\n",
    "        print('perm1[ind1]:',perm1[ind1] )\n",
    "        print('perm1: ', perm1)\n",
    "        print('perm2[ind1]:',perm2[ind1] )\n",
    "        print('perm2: ', perm2)\n",
    "        #print('pmean1[i]:',pmean1[i])\n",
    "        print('pmean1:',pmean1)\n",
    "        #print('pmean2[i]:',pmean2[i])\n",
    "        print('pmean2:',pmean2)\n",
    "#         del(ind1,ind2)\n",
    "    print('final_perm1: ', perm1)\n",
    "    print('final_perm2: ', perm2)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand paired sig test on mean p=0.848152\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8481518481518482"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 473 ms\n"
     ]
    }
   ],
   "source": [
    "#df_dic['rf'],x=x_test_24,y=y_test_24\n",
    "out1=models_72_dic['rf'].predict_proba(np.array(x_test_72))[:,1]\n",
    "out2=models_24_dic['rf'].predict_proba(np.array(x_test_24))[:,1]\n",
    "perm_test_fxn(out1,out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23133396"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.94 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.mean(out1),\n",
    "np.mean(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23606709"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.7 ms\n"
     ]
    }
   ],
   "source": [
    "np.mean(out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.9 ms\n"
     ]
    }
   ],
   "source": [
    "np.mean(out1-out2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert type 'float32' to numerator/denominator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-e309a0dfe619>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstatistics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/rpy-env/lib/python3.6/statistics.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mStatisticsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mean requires at least one data point'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/rpy-env/lib/python3.6/statistics.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(data, start)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_coerce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# or raise TypeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_exact_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mpartials\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartials_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/rpy-env/lib/python3.6/statistics.py\u001b[0m in \u001b[0;36m_exact_ratio\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"can't convert type '{}' to numerator/denominator\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert type 'float32' to numerator/denominator"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.9 ms\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "mean(out2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "rand paired sig test on mean p=1.000000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.83 s\n"
     ]
    }
   ],
   "source": [
    "randPairedSigTest(out1,out2, N=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.24957651, 0.25126702, 0.11935172, ..., 0.11380261, 0.6149088 ,\n",
       "       0.06434408], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.01 ms\n"
     ]
    }
   ],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
