{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the purpose of this notebook is to take the big dataframe created in 07.01-baseline_data_merging, and make an aggregate we can use for our baseline \"worst case\" scenario model. This will then be fed into R, where we will use the MICE package to impute data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changelog:\n",
    "\n",
    "* 4/16/19: added newagg\n",
    "* 4/17/19: reformatted the ordering of how code runs, and variable names. added aggregation #3.\n",
    "* 4/19/19: changed the standardizing so that log(x+1) is now applied prior to standardization. also removed ordinal variables from standardizing algorithm and concat them in later with median 0 and iqr 1 so standardize value is either 0 or 1. values from ordinal are not log transformed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06/14/19:\n",
    "# prior to this point my pipeline:\n",
    "1. first median standardized\n",
    "2. aggregated\n",
    "3. converted to 2class\n",
    "4. train/test split\n",
    "5. imputed\n",
    "\n",
    "\n",
    "# a big change will happen in this notebook, I will first:\n",
    "1. convert to two class (c-/abshort &c+/ablong)\n",
    "2. split the train and test set\n",
    "3. median standardize\n",
    "4. aggregate\n",
    "5. impute\n",
    "BEFORE I AGGREGATE and median standardize, as some information may be leaking from the train/test set as i had it previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## last run: 6/14/19: sensitivity analysis 3day timewindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning: The 'cachedir' parameter has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "You provided \"cachedir='/tmp'\", use \"location='/tmp'\" instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.model_selection import train_test_split\n",
    "memory = Memory(cachedir='/tmp', verbose=0)\n",
    "#@memory.cache above any def fxn.\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1024,\n",
    "        'height': 768,\n",
    "        'scroll': True,\n",
    "})\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.28 s\n"
     ]
    }
   ],
   "source": [
    "#patients of interest from rotation_cohort_generation\n",
    "from parameters import final_pt_df_v, date, repository_path\n",
    "\n",
    "#patients of interest from rotation_cohort_generation\n",
    "final_pt_df2 = final_pt_df_v #pd.read_csv('/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling/data/raw/csv/%s_final_pt_df2.csv'%(most_updated_patient_df), index_col=0)\n",
    "del(final_pt_df_v)\n",
    "\n",
    "patients= list(final_pt_df2['subject_id'].unique())\n",
    "hadm_id= list(final_pt_df2['hadm_id'].unique())\n",
    "icustay_id= list(final_pt_df2['icustay_id'].unique())\n",
    "icustay_id= [int(x) for x in icustay_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15412"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.21 ms\n"
     ]
    }
   ],
   "source": [
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.28 ms\n"
     ]
    }
   ],
   "source": [
    "save_path= str(repository_path)+'/data/cleaned_merged_agg/'\n",
    "def save_df(df, df_name='default', save_path=save_path, add_subfolder=False):\n",
    "    #uses the date and supplied df name and saves to the savepath specified above.\n",
    "    if df_name == 'default':\n",
    "        df_name= \"%s\"%(df)\n",
    "    \n",
    "    address=save_path+'%s/'%(folder)\n",
    "    if not os.path.exists(address):\n",
    "        print(address)\n",
    "        os.makedirs(address)\n",
    "    pd.DataFrame(df).to_csv(Path(address+'%s_%s_cleaned_merged_agg.csv' %(date, df_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 753 Âµs\n"
     ]
    }
   ],
   "source": [
    "from parameters import lower_window, upper_window, folder, date, time_col, time_var, patient_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12.5 s\n"
     ]
    }
   ],
   "source": [
    "#importing cleaned_merged big_df\n",
    "allFiles = glob.glob(str(repository_path)+ '/data/cleaned_merged/%s/'%(folder) + \"{}_*.csv\".format(date))\n",
    "\n",
    "df_list=[]\n",
    "for element in allFiles:\n",
    "    df_list.append(element.split('{}_'.format(date))[1].split('_prepped.csv')[0]) #making an list of all my dataframes in order they appear in file\n",
    "\n",
    "i=0\n",
    "for name in df_list:\n",
    "    big_df = pd.read_csv(allFiles[i],  index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 374 ms\n"
     ]
    }
   ],
   "source": [
    "#quick housekeeping addition to accomidate older generated data\n",
    "if len(big_df.loc[big_df['label']==\"pao2/fio2\",'label'])>1:\n",
    "    big_df.loc[big_df['label']==\"pao2/fio2\",'label']=\"pao2fio2ratio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>t_0</th>\n",
       "      <th>value</th>\n",
       "      <th>label</th>\n",
       "      <th>uom</th>\n",
       "      <th>delta</th>\n",
       "      <th>source</th>\n",
       "      <th>subject_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>840553</th>\n",
       "      <td>200001.0</td>\n",
       "      <td>2181-11-26</td>\n",
       "      <td>absent</td>\n",
       "      <td>bands</td>\n",
       "      <td>y/n</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>labs</td>\n",
       "      <td>55973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16144</th>\n",
       "      <td>200001.0</td>\n",
       "      <td>2181-11-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cancer_elix</td>\n",
       "      <td>y/n</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>cancer_elix</td>\n",
       "      <td>55973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22958</th>\n",
       "      <td>200001.0</td>\n",
       "      <td>2181-11-26</td>\n",
       "      <td>5</td>\n",
       "      <td>daily_sofa</td>\n",
       "      <td>daily_sofa_score</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>sofa</td>\n",
       "      <td>55973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14836</th>\n",
       "      <td>200001.0</td>\n",
       "      <td>2181-11-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dobutamine</td>\n",
       "      <td>y/n</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>dobutamine</td>\n",
       "      <td>55973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18928</th>\n",
       "      <td>200001.0</td>\n",
       "      <td>2181-11-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dopamine</td>\n",
       "      <td>y/n</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>dopamine</td>\n",
       "      <td>55973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        icustay_id         t_0   value        label               uom  \\\n",
       "840553    200001.0  2181-11-26  absent        bands               y/n   \n",
       "16144     200001.0  2181-11-26     0.0  cancer_elix               y/n   \n",
       "22958     200001.0  2181-11-26       5   daily_sofa  daily_sofa_score   \n",
       "14836     200001.0  2181-11-26     0.0   dobutamine               y/n   \n",
       "18928     200001.0  2181-11-26     0.0     dopamine               y/n   \n",
       "\n",
       "                            delta       source  subject_id  \n",
       "840553  0 days 00:00:00.000000000         labs       55973  \n",
       "16144   0 days 00:00:00.000000000  cancer_elix       55973  \n",
       "22958   0 days 00:00:00.000000000         sofa       55973  \n",
       "14836   0 days 00:00:00.000000000   dobutamine       55973  \n",
       "18928   0 days 00:00:00.000000000     dopamine       55973  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 16.7 ms\n"
     ]
    }
   ],
   "source": [
    "big_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dobutamine</th>\n",
       "      <td>20982</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rrt</th>\n",
       "      <td>19633</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nitrite</th>\n",
       "      <td>19633</td>\n",
       "      <td>2</td>\n",
       "      <td>Neg/Not_tested</td>\n",
       "      <td>19095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>12904</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>7021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epinephrine</th>\n",
       "      <td>21746</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dopamine</th>\n",
       "      <td>25211</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vasopressin</th>\n",
       "      <td>22874</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norepinephrine</th>\n",
       "      <td>42225</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leukocyte</th>\n",
       "      <td>19633</td>\n",
       "      <td>2</td>\n",
       "      <td>Neg/Not_tested</td>\n",
       "      <td>16774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o2_flow</th>\n",
       "      <td>19932</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancer_elix</th>\n",
       "      <td>19633</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phenylephrine</th>\n",
       "      <td>34687</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pco2</th>\n",
       "      <td>19633</td>\n",
       "      <td>3</td>\n",
       "      <td>absent</td>\n",
       "      <td>11981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vent_recieved</th>\n",
       "      <td>19456</td>\n",
       "      <td>3</td>\n",
       "      <td>Mech</td>\n",
       "      <td>9958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bands</th>\n",
       "      <td>19633</td>\n",
       "      <td>3</td>\n",
       "      <td>absent</td>\n",
       "      <td>16546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethnicity</th>\n",
       "      <td>12904</td>\n",
       "      <td>5</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>9332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mingcs</th>\n",
       "      <td>7777</td>\n",
       "      <td>13</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_elix</th>\n",
       "      <td>22281</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily_sofa</th>\n",
       "      <td>43650</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>7816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bicarbonate</th>\n",
       "      <td>62333</td>\n",
       "      <td>57</td>\n",
       "      <td>23.0</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resprate</th>\n",
       "      <td>1020068</td>\n",
       "      <td>72</td>\n",
       "      <td>20.0</td>\n",
       "      <td>79576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sodium</th>\n",
       "      <td>73014</td>\n",
       "      <td>84</td>\n",
       "      <td>138.0</td>\n",
       "      <td>6536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chloride</th>\n",
       "      <td>69606</td>\n",
       "      <td>84</td>\n",
       "      <td>106.0</td>\n",
       "      <td>4480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spo2</th>\n",
       "      <td>926507</td>\n",
       "      <td>102</td>\n",
       "      <td>100.0</td>\n",
       "      <td>223264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potassium</th>\n",
       "      <td>89966</td>\n",
       "      <td>103</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ph</th>\n",
       "      <td>78707</td>\n",
       "      <td>104</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>13372</td>\n",
       "      <td>134</td>\n",
       "      <td>177.8</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hemoglobin</th>\n",
       "      <td>67540</td>\n",
       "      <td>169</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inr</th>\n",
       "      <td>41916</td>\n",
       "      <td>186</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creatinine</th>\n",
       "      <td>62214</td>\n",
       "      <td>186</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calcium</th>\n",
       "      <td>33713</td>\n",
       "      <td>193</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bun</th>\n",
       "      <td>61960</td>\n",
       "      <td>200</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heartrate</th>\n",
       "      <td>966962</td>\n",
       "      <td>206</td>\n",
       "      <td>80.0</td>\n",
       "      <td>25775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diasbp</th>\n",
       "      <td>943009</td>\n",
       "      <td>208</td>\n",
       "      <td>56.0</td>\n",
       "      <td>29858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sysbp</th>\n",
       "      <td>947120</td>\n",
       "      <td>241</td>\n",
       "      <td>108.0</td>\n",
       "      <td>17837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lactate</th>\n",
       "      <td>42157</td>\n",
       "      <td>309</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bilirubin</th>\n",
       "      <td>18798</td>\n",
       "      <td>455</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanartpress</th>\n",
       "      <td>957885</td>\n",
       "      <td>588</td>\n",
       "      <td>72.0</td>\n",
       "      <td>25498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>293018</td>\n",
       "      <td>619</td>\n",
       "      <td>36.6666666666667</td>\n",
       "      <td>7678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>232724</td>\n",
       "      <td>734</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wbc</th>\n",
       "      <td>55783</td>\n",
       "      <td>822</td>\n",
       "      <td>8.8</td>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platelet</th>\n",
       "      <td>58189</td>\n",
       "      <td>947</td>\n",
       "      <td>108.0</td>\n",
       "      <td>266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pao2fio2ratio</th>\n",
       "      <td>19633</td>\n",
       "      <td>1150</td>\n",
       "      <td>476.0</td>\n",
       "      <td>11982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ptt</th>\n",
       "      <td>43966</td>\n",
       "      <td>1244</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>17867</td>\n",
       "      <td>1573</td>\n",
       "      <td>70.0</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearsold</th>\n",
       "      <td>12904</td>\n",
       "      <td>12129</td>\n",
       "      <td>90.0</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count unique                top    freq\n",
       "label                                                    \n",
       "dobutamine        20982      2                0.0   19345\n",
       "rrt               19633      2                0.0   17960\n",
       "nitrite           19633      2     Neg/Not_tested   19095\n",
       "gender            12904      2                  M    7021\n",
       "epinephrine       21746      2                0.0   19187\n",
       "dopamine          25211      2                0.0   18518\n",
       "vasopressin       22874      2                0.0   19117\n",
       "norepinephrine    42225      2                1.0   26326\n",
       "leukocyte         19633      2     Neg/Not_tested   16774\n",
       "o2_flow           19932      2                0.0   18754\n",
       "cancer_elix       19633      2                0.0   17212\n",
       "phenylephrine     34687      2                1.0   18147\n",
       "pco2              19633      3             absent   11981\n",
       "vent_recieved     19456      3               Mech    9958\n",
       "bands             19633      3             absent   16546\n",
       "ethnicity         12904      5  white/nonhispanic    9332\n",
       "mingcs             7777     13               15.0    2812\n",
       "sum_elix          22281     14                0.0   14005\n",
       "daily_sofa        43650     24                  1    7816\n",
       "bicarbonate       62333     57               23.0    5169\n",
       "resprate        1020068     72               20.0   79576\n",
       "sodium            73014     84              138.0    6536\n",
       "chloride          69606     84              106.0    4480\n",
       "spo2             926507    102              100.0  223264\n",
       "potassium         89966    103                4.0    6388\n",
       "ph                78707    104                7.4    4131\n",
       "height            13372    134              177.8     870\n",
       "hemoglobin        67540    169                9.7    1609\n",
       "inr               41916    186                1.2    6086\n",
       "creatinine        62214    186                0.7    5054\n",
       "calcium           33713    193               1.13    1673\n",
       "bun               61960    200               13.0    1819\n",
       "heartrate        966962    206               80.0   25775\n",
       "diasbp           943009    208               56.0   29858\n",
       "sysbp            947120    241              108.0   17837\n",
       "lactate           42157    309                1.2    1984\n",
       "bilirubin         18798    455                0.4    1492\n",
       "meanartpress     957885    588               72.0   25498\n",
       "temperature      293018    619   36.6666666666667    7678\n",
       "glucose          232724    734              110.0    2536\n",
       "wbc               55783    822                8.8     458\n",
       "platelet          58189    947              108.0     266\n",
       "pao2fio2ratio     19633   1150              476.0   11982\n",
       "ptt               43966   1244              150.0    1073\n",
       "weight            17867   1573               70.0     322\n",
       "yearsold          12904  12129               90.0     776"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.06 s\n"
     ]
    }
   ],
   "source": [
    "#overview of all variables and formats\n",
    "big_df.groupby('label')['value'].describe().sort_values('unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial data prep\n",
    "* convert to two class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.5 ms\n"
     ]
    }
   ],
   "source": [
    "#convert to two class\n",
    "final_pt_df2['final_bin'].unique()\n",
    "two_classes=['C_neg/A_partial','C_pos/A_full']\n",
    "two_class_icu=final_pt_df2.loc[final_pt_df2.loc[:,\"final_bin\"].isin(two_classes),['icustay_id','subject_id','final_bin']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "big_df=big_df.loc[big_df['icustay_id'].isin(list(two_class_icu['icustay_id'])),:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10305"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 37.5 ms\n"
     ]
    }
   ],
   "source": [
    "len(big_df)\n",
    "big_df['icustay_id'].nunique() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roundabout way of sampling train/test set so that each subject is only in either train or test:\n",
    "* To ensure a single patient did not end up with samples in both training and testing sets, individual patients (subject_id's) are kept together when performing the stratified train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "# label each subject_id with the max of the two classes. \n",
    "two_class_pt=two_class_icu.copy()\n",
    "two_class_pt['final_bin']=pd.factorize(two_class_pt['final_bin'])[0]\n",
    "two_class_maxsub=two_class_pt.loc[two_class_pt.groupby('subject_id')['final_bin'].idxmax(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.38 s\n"
     ]
    }
   ],
   "source": [
    "# 70/30 train/test set split with 12345=seed, splitting on max final bin of each SUBJECT_ID\n",
    "train, test = train_test_split(two_class_maxsub, test_size=0.3, random_state=12345, \n",
    "                               stratify=two_class_maxsub['final_bin'])\n",
    "# generate list of each SUBJECT_ID in each split\n",
    "train_subject=list(train['subject_id'])\n",
    "test_subject=list(test['subject_id'])\n",
    "\n",
    "#filtering big_df on train subjects and test subjects to get my train/test splits.\n",
    "big_df_train= big_df.loc[big_df.loc[:,'subject_id'].isin(train_subject),:].copy()\n",
    "big_df_test= big_df.loc[big_df.loc[:,'subject_id'].isin(test_subject),:].copy()\n",
    "del big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 861 Âµs\n"
     ]
    }
   ],
   "source": [
    "# #converting venttype to category\n",
    "# big_df.loc[big_df.loc[:,'label']=='vent_recieved','value']= big_df.loc[big_df.loc[:,'label']=='vent_recieved','value'].astype('category')\n",
    "# #big_df.loc[big_df.loc[:,'label']=='vent_recieved','value'].apply(astype('category'))\n",
    "# big_df.loc[big_df.loc[:,'label']=='vent_recieved','value'] = pd.Categorical(big_df.loc[big_df.loc[:,'label']=='vent_recieved','value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 59.6 ms\n"
     ]
    }
   ],
   "source": [
    "def category_mapper(big_df):\n",
    "    \n",
    "    \"\"\"\n",
    "    this function is designed to map some variables currently in categorical format into a ordinal category for the following aggregations. the variables are eventually converted to one-hot-encoding prior to modeling. \n",
    "    \"\"\"\n",
    "    #converting categories to integers\n",
    "    mapper={'Mech':2 , 'Oxygen': 1, 'None': 0}\n",
    "    big_df.loc[big_df.loc[:,'label']=='vent_recieved','value']=big_df.loc[big_df.loc[:,'label']=='vent_recieved','value'].replace(mapper).copy()\n",
    "\n",
    "    #gender_index=pd.factorize(big_df.loc[big_df.loc[:,'label']=='gender','value'])[1]\n",
    "    mapper={'F':0 , 'M': 1}\n",
    "    big_df.loc[big_df.loc[:,'label']=='gender','value']=big_df.loc[big_df.loc[:,'label']=='gender','value'].replace(mapper).copy()\n",
    "\n",
    "    #leukocyte_index=pd.factorize(big_df.loc[big_df.loc[:,'label']=='leukocyte','value'])[1]\n",
    "    mapper={'Neg/Not_tested':0 , 'pos': 1}\n",
    "    big_df.loc[big_df.loc[:,'label']=='leukocyte','value']=big_df.loc[big_df.loc[:,'label']=='leukocyte','value'].replace(mapper).copy()\n",
    "    #     pd.factorize(big_df.loc[big_df.loc[:,'label']=='leukocyte','value'])[0] \n",
    "\n",
    "    #nitrite_index=pd.factorize(big_df.loc[big_df.loc[:,'label']=='nitrite','value'])[1]\n",
    "    mapper={'Neg/Not_tested':0 , 'pos': 1}\n",
    "    big_df.loc[big_df.loc[:,'label']=='nitrite','value']=big_df.loc[big_df.loc[:,'label']=='nitrite','value'].replace(mapper).copy()\n",
    "    #     pd.factorize(big_df.loc[big_df.loc[:,'label']=='nitrite','value'])[0] \n",
    "    \n",
    "    # changing pao2/fio2 ratio to a category\n",
    "    \"\"\"\n",
    "    A PaO2/FiO2 ratio less than or equal to 200 is necessary for the diagnosis of acute respiratory distress syndrome by the AECC criteria.[6] \n",
    "    The more recent Berlin criteria defines mild ARDS at a ratio of <300.\n",
    "\n",
    "    A PaO2/FiO2 ratio less than or equal to 250 is one of the minor criteria for severe community acquired pneumonia (i.e., possible indication for inpatient treatment).\n",
    "\n",
    "    A PaO2/FiO2 ratio less than or equal to 333 is one of the variables in the SMART-COP risk score for intensive respiratory or vasopressor support in community-acquired pneumonia.\n",
    "    \"\"\"\n",
    "    \n",
    "    pd.to_numeric(big_df[big_df['label']==\"pao2fio2ratio\"]['value'])\n",
    "    labels= ['0-200', '201-333', \"334-475\",\"476+\"]\n",
    "    bins = pd.IntervalIndex.from_tuples([(0, 200), (200, 333), (333, 475),(475,3000)])\n",
    "\n",
    "    big_df.loc[big_df['label']==\"pao2fio2ratio\",'value']=pd.cut(pd.to_numeric(big_df.loc[big_df['label']==\"pao2fio2ratio\",'value']), bins,right=False, labels=labels)\n",
    "    big_df.loc[big_df['label']==\"pao2fio2ratio\",'value'].value_counts()\n",
    "    return(big_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.99 s\n"
     ]
    }
   ],
   "source": [
    "big_df_train=category_mapper(big_df_train)\n",
    "big_df_test=category_mapper(big_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3422\n",
       "2    3261\n",
       "0     450\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 104 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='vent_recieved','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2628\n",
       "0    2147\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 110 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='gender','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absent    6254\n",
       "<10        607\n",
       ">10        344\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 113 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='bands','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absent    4752\n",
       "<50       1752\n",
       ">50        701\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='pco2','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2628\n",
       "0    2147\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 109 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='gender','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475, 3000]    2236\n",
       "(333, 475]      310\n",
       "(0, 200]        297\n",
       "(200, 333]      257\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 51.5 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_test.loc[big_df_test.loc[:,'label']=='pao2fio2ratio','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475, 3000]    5207\n",
       "(333, 475]      687\n",
       "(0, 200]        674\n",
       "(200, 333]      637\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 113 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='pao2fio2ratio','value'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calc median/iqr for standardization\n",
    "take all non-categorical variables for HEALTHY PATIENTS and calculate the median and IQR for them. then will use this to make z scores via:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Z=\\frac{(X-\\widetilde{X}_{-/short})}{(IQR_{-/short})}$$ where $\\widetilde{X}_{-/short}$ is the median value of the patients with negative SSC and short duration EAT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.6 ms\n"
     ]
    }
   ],
   "source": [
    "continuous=['daily_sofa',\n",
    "            'lactate',\n",
    "            'mingcs',\n",
    "            'diasbp',\n",
    "            'heartrate',\n",
    "            'meanartpress',\n",
    "            'resprate',\n",
    "            'sysbp',\n",
    "            'temperature',\n",
    "            'hemoglobin',\n",
    "            'platelet',\n",
    "            'wbc',\n",
    "            'calcium',\n",
    "            'glucose',\n",
    "            'ph',\n",
    "            'bicarbonate',\n",
    "            'bun',\n",
    "            'chloride',\n",
    "            'creatinine',\n",
    "            'inr',\n",
    "            'potassium',\n",
    "            'ptt',\n",
    "            'sodium',\n",
    "            'bilirubin',\n",
    "            'spo2',\n",
    "            'sum_elix']\n",
    "\n",
    "onetime=['yearsold','height','weight']\n",
    "\n",
    "vaso_active=['phenylephrine',\n",
    "            'norepinephrine',\n",
    "            'vasopressin',\n",
    "            'dobutamine',\n",
    "            'dopamine',\n",
    "            'epinephrine'] \n",
    "\n",
    "ordinal=[\n",
    "            'leukocyte',\n",
    "            'nitrite',\n",
    "            'vent_recieved',\n",
    "            'o2_flow',\n",
    "            'rrt',\n",
    "            'pao2fio2ratio',\n",
    "            'cancer_elix',\n",
    "            \"any_vasoactives\",\n",
    "            'bands', #added 6/13/19\n",
    "            'pco2' #added 6/13/19\n",
    "]\n",
    "\n",
    "categorical=[\n",
    "            \"ethnicity\",\n",
    "            'gender'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 292 ms\n"
     ]
    }
   ],
   "source": [
    "def median_label_fxn(big_df):\n",
    "    global final_pt_df2\n",
    "    \n",
    "    healthy_pt=list(final_pt_df2[final_pt_df2['final_bin']==\"C_neg/A_partial\"]['icustay_id'])\n",
    "\n",
    "    #filter to only healthy patients filter\n",
    "    ##splitting big_df, making a copy and restricting it to all values that will be usd in standardizing\n",
    "    healthy_df=big_df[big_df['label'].isin(continuous+onetime)].copy()\n",
    "    healthy_df['value']= pd.to_numeric(healthy_df['value']) #converting to numeric \n",
    "    healthy_df=healthy_df[healthy_df['icustay_id'].isin(healthy_pt)].copy() #only numerical values for cneg/ab partial pt\n",
    "    \n",
    "    #finding the last 24 hours of each healthy patient.\n",
    "    healthy_pt_end=pd.DataFrame(healthy_df.groupby(\"icustay_id\")['delta'].max())\n",
    "    healthy_pt_end[\"start\"]=healthy_pt_end['delta']- pd.to_timedelta(\"1 day 00:00:00\")\n",
    "    healthy_pt_end=healthy_pt_end.rename(columns={\"delta\":\"end\"}).reset_index()\n",
    "    healthy_df= pd.merge(healthy_df,healthy_pt_end, left_on=\"icustay_id\", right_on=\"icustay_id\", how=\"left\" ) #now have the last 24 hours annotated for each patient as start and end.\n",
    "    \n",
    "    #calculating medians and iqr for each label based on healthy patient's last 24 hours in icu\n",
    "    median_label=pd.DataFrame((healthy_df.groupby(\"label\")['value'].median())).reset_index()\n",
    "    median_label=median_label.rename(columns={'value':\"median\"})\n",
    "    iqr_label=pd.DataFrame((healthy_df.groupby(\"label\")['value'].quantile(0.75)-healthy_df.groupby(\"label\")['value'].quantile(0.25))).reset_index()\n",
    "    iqr_label=iqr_label.rename(columns={'value':\"iqr\"})\n",
    "    median_label=pd.merge(median_label,iqr_label)  #final median df\n",
    "    return(median_label)\n",
    "\n",
    "def combine_vasoactives(big_noCat, median_label):\n",
    "    global vaso_active\n",
    "    ##combining vasoactives\n",
    "    vaso_active_df=big_noCat[big_noCat['label'].isin(vaso_active)].groupby('icustay_id')['value'].max().reset_index()\n",
    "    vaso_active_df['uom']=\"y/n\"\n",
    "    vaso_active_df['label']=\"any_vasoactives\"\n",
    "    vaso_active_df['delta']=pd.to_timedelta(\"0days\")\n",
    "    vaso_active_df['source']=\"any_vasoactives\"\n",
    "\n",
    "    vaso_active_df=pd.merge(vaso_active_df, final_pt_df2[[\"icustay_id\",'subject_id',\"t_0\"]], how=\"left\", left_on=\"icustay_id\", right_on=\"icustay_id\")\n",
    "    vaso_active_df=pd.merge(vaso_active_df, median_label, how=\"left\").fillna(0)\n",
    "    vaso_active_df['standardize']=vaso_active_df['value']\n",
    "    vaso_active_df['raw_value']=vaso_active_df['value']\n",
    "    vaso_active_df.head()\n",
    "\n",
    "    # # #grabing the rest of the variables not suitable for range or mean/std\n",
    "    big_noCat=pd.concat([big_noCat, vaso_active_df], sort=False)\n",
    "    return(big_noCat)\n",
    "\n",
    "def standardization_fxn(big_df):\n",
    "    global continuous, onetime, vaso_active, ordinal, categorical\n",
    "    \n",
    "    median_label=median_label_fxn(big_df)\n",
    "    \n",
    "    ### dataformatting: convert all dtypes to a numeric type that pereserves nan. \n",
    "    #splitting categorical, ordinal and continuous\n",
    "    big_categorical= big_df.loc[big_df.loc[:,'label'].isin(categorical),:].copy() \n",
    "\n",
    "    #continuous and ordinal variables\n",
    "    big_noCat= big_df.loc[big_df.loc[:,'label'].isin(continuous),:].copy() \n",
    "    big_noCat['value']= big_noCat['value'].apply(pd.to_numeric, args=('coerce',)) #instead of convert to float, may preserve nan's better. \n",
    "    \n",
    "    ### adding a standardized value (x-median)/iqr  where median is of the last 24 hours in time window for culture neg/ ab partial patients \n",
    "    big_noCat=pd.merge(big_noCat, median_label, how=\"left\") \n",
    "    #loging values\n",
    "    big_noCat['median']= np.log(big_noCat['median']+1.0)\n",
    "    big_noCat['iqr']= np.log(big_noCat['iqr']+1.0)\n",
    "    big_noCat['raw_value']=big_noCat['value']\n",
    "    big_noCat['value']=np.log(big_noCat['value']+1.0)\n",
    "    \n",
    "    big_noCat['standardize']=((big_noCat['value']-big_noCat['median'])/big_noCat['iqr']).fillna(0) #standardize is log standardized\n",
    "\n",
    "    #making an ordinal df to concat on\n",
    "    ord_df=big_df.loc[big_df.loc[:,'label'].isin(ordinal+vaso_active),:].copy()\n",
    "    ord_df['raw_value']=ord_df['value']\n",
    "    ord_df['standardize']=ord_df['value']\n",
    "    ord_df['median']=None\n",
    "    ord_df['iqr']=None\n",
    "\n",
    "    big_noCat=pd.concat([big_noCat,ord_df], sort=False)\n",
    "    \n",
    "    #making all ordinal values in standardize equal to unstandardized\n",
    "    big_noCat.loc[big_noCat['label'].isin(ordinal+vaso_active),'standardize']=big_noCat.loc[big_noCat['label'].isin(ordinal+vaso_active),'value']  #do i need to add sparse?\n",
    "    #ig_noCat.head()\n",
    "    \n",
    "    big_noCat['standardize']= big_noCat['standardize'].apply(pd.to_numeric, args=('coerce',)) #errors occuring downstream due to not having numeric, trying this 4/18/19\n",
    "    \n",
    "    ##last step, combining vasoactives into 1 feature\n",
    "    big_noCat=combine_vasoactives(big_noCat, median_label)  \n",
    "\n",
    "    return(big_noCat, big_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Passing integers to fillna is deprecated, will raise a TypeError in a future version.  To retain the old behavior, pass pd.Timedelta(seconds=n) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "noCat_df_train, cat_df_train = standardization_fxn(big_df_train)\n",
    "noCat_df_test, cat_df_test = standardization_fxn(big_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 601 Âµs\n"
     ]
    }
   ],
   "source": [
    "#noCat_df_train[noCat_df_train['label']=='any_vasoactives'].head()#.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggregation1:\n",
    "### clincally guided min/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.66 ms\n"
     ]
    }
   ],
   "source": [
    "hi_value= [#'bands',\n",
    "'bilirubin',\n",
    "'bun',\n",
    "'chloride',\n",
    "'creatinine',\n",
    "'daily_sofa',\n",
    "'glucose',\n",
    "'heartrate',\n",
    "'inr',\n",
    "'lactate',\n",
    "#'pco2',\n",
    "'potassium',\n",
    "'ptt',\n",
    "'resprate',\n",
    "'temperature',\n",
    "'weight', 'rrt', \n",
    "'phenylephrine', 'norepinephrine', 'vasopressin', 'dobutamine', 'dopamine', 'epinephrine',  #added this and removed individual vasoactive 5/3/19\n",
    "'yearsold','leukocyte','nitrite','vent_recieved','o2_flow', \n",
    "'any_vasoactives', #added this and removed individual vasoactive 5/3/19\n",
    "'sum_elix', #added 6/4/19\n",
    "'cancer_elix'  ]#added 6/4/19\n",
    "\n",
    "low_value=['bicarbonate',\n",
    "'diasbp',\n",
    "'hemoglobin',\n",
    "'meanartpress',\n",
    "'mingcs',\n",
    "'ph',\n",
    "'platelet',\n",
    "'spo2',\n",
    "'sysbp']\n",
    "\n",
    "both_value=['calcium',\n",
    "'sodium',\n",
    "'wbc']\n",
    "\n",
    "#important_ordinal=[\"any_vasoactives\"]\n",
    "important_onetime=['yearsold','weight','pao2fio2ratio', 'pco2','bands'] #added pco2 and bands here, removed them above 06/14/19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['daily_sofa', 'sum_elix', 'lactate', 'mingcs', 'diasbp',\n",
       "       'heartrate', 'meanartpress', 'resprate', 'spo2', 'sysbp',\n",
       "       'temperature', 'hemoglobin', 'platelet', 'wbc', 'calcium',\n",
       "       'glucose', 'ph', 'bicarbonate', 'bun', 'chloride', 'creatinine',\n",
       "       'inr', 'potassium', 'ptt', 'sodium', 'bilirubin', 'cancer_elix',\n",
       "       'dobutamine', 'dopamine', 'epinephrine', 'norepinephrine',\n",
       "       'o2_flow', 'pao2fio2ratio', 'pco2', 'phenylephrine', 'rrt',\n",
       "       'vasopressin', 'vent_recieved', 'bands', 'leukocyte', 'nitrite',\n",
       "       'any_vasoactives'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 108 ms\n"
     ]
    }
   ],
   "source": [
    "noCat_df_train['label'].unique()#noCat_df_train['label']=='any_vasoactives'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running the min/max aggregations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 78.9 ms\n"
     ]
    }
   ],
   "source": [
    "def merge_cat_agg(num_df, cat_df, ):\n",
    "    \"\"\"\n",
    "    merges the categorical and aggregated dataframes together. \n",
    "    \"\"\"\n",
    "    \n",
    "    worst_df=pd.merge(num_df, cat_df, left_on='icustay_id', right_on='icustay_id',how='left')\n",
    "    worst_df['ethnicity']=worst_df['ethnicity'].astype(\"category\")\n",
    "    worst_df['gender']=worst_df['gender'].astype(\"category\")\n",
    "    \n",
    "    return(worst_df)\n",
    "\n",
    "def clin_agg(big_noCat, big_cat,big_df, values=\"standardize\"):\n",
    "    \"\"\"\n",
    "    clincally guided aggregations.\n",
    "    \n",
    "    values= choose here if want to use standardization or raw values.\n",
    "    \n",
    "    note: getting two minor errors, could use some cleaning up at later date.\n",
    "    \"\"\"\n",
    "    global hi_value, low_value, both_value, important_onetime\n",
    "    #max aggregation for selected variables\n",
    "    big_max= big_noCat.loc[big_noCat.loc[:,'label'].isin(hi_value),:]\n",
    "    table = pd.pivot_table(big_max, values=values, columns='label', index=['icustay_id'],aggfunc=max, dropna=False)\n",
    "    \n",
    "    #min aggregation for selected variables\n",
    "    big_min= big_noCat.loc[big_noCat.loc[:,'label'].isin(low_value),:]\n",
    "    table2 = pd.pivot_table(big_min, values=values, columns='label', index=['icustay_id'],aggfunc=min, dropna=False)\n",
    "    \n",
    "    #max&min aggregation for selected variables\n",
    "    big_both= big_noCat.loc[big_noCat.loc[:,'label'].isin(both_value),:]\n",
    "    table3 = pd.pivot_table(big_both, values=values, columns='label', index=['icustay_id'],aggfunc=[max,min], dropna=False)\n",
    "    \n",
    "    #first left join all different continuous aggregations together. \n",
    "    worst_df=pd.merge(table.reset_index(), table2.reset_index(), how='left')\n",
    "    worst_df=pd.merge(worst_df, table3.reset_index(), left_on='icustay_id', right_on='icustay_id',how='left')\n",
    "    \n",
    "    ### formatting categorical to wide format to match the tables/worst_df\n",
    "    big_cat= big_cat.pivot(\n",
    "    index='icustay_id',\n",
    "    values='value',\n",
    "    columns='label').reset_index() #need to convert to wide format. should be one row per icustay per time. \n",
    "    \n",
    "    ## merging the categorical and aggregated dataframes together. \n",
    "    worst_df=merge_cat_agg(worst_df, big_cat) #using max/min aggregates \n",
    "\n",
    "    #adding important one_time values to final aggregated\n",
    "    agg_remaining= big_df.loc[big_df.loc[:,'label'].isin(important_onetime),:]\n",
    "    agg_table2 = pd.pivot_table(agg_remaining, values='value', columns='label', index=['icustay_id'],aggfunc=[max], dropna=False) \n",
    "    agg_table2.columns = agg_table2.columns.get_level_values(1)\n",
    "    agg_table2=agg_table2.reset_index()\n",
    "    agg_table2.head()#.rename(columns={})\n",
    "\n",
    "    worst_df=pd.merge(worst_df, agg_table2, how='left')\n",
    "    return(worst_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/pandas/core/reshape/merge.py:522: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/pandas/core/generic.py:3812: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  new_axis = axis.drop(labels, errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "worst_df_train=clin_agg(noCat_df_train, cat_df_train,big_df_train, values=\"standardize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/pandas/core/reshape/merge.py:522: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/pandas/core/generic.py:3812: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  new_axis = axis.drop(labels, errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 28.2 s\n"
     ]
    }
   ],
   "source": [
    "worst_df_test=clin_agg(noCat_df_test, cat_df_test, big_df_test, values=\"standardize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>any_vasoactives</th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>bun</th>\n",
       "      <th>cancer_elix</th>\n",
       "      <th>chloride</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>daily_sofa</th>\n",
       "      <th>dobutamine</th>\n",
       "      <th>dopamine</th>\n",
       "      <th>...</th>\n",
       "      <th>(min, calcium)</th>\n",
       "      <th>(min, sodium)</th>\n",
       "      <th>(min, wbc)</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>bands</th>\n",
       "      <th>pao2fio2ratio</th>\n",
       "      <th>pco2</th>\n",
       "      <th>weight</th>\n",
       "      <th>yearsold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.316749</td>\n",
       "      <td>asian</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt;10</td>\n",
       "      <td>(475, 3000]</td>\n",
       "      <td>absent</td>\n",
       "      <td>51.2</td>\n",
       "      <td>32.9889590780034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0407698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0370891</td>\n",
       "      <td>-0.234465</td>\n",
       "      <td>-0.178747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012492</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>absent</td>\n",
       "      <td>(200, 333]</td>\n",
       "      <td>&lt;50</td>\n",
       "      <td>62.0</td>\n",
       "      <td>84.7281861738535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200033.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0822292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00850716</td>\n",
       "      <td>-0.234465</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.505654</td>\n",
       "      <td>-0.020446</td>\n",
       "      <td>-0.220988</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>absent</td>\n",
       "      <td>(475, 3000]</td>\n",
       "      <td>absent</td>\n",
       "      <td>74.0</td>\n",
       "      <td>67.1450990252744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119501</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011917</td>\n",
       "      <td>-0.188701</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>absent</td>\n",
       "      <td>(475, 3000]</td>\n",
       "      <td>absent</td>\n",
       "      <td>79.0</td>\n",
       "      <td>74.934136467919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.356425</td>\n",
       "      <td>0.198543</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0219907</td>\n",
       "      <td>2.30743</td>\n",
       "      <td>0.503859</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135281</td>\n",
       "      <td>-0.004030</td>\n",
       "      <td>-0.255600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>absent</td>\n",
       "      <td>(475, 3000]</td>\n",
       "      <td>absent</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   icustay_id any_vasoactives bilirubin        bun cancer_elix    chloride  \\\n",
       "0    200012.0             0.0       NaN        NaN           0         NaN   \n",
       "1    200014.0             0.0       NaN  0.0407698           0   0.0370891   \n",
       "2    200033.0             1.0       NaN -0.0822292           1  0.00850716   \n",
       "3    200036.0             0.0       NaN   0.119501           0    0.020977   \n",
       "4    200055.0             0.0 -0.356425   0.198543           0  -0.0219907   \n",
       "\n",
       "  creatinine daily_sofa dobutamine dopamine  ... (min, calcium) (min, sodium)  \\\n",
       "0        NaN  -0.430677          0        0  ...            NaN           NaN   \n",
       "1  -0.234465  -0.178747          0        0  ...      -0.044882      0.000000   \n",
       "2  -0.234465  -0.430677          0        0  ...      -0.505654     -0.020446   \n",
       "3          0  -0.430677          0        0  ...            NaN      0.011917   \n",
       "4    2.30743   0.503859          0        0  ...      -0.135281     -0.004030   \n",
       "\n",
       "  (min, wbc)          ethnicity gender   bands pao2fio2ratio    pco2 weight  \\\n",
       "0  -0.316749              asian      0     >10   (475, 3000]  absent   51.2   \n",
       "1   0.012492      unknown/other      1  absent    (200, 333]     <50   62.0   \n",
       "2  -0.220988  white/nonhispanic      1  absent   (475, 3000]  absent   74.0   \n",
       "3  -0.188701  white/nonhispanic      1  absent   (475, 3000]  absent   79.0   \n",
       "4  -0.255600                NaN    NaN  absent   (475, 3000]  absent   56.0   \n",
       "\n",
       "           yearsold  \n",
       "0  32.9889590780034  \n",
       "1  84.7281861738535  \n",
       "2  67.1450990252744  \n",
       "3   74.934136467919  \n",
       "4               NaN  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 25.4 ms\n"
     ]
    }
   ],
   "source": [
    "worst_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count            7205\n",
       "unique              4\n",
       "top       (475, 3000]\n",
       "freq             5207\n",
       "Name: pao2fio2ratio, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.8 ms\n"
     ]
    }
   ],
   "source": [
    "worst_df_train['pao2fio2ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['icustay_id',\n",
       " 'any_vasoactives',\n",
       " 'bilirubin',\n",
       " 'bun',\n",
       " 'cancer_elix',\n",
       " 'chloride',\n",
       " 'creatinine',\n",
       " 'daily_sofa',\n",
       " 'dobutamine',\n",
       " 'dopamine',\n",
       " 'epinephrine',\n",
       " 'glucose',\n",
       " 'heartrate',\n",
       " 'inr',\n",
       " 'lactate',\n",
       " 'leukocyte',\n",
       " 'nitrite',\n",
       " 'norepinephrine',\n",
       " 'o2_flow',\n",
       " 'phenylephrine',\n",
       " 'potassium',\n",
       " 'ptt',\n",
       " 'resprate',\n",
       " 'rrt',\n",
       " 'sum_elix',\n",
       " 'temperature',\n",
       " 'vasopressin',\n",
       " 'vent_recieved',\n",
       " 'bicarbonate',\n",
       " 'diasbp',\n",
       " 'hemoglobin',\n",
       " 'meanartpress',\n",
       " 'mingcs',\n",
       " 'ph',\n",
       " 'platelet',\n",
       " 'spo2',\n",
       " 'sysbp',\n",
       " ('max', 'calcium'),\n",
       " ('max', 'sodium'),\n",
       " ('max', 'wbc'),\n",
       " ('min', 'calcium'),\n",
       " ('min', 'sodium'),\n",
       " ('min', 'wbc'),\n",
       " 'ethnicity',\n",
       " 'gender',\n",
       " 'bands',\n",
       " 'pao2fio2ratio',\n",
       " 'pco2',\n",
       " 'weight',\n",
       " 'yearsold']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.46 ms\n"
     ]
    }
   ],
   "source": [
    "list(worst_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    7070\n",
       "1.0     135\n",
       "Name: vasopressin, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.61 ms\n"
     ]
    }
   ],
   "source": [
    "worst_df_train['vasopressin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 386 Âµs\n"
     ]
    }
   ],
   "source": [
    "#worst_df_train['vasopressin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absent    6254\n",
       "<10        607\n",
       ">10        344\n",
       "Name: bands, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.08 ms\n"
     ]
    }
   ],
   "source": [
    "worst_df_train['bands'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absent    4752\n",
       "<50       1752\n",
       ">50        701\n",
       "Name: pco2, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.32 ms\n"
     ]
    }
   ],
   "source": [
    "worst_df_train['pco2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/cleaned_merged_agg/48_hr_window/\n",
      "time: 574 ms\n"
     ]
    }
   ],
   "source": [
    "save_df(worst_df_train, 'train')\n",
    "save_df(worst_df_test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.08 ms\n"
     ]
    }
   ],
   "source": [
    "del worst_df_train, worst_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 466 Âµs\n"
     ]
    }
   ],
   "source": [
    "#wd+'/data/processed/merged/{}_worst_df_train_preImp_{}.csv'.format(date,timewindowdays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 411 Âµs\n"
     ]
    }
   ],
   "source": [
    "#print(wd+'/data/processed/merged/{}_worstdf_preImp{}.csv'.format(date,timewindowdays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.36 ms\n"
     ]
    }
   ],
   "source": [
    "# class onehot(TransformerMixin):\n",
    "#     def __init__(self, cols_to_transform):\n",
    "#         self.cols_to_transform=cols_to_transform\n",
    "        \n",
    "#     def transform(self,df ):\n",
    "#         data = pd.get_dummies(df, columns = self.cols_to_transform, drop_first=True)\n",
    "#         return(data)\n",
    "    \n",
    "#     def fit(self, *_):\n",
    "#         return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
