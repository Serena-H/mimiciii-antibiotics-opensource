{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the purpose of this notebook is to take the big dataframe created in 07.01-baseline_data_merging, and make an aggregate we can use for our baseline \"worst case\" scenario model. This will then be fed into R, where we will use the MICE package to impute data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "changelog:\n",
    "\n",
    "* 4/16/19: added newagg\n",
    "* 4/17/19: reformatted the ordering of how code runs, and variable names. added aggregation #3.\n",
    "* 4/19/19: changed the standardizing so that log(x+1) is now applied prior to standardization. also removed ordinal variables from standardizing algorithm and concat them in later with median 0 and iqr 1 so standardize value is either 0 or 1. values from ordinal are not log transformed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "06/14/19:\n",
    "# prior to this point my pipeline:\n",
    "1. first median standardized\n",
    "2. aggregated\n",
    "3. converted to 2class\n",
    "4. train/test split\n",
    "5. imputed\n",
    "\n",
    "\n",
    "# a big change will happen in this notebook, I will first:\n",
    "1. convert to two class (c-/abshort &c+/ablong)\n",
    "2. split the train and test set\n",
    "3. median standardize\n",
    "4. aggregate\n",
    "5. impute\n",
    "BEFORE I AGGREGATE and median standardize, as some information may be leaking from the train/test set as i had it previously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## last run: 6/14/19: sensitivity analysis 3day timewindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/ipykernel_launcher.py:11: DeprecationWarning: The 'cachedir' parameter has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "You provided \"cachedir='/tmp'\", use \"location='/tmp'\" instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from sklearn.externals.joblib import Memory\n",
    "from sklearn.model_selection import train_test_split\n",
    "memory = Memory(cachedir='/tmp', verbose=0)\n",
    "#@memory.cache above any def fxn.\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1024,\n",
    "        'height': 768,\n",
    "        'scroll': True,\n",
    "})\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.29 s\n"
     ]
    }
   ],
   "source": [
    "#patients of interest from rotation_cohort_generation\n",
    "from parameters import final_pt_df_v, date, repository_path\n",
    "\n",
    "#patients of interest from rotation_cohort_generation\n",
    "final_pt_df2 = final_pt_df_v #pd.read_csv('/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-modeling/data/raw/csv/%s_final_pt_df2.csv'%(most_updated_patient_df), index_col=0)\n",
    "del(final_pt_df_v)\n",
    "\n",
    "patients= list(final_pt_df2['subject_id'].unique())\n",
    "hadm_id= list(final_pt_df2['hadm_id'].unique())\n",
    "icustay_id= list(final_pt_df2['icustay_id'].unique())\n",
    "icustay_id= [int(x) for x in icustay_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15412"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.65 ms\n"
     ]
    }
   ],
   "source": [
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "save_path= str(repository_path)+'/data/cleaned_merged_agg/'\n",
    "def save_df(df, df_name='default', save_path=save_path, add_subfolder=False):\n",
    "    #uses the date and supplied df name and saves to the savepath specified above.\n",
    "    if df_name == 'default':\n",
    "        df_name= \"%s\"%(df)\n",
    "    \n",
    "    address=save_path+'%s/'%(folder)\n",
    "    if not os.path.exists(address):\n",
    "        print(address)\n",
    "        os.makedirs(address)\n",
    "    pd.DataFrame(df).to_csv(Path(address+'%s_%s_cleaned_merged_agg.csv' %(date, df_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.13 ms\n"
     ]
    }
   ],
   "source": [
    "from parameters import lower_window, upper_window, folder, date, time_col, time_var, patient_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15 s\n"
     ]
    }
   ],
   "source": [
    "#importing cleaned_merged big_df\n",
    "allFiles = glob.glob(str(repository_path)+ '/data/cleaned_merged/%s/'%(folder) + \"{}_*.csv\".format(date))\n",
    "\n",
    "df_list=[]\n",
    "for element in allFiles:\n",
    "    df_list.append(element.split('{}_'.format(date))[1].split('_prepped.csv')[0]) #making an list of all my dataframes in order they appear in file\n",
    "\n",
    "i=0\n",
    "for name in df_list:\n",
    "    big_df = pd.read_csv(allFiles[i],  index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 489 ms\n"
     ]
    }
   ],
   "source": [
    "#quick housekeeping addition to accomidate older generated data\n",
    "if len(big_df.loc[big_df['label']==\"pao2/fio2\",'label'])>1:\n",
    "    big_df.loc[big_df['label']==\"pao2/fio2\",'label']=\"pao2fio2ratio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>t_0</th>\n",
       "      <th>value</th>\n",
       "      <th>label</th>\n",
       "      <th>uom</th>\n",
       "      <th>delta</th>\n",
       "      <th>source</th>\n",
       "      <th>subject_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1124778</th>\n",
       "      <td>200001.0</td>\n",
       "      <td>2181-11-26</td>\n",
       "      <td>absent</td>\n",
       "      <td>bands</td>\n",
       "      <td>y/n</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>labs</td>\n",
       "      <td>55973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16144</th>\n",
       "      <td>200001.0</td>\n",
       "      <td>2181-11-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>cancer_elix</td>\n",
       "      <td>y/n</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>cancer_elix</td>\n",
       "      <td>55973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27523</th>\n",
       "      <td>200001.0</td>\n",
       "      <td>2181-11-26</td>\n",
       "      <td>5</td>\n",
       "      <td>daily_sofa</td>\n",
       "      <td>daily_sofa_score</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>sofa</td>\n",
       "      <td>55973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15332</th>\n",
       "      <td>200001.0</td>\n",
       "      <td>2181-11-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dobutamine</td>\n",
       "      <td>y/n</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>dobutamine</td>\n",
       "      <td>55973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20112</th>\n",
       "      <td>200001.0</td>\n",
       "      <td>2181-11-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dopamine</td>\n",
       "      <td>y/n</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>dopamine</td>\n",
       "      <td>55973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         icustay_id         t_0   value        label               uom  \\\n",
       "1124778    200001.0  2181-11-26  absent        bands               y/n   \n",
       "16144      200001.0  2181-11-26     0.0  cancer_elix               y/n   \n",
       "27523      200001.0  2181-11-26       5   daily_sofa  daily_sofa_score   \n",
       "15332      200001.0  2181-11-26     0.0   dobutamine               y/n   \n",
       "20112      200001.0  2181-11-26     0.0     dopamine               y/n   \n",
       "\n",
       "                             delta       source  subject_id  \n",
       "1124778  0 days 00:00:00.000000000         labs       55973  \n",
       "16144    0 days 00:00:00.000000000  cancer_elix       55973  \n",
       "27523    0 days 00:00:00.000000000         sofa       55973  \n",
       "15332    0 days 00:00:00.000000000   dobutamine       55973  \n",
       "20112    0 days 00:00:00.000000000     dopamine       55973  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23.4 ms\n"
     ]
    }
   ],
   "source": [
    "big_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dobutamine</th>\n",
       "      <td>21508</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nitrite</th>\n",
       "      <td>19633</td>\n",
       "      <td>2</td>\n",
       "      <td>Neg/Not_tested</td>\n",
       "      <td>19049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norepinephrine</th>\n",
       "      <td>48691</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o2_flow</th>\n",
       "      <td>20048</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>12904</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>7021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epinephrine</th>\n",
       "      <td>22185</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dopamine</th>\n",
       "      <td>26457</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phenylephrine</th>\n",
       "      <td>38826</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leukocyte</th>\n",
       "      <td>19633</td>\n",
       "      <td>2</td>\n",
       "      <td>Neg/Not_tested</td>\n",
       "      <td>16385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rrt</th>\n",
       "      <td>19633</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cancer_elix</th>\n",
       "      <td>19633</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vasopressin</th>\n",
       "      <td>24235</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pco2</th>\n",
       "      <td>19633</td>\n",
       "      <td>3</td>\n",
       "      <td>absent</td>\n",
       "      <td>11802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vent_recieved</th>\n",
       "      <td>19471</td>\n",
       "      <td>3</td>\n",
       "      <td>Mech</td>\n",
       "      <td>10156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bands</th>\n",
       "      <td>19633</td>\n",
       "      <td>3</td>\n",
       "      <td>absent</td>\n",
       "      <td>16231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ethnicity</th>\n",
       "      <td>12904</td>\n",
       "      <td>5</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>9332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mingcs</th>\n",
       "      <td>9150</td>\n",
       "      <td>13</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum_elix</th>\n",
       "      <td>22281</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daily_sofa</th>\n",
       "      <td>52281</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>9490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bicarbonate</th>\n",
       "      <td>85733</td>\n",
       "      <td>58</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resprate</th>\n",
       "      <td>1351346</td>\n",
       "      <td>79</td>\n",
       "      <td>20.0</td>\n",
       "      <td>105261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yearsold</th>\n",
       "      <td>12904</td>\n",
       "      <td>79</td>\n",
       "      <td>300.0</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chloride</th>\n",
       "      <td>94196</td>\n",
       "      <td>84</td>\n",
       "      <td>106.0</td>\n",
       "      <td>6090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sodium</th>\n",
       "      <td>98474</td>\n",
       "      <td>85</td>\n",
       "      <td>138.0</td>\n",
       "      <td>8717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spo2</th>\n",
       "      <td>1225740</td>\n",
       "      <td>104</td>\n",
       "      <td>100.0</td>\n",
       "      <td>285825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>potassium</th>\n",
       "      <td>119914</td>\n",
       "      <td>105</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ph</th>\n",
       "      <td>99853</td>\n",
       "      <td>106</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>13372</td>\n",
       "      <td>134</td>\n",
       "      <td>177.8</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hemoglobin</th>\n",
       "      <td>90138</td>\n",
       "      <td>170</td>\n",
       "      <td>9.6</td>\n",
       "      <td>2224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creatinine</th>\n",
       "      <td>85693</td>\n",
       "      <td>190</td>\n",
       "      <td>0.7</td>\n",
       "      <td>7150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inr</th>\n",
       "      <td>55455</td>\n",
       "      <td>199</td>\n",
       "      <td>1.2</td>\n",
       "      <td>8161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calcium</th>\n",
       "      <td>42744</td>\n",
       "      <td>199</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bun</th>\n",
       "      <td>85334</td>\n",
       "      <td>200</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heartrate</th>\n",
       "      <td>1278100</td>\n",
       "      <td>211</td>\n",
       "      <td>80.0</td>\n",
       "      <td>33702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diasbp</th>\n",
       "      <td>1249366</td>\n",
       "      <td>213</td>\n",
       "      <td>56.0</td>\n",
       "      <td>39556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sysbp</th>\n",
       "      <td>1255229</td>\n",
       "      <td>243</td>\n",
       "      <td>108.0</td>\n",
       "      <td>23274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lactate</th>\n",
       "      <td>49875</td>\n",
       "      <td>338</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bilirubin</th>\n",
       "      <td>24769</td>\n",
       "      <td>483</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanartpress</th>\n",
       "      <td>1269382</td>\n",
       "      <td>601</td>\n",
       "      <td>72.0</td>\n",
       "      <td>33596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temperature</th>\n",
       "      <td>384458</td>\n",
       "      <td>670</td>\n",
       "      <td>36.6666666666667</td>\n",
       "      <td>10228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>glucose</th>\n",
       "      <td>310354</td>\n",
       "      <td>759</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wbc</th>\n",
       "      <td>76976</td>\n",
       "      <td>881</td>\n",
       "      <td>8.8</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platelet</th>\n",
       "      <td>80029</td>\n",
       "      <td>991</td>\n",
       "      <td>108.0</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pao2fio2ratio</th>\n",
       "      <td>19633</td>\n",
       "      <td>1161</td>\n",
       "      <td>476.0</td>\n",
       "      <td>11803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ptt</th>\n",
       "      <td>58409</td>\n",
       "      <td>1277</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>17867</td>\n",
       "      <td>1573</td>\n",
       "      <td>70.0</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count unique                top    freq\n",
       "label                                                    \n",
       "dobutamine        21508      2                0.0   19314\n",
       "nitrite           19633      2     Neg/Not_tested   19049\n",
       "norepinephrine    48691      2                1.0   32954\n",
       "o2_flow           20048      2                0.0   18543\n",
       "gender            12904      2                  M    7021\n",
       "epinephrine       22185      2                0.0   19166\n",
       "dopamine          26457      2                0.0   18468\n",
       "phenylephrine     38826      2                1.0   22473\n",
       "leukocyte         19633      2     Neg/Not_tested   16385\n",
       "rrt               19633      2                0.0   17845\n",
       "cancer_elix       19633      2                0.0   17212\n",
       "vasopressin       24235      2                0.0   19061\n",
       "pco2              19633      3             absent   11802\n",
       "vent_recieved     19471      3               Mech   10156\n",
       "bands             19633      3             absent   16231\n",
       "ethnicity         12904      5  white/nonhispanic    9332\n",
       "mingcs             9150     13               15.0    3138\n",
       "sum_elix          22281     14                0.0   14005\n",
       "daily_sofa        52281     24                  1    9490\n",
       "bicarbonate       85733     58               24.0    7135\n",
       "resprate        1351346     79               20.0  105261\n",
       "yearsold          12904     79              300.0     771\n",
       "chloride          94196     84              106.0    6090\n",
       "sodium            98474     85              138.0    8717\n",
       "spo2            1225740    104              100.0  285825\n",
       "potassium        119914    105                4.0    8813\n",
       "ph                99853    106                7.4    5287\n",
       "height            13372    134              177.8     870\n",
       "hemoglobin        90138    170                9.6    2224\n",
       "creatinine        85693    190                0.7    7150\n",
       "inr               55455    199                1.2    8161\n",
       "calcium           42744    199               1.13    2150\n",
       "bun               85334    200               14.0    2549\n",
       "heartrate       1278100    211               80.0   33702\n",
       "diasbp          1249366    213               56.0   39556\n",
       "sysbp           1255229    243              108.0   23274\n",
       "lactate           49875    338                1.2    2457\n",
       "bilirubin         24769    483                0.4    1917\n",
       "meanartpress    1269382    601               72.0   33596\n",
       "temperature      384458    670   36.6666666666667   10228\n",
       "glucose          310354    759              110.0    3436\n",
       "wbc               76976    881                8.8     666\n",
       "platelet          80029    991              108.0     353\n",
       "pao2fio2ratio     19633   1161              476.0   11803\n",
       "ptt               58409   1277              150.0    1293\n",
       "weight            17867   1573               70.0     322"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.38 s\n"
     ]
    }
   ],
   "source": [
    "#overview of all variables and formats\n",
    "big_df.groupby('label')['value'].describe().sort_values('unique')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initial data prep\n",
    "* convert to two class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.8 ms\n"
     ]
    }
   ],
   "source": [
    "#convert to two class\n",
    "final_pt_df2['final_bin'].unique()\n",
    "two_classes=['C_neg/A_partial','C_pos/A_full']\n",
    "two_class_icu=final_pt_df2.loc[final_pt_df2.loc[:,\"final_bin\"].isin(two_classes),['icustay_id','subject_id','final_bin']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.89 s\n"
     ]
    }
   ],
   "source": [
    "big_df=big_df.loc[big_df['icustay_id'].isin(list(two_class_icu['icustay_id'])),:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10305"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 68.8 ms\n"
     ]
    }
   ],
   "source": [
    "len(big_df)\n",
    "big_df['icustay_id'].nunique() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### roundabout way of sampling train/test set so that each subject is only in either train or test:\n",
    "* To ensure a single patient did not end up with samples in both training and testing sets, individual patients (subject_id's) are kept together when performing the stratified train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.05 s\n"
     ]
    }
   ],
   "source": [
    "# label each subject_id with the max of the two classes. \n",
    "two_class_pt=two_class_icu.copy()\n",
    "two_class_pt['final_bin']=pd.factorize(two_class_pt['final_bin'])[0]\n",
    "two_class_maxsub=two_class_pt.loc[two_class_pt.groupby('subject_id')['final_bin'].idxmax(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.73 s\n"
     ]
    }
   ],
   "source": [
    "# 70/30 train/test set split with 12345=seed, splitting on max final bin of each SUBJECT_ID\n",
    "train, test = train_test_split(two_class_maxsub, test_size=0.3, random_state=12345, \n",
    "                               stratify=two_class_maxsub['final_bin'])\n",
    "# generate list of each SUBJECT_ID in each split\n",
    "train_subject=list(train['subject_id'])\n",
    "test_subject=list(test['subject_id'])\n",
    "\n",
    "#filtering big_df on train subjects and test subjects to get my train/test splits.\n",
    "big_df_train= big_df.loc[big_df.loc[:,'subject_id'].isin(train_subject),:].copy()\n",
    "big_df_test= big_df.loc[big_df.loc[:,'subject_id'].isin(test_subject),:].copy()\n",
    "del big_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.46 ms\n"
     ]
    }
   ],
   "source": [
    "# #converting venttype to category\n",
    "# big_df.loc[big_df.loc[:,'label']=='vent_recieved','value']= big_df.loc[big_df.loc[:,'label']=='vent_recieved','value'].astype('category')\n",
    "# #big_df.loc[big_df.loc[:,'label']=='vent_recieved','value'].apply(astype('category'))\n",
    "# big_df.loc[big_df.loc[:,'label']=='vent_recieved','value'] = pd.Categorical(big_df.loc[big_df.loc[:,'label']=='vent_recieved','value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 66 ms\n"
     ]
    }
   ],
   "source": [
    "def category_mapper(big_df):\n",
    "    \n",
    "    \"\"\"\n",
    "    this function is designed to map some variables currently in categorical format into a ordinal category for the following aggregations. the variables are eventually converted to one-hot-encoding prior to modeling. \n",
    "    \"\"\"\n",
    "    #converting categories to integers\n",
    "    mapper={'Mech':2 , 'Oxygen': 1, 'None': 0}\n",
    "    big_df.loc[big_df.loc[:,'label']=='vent_recieved','value']=big_df.loc[big_df.loc[:,'label']=='vent_recieved','value'].replace(mapper).copy()\n",
    "\n",
    "    #gender_index=pd.factorize(big_df.loc[big_df.loc[:,'label']=='gender','value'])[1]\n",
    "    mapper={'F':0 , 'M': 1}\n",
    "    big_df.loc[big_df.loc[:,'label']=='gender','value']=big_df.loc[big_df.loc[:,'label']=='gender','value'].replace(mapper).copy()\n",
    "\n",
    "    #leukocyte_index=pd.factorize(big_df.loc[big_df.loc[:,'label']=='leukocyte','value'])[1]\n",
    "    mapper={'Neg/Not_tested':0 , 'pos': 1}\n",
    "    big_df.loc[big_df.loc[:,'label']=='leukocyte','value']=big_df.loc[big_df.loc[:,'label']=='leukocyte','value'].replace(mapper).copy()\n",
    "    #     pd.factorize(big_df.loc[big_df.loc[:,'label']=='leukocyte','value'])[0] \n",
    "\n",
    "    #nitrite_index=pd.factorize(big_df.loc[big_df.loc[:,'label']=='nitrite','value'])[1]\n",
    "    mapper={'Neg/Not_tested':0 , 'pos': 1}\n",
    "    big_df.loc[big_df.loc[:,'label']=='nitrite','value']=big_df.loc[big_df.loc[:,'label']=='nitrite','value'].replace(mapper).copy()\n",
    "    #     pd.factorize(big_df.loc[big_df.loc[:,'label']=='nitrite','value'])[0] \n",
    "    \n",
    "    # changing pao2/fio2 ratio to a category\n",
    "    \"\"\"\n",
    "    A PaO2/FiO2 ratio less than or equal to 200 is necessary for the diagnosis of acute respiratory distress syndrome by the AECC criteria.[6] \n",
    "    The more recent Berlin criteria defines mild ARDS at a ratio of <300.\n",
    "\n",
    "    A PaO2/FiO2 ratio less than or equal to 250 is one of the minor criteria for severe community acquired pneumonia (i.e., possible indication for inpatient treatment).\n",
    "\n",
    "    A PaO2/FiO2 ratio less than or equal to 333 is one of the variables in the SMART-COP risk score for intensive respiratory or vasopressor support in community-acquired pneumonia.\n",
    "    \"\"\"\n",
    "    \n",
    "    pd.to_numeric(big_df[big_df['label']==\"pao2fio2ratio\"]['value'])\n",
    "    labels= ['0-200', '201-333', \"334-475\",\"476+\"]\n",
    "    bins = pd.IntervalIndex.from_tuples([(0, 200), (200, 333), (333, 475),(475,3000)])\n",
    "\n",
    "    big_df.loc[big_df['label']==\"pao2fio2ratio\",'value']=pd.cut(pd.to_numeric(big_df.loc[big_df['label']==\"pao2fio2ratio\",'value']), bins,right=False, labels=labels)\n",
    "    big_df.loc[big_df['label']==\"pao2fio2ratio\",'value'].value_counts()\n",
    "    return(big_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.03 s\n"
     ]
    }
   ],
   "source": [
    "big_df_train=category_mapper(big_df_train)\n",
    "big_df_test=category_mapper(big_df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3394\n",
       "2    3302\n",
       "0     439\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 145 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='vent_recieved','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2628\n",
       "0    2147\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 147 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='gender','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absent    6156\n",
       "<10        687\n",
       ">10        362\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 150 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='bands','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absent    4699\n",
       "<50       1740\n",
       ">50        766\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 149 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='pco2','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2628\n",
       "0    2147\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 151 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='gender','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475, 3000]    2199\n",
       "(0, 200]        320\n",
       "(333, 475]      304\n",
       "(200, 333]      277\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 72.3 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_test.loc[big_df_test.loc[:,'label']=='pao2fio2ratio','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(475, 3000]    5124\n",
       "(0, 200]        756\n",
       "(333, 475]      667\n",
       "(200, 333]      658\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 171 ms\n"
     ]
    }
   ],
   "source": [
    "big_df_train.loc[big_df_train.loc[:,'label']=='pao2fio2ratio','value'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calc median/iqr for standardization\n",
    "take all non-categorical variables for HEALTHY PATIENTS and calculate the median and IQR for them. then will use this to make z scores via:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Z=\\frac{(X-\\widetilde{X}_{-/short})}{(IQR_{-/short})}$$ where $\\widetilde{X}_{-/short}$ is the median value of the patients with negative SSC and short duration EAT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23.5 ms\n"
     ]
    }
   ],
   "source": [
    "continuous=['daily_sofa',\n",
    "            'lactate',\n",
    "            'mingcs',\n",
    "            'diasbp',\n",
    "            'heartrate',\n",
    "            'meanartpress',\n",
    "            'resprate',\n",
    "            'sysbp',\n",
    "            'temperature',\n",
    "            'hemoglobin',\n",
    "            'platelet',\n",
    "            'wbc',\n",
    "            'calcium',\n",
    "            'glucose',\n",
    "            'ph',\n",
    "            'bicarbonate',\n",
    "            'bun',\n",
    "            'chloride',\n",
    "            'creatinine',\n",
    "            'inr',\n",
    "            'potassium',\n",
    "            'ptt',\n",
    "            'sodium',\n",
    "            'bilirubin',\n",
    "            'spo2',\n",
    "            'sum_elix']\n",
    "\n",
    "onetime=['yearsold','height','weight']\n",
    "\n",
    "vaso_active=['phenylephrine',\n",
    "            'norepinephrine',\n",
    "            'vasopressin',\n",
    "            'dobutamine',\n",
    "            'dopamine',\n",
    "            'epinephrine'] \n",
    "\n",
    "ordinal=[\n",
    "            'leukocyte',\n",
    "            'nitrite',\n",
    "            'vent_recieved',\n",
    "            'o2_flow',\n",
    "            'rrt',\n",
    "            'pao2fio2ratio',\n",
    "            'cancer_elix',\n",
    "            \"any_vasoactives\",\n",
    "            'bands', #added 6/13/19\n",
    "            'pco2' #added 6/13/19\n",
    "]\n",
    "\n",
    "categorical=[\n",
    "            \"ethnicity\",\n",
    "            'gender'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 400 ms\n"
     ]
    }
   ],
   "source": [
    "def median_label_fxn(big_df):\n",
    "    global final_pt_df2\n",
    "    \n",
    "    healthy_pt=list(final_pt_df2[final_pt_df2['final_bin']==\"C_neg/A_partial\"]['icustay_id'])\n",
    "\n",
    "    #filter to only healthy patients filter\n",
    "    ##splitting big_df, making a copy and restricting it to all values that will be usd in standardizing\n",
    "    healthy_df=big_df[big_df['label'].isin(continuous+onetime)].copy()\n",
    "    healthy_df['value']= pd.to_numeric(healthy_df['value']) #converting to numeric \n",
    "    healthy_df=healthy_df[healthy_df['icustay_id'].isin(healthy_pt)].copy() #only numerical values for cneg/ab partial pt\n",
    "    \n",
    "    #finding the last 24 hours of each healthy patient.\n",
    "    healthy_pt_end=pd.DataFrame(healthy_df.groupby(\"icustay_id\")['delta'].max())\n",
    "    healthy_pt_end[\"start\"]=healthy_pt_end['delta']- pd.to_timedelta(\"1 day 00:00:00\")\n",
    "    healthy_pt_end=healthy_pt_end.rename(columns={\"delta\":\"end\"}).reset_index()\n",
    "    healthy_df= pd.merge(healthy_df,healthy_pt_end, left_on=\"icustay_id\", right_on=\"icustay_id\", how=\"left\" ) #now have the last 24 hours annotated for each patient as start and end.\n",
    "    \n",
    "    #calculating medians and iqr for each label based on healthy patient's last 24 hours in icu\n",
    "    median_label=pd.DataFrame((healthy_df.groupby(\"label\")['value'].median())).reset_index()\n",
    "    median_label=median_label.rename(columns={'value':\"median\"})\n",
    "    iqr_label=pd.DataFrame((healthy_df.groupby(\"label\")['value'].quantile(0.75)-healthy_df.groupby(\"label\")['value'].quantile(0.25))).reset_index()\n",
    "    iqr_label=iqr_label.rename(columns={'value':\"iqr\"})\n",
    "    median_label=pd.merge(median_label,iqr_label)  #final median df\n",
    "    return(median_label)\n",
    "\n",
    "def combine_vasoactives(big_noCat, median_label):\n",
    "    global vaso_active\n",
    "    ##combining vasoactives\n",
    "    vaso_active_df=big_noCat[big_noCat['label'].isin(vaso_active)].groupby('icustay_id')['value'].max().reset_index()\n",
    "    vaso_active_df['uom']=\"y/n\"\n",
    "    vaso_active_df['label']=\"any_vasoactives\"\n",
    "    vaso_active_df['delta']=pd.to_timedelta(\"0days\")\n",
    "    vaso_active_df['source']=\"any_vasoactives\"\n",
    "\n",
    "    vaso_active_df=pd.merge(vaso_active_df, final_pt_df2[[\"icustay_id\",'subject_id',\"t_0\"]], how=\"left\", left_on=\"icustay_id\", right_on=\"icustay_id\")\n",
    "    vaso_active_df=pd.merge(vaso_active_df, median_label, how=\"left\").fillna(0)\n",
    "    vaso_active_df['standardize']=vaso_active_df['value']\n",
    "    vaso_active_df['raw_value']=vaso_active_df['value']\n",
    "    vaso_active_df.head()\n",
    "\n",
    "    # # #grabing the rest of the variables not suitable for range or mean/std\n",
    "    big_noCat=pd.concat([big_noCat, vaso_active_df], sort=False)\n",
    "    return(big_noCat)\n",
    "\n",
    "def standardization_fxn(big_df):\n",
    "    global continuous, onetime, vaso_active, ordinal, categorical\n",
    "    \n",
    "    median_label=median_label_fxn(big_df)\n",
    "    \n",
    "    ### dataformatting: convert all dtypes to a numeric type that pereserves nan. \n",
    "    #splitting categorical, ordinal and continuous\n",
    "    big_categorical= big_df.loc[big_df.loc[:,'label'].isin(categorical),:].copy() \n",
    "\n",
    "    #continuous and ordinal variables\n",
    "    big_noCat= big_df.loc[big_df.loc[:,'label'].isin(continuous),:].copy() \n",
    "    big_noCat['value']= big_noCat['value'].apply(pd.to_numeric, args=('coerce',)) #instead of convert to float, may preserve nan's better. \n",
    "    \n",
    "    ### adding a standardized value (x-median)/iqr  where median is of the last 24 hours in time window for culture neg/ ab partial patients \n",
    "    big_noCat=pd.merge(big_noCat, median_label, how=\"left\") \n",
    "    #loging values\n",
    "    big_noCat['median']= np.log(big_noCat['median']+1.0)\n",
    "    big_noCat['iqr']= np.log(big_noCat['iqr']+1.0)\n",
    "    big_noCat['raw_value']=big_noCat['value']\n",
    "    big_noCat['value']=np.log(big_noCat['value']+1.0)\n",
    "    \n",
    "    big_noCat['standardize']=((big_noCat['value']-big_noCat['median'])/big_noCat['iqr']).fillna(0) #standardize is log standardized\n",
    "\n",
    "    #making an ordinal df to concat on\n",
    "    ord_df=big_df.loc[big_df.loc[:,'label'].isin(ordinal+vaso_active),:].copy()\n",
    "    ord_df['raw_value']=ord_df['value']\n",
    "    ord_df['standardize']=ord_df['value']\n",
    "    ord_df['median']=None\n",
    "    ord_df['iqr']=None\n",
    "\n",
    "    big_noCat=pd.concat([big_noCat,ord_df], sort=False)\n",
    "    \n",
    "    #making all ordinal values in standardize equal to unstandardized\n",
    "    big_noCat.loc[big_noCat['label'].isin(ordinal+vaso_active),'standardize']=big_noCat.loc[big_noCat['label'].isin(ordinal+vaso_active),'value']  #do i need to add sparse?\n",
    "    #ig_noCat.head()\n",
    "    \n",
    "    big_noCat['standardize']= big_noCat['standardize'].apply(pd.to_numeric, args=('coerce',)) #errors occuring downstream due to not having numeric, trying this 4/18/19\n",
    "    \n",
    "    ##last step, combining vasoactives into 1 feature\n",
    "    big_noCat=combine_vasoactives(big_noCat, median_label)  \n",
    "\n",
    "    return(big_noCat, big_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/ipykernel_launcher.py:36: FutureWarning: Passing integers to fillna is deprecated, will raise a TypeError in a future version.  To retain the old behavior, pass pd.Timedelta(seconds=n) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "noCat_df_train, cat_df_train = standardization_fxn(big_df_train)\n",
    "noCat_df_test, cat_df_test = standardization_fxn(big_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 541 µs\n"
     ]
    }
   ],
   "source": [
    "#noCat_df_train[noCat_df_train['label']=='any_vasoactives'].head()#.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aggregation1:\n",
    "### clincally guided min/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "hi_value= [#'bands',\n",
    "'bilirubin',\n",
    "'bun',\n",
    "'chloride',\n",
    "'creatinine',\n",
    "'daily_sofa',\n",
    "'glucose',\n",
    "'heartrate',\n",
    "'inr',\n",
    "'lactate',\n",
    "#'pco2',\n",
    "'potassium',\n",
    "'ptt',\n",
    "'resprate',\n",
    "'temperature',\n",
    "'weight', 'rrt', \n",
    "'phenylephrine', 'norepinephrine', 'vasopressin', 'dobutamine', 'dopamine', 'epinephrine',  #added this and removed individual vasoactive 5/3/19\n",
    "'yearsold','leukocyte','nitrite','vent_recieved','o2_flow', \n",
    "'any_vasoactives', #added this and removed individual vasoactive 5/3/19\n",
    "'sum_elix', #added 6/4/19\n",
    "'cancer_elix'  ]#added 6/4/19\n",
    "\n",
    "low_value=['bicarbonate',\n",
    "'diasbp',\n",
    "'hemoglobin',\n",
    "'meanartpress',\n",
    "'mingcs',\n",
    "'ph',\n",
    "'platelet',\n",
    "'spo2',\n",
    "'sysbp']\n",
    "\n",
    "both_value=['calcium',\n",
    "'sodium',\n",
    "'wbc']\n",
    "\n",
    "#important_ordinal=[\"any_vasoactives\"]\n",
    "important_onetime=['yearsold','weight','pao2fio2ratio', 'pco2','bands'] #added pco2 and bands here, removed them above 06/14/19\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['daily_sofa', 'sum_elix', 'lactate', 'mingcs', 'diasbp',\n",
       "       'heartrate', 'meanartpress', 'resprate', 'spo2', 'sysbp',\n",
       "       'temperature', 'hemoglobin', 'platelet', 'wbc', 'calcium',\n",
       "       'glucose', 'ph', 'bicarbonate', 'bun', 'chloride', 'creatinine',\n",
       "       'inr', 'potassium', 'ptt', 'sodium', 'bilirubin', 'cancer_elix',\n",
       "       'dobutamine', 'dopamine', 'epinephrine', 'norepinephrine',\n",
       "       'o2_flow', 'pao2fio2ratio', 'pco2', 'phenylephrine', 'rrt',\n",
       "       'vasopressin', 'vent_recieved', 'bands', 'leukocyte', 'nitrite',\n",
       "       'any_vasoactives'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 183 ms\n"
     ]
    }
   ],
   "source": [
    "noCat_df_train['label'].unique()#noCat_df_train['label']=='any_vasoactives'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### running the min/max aggregations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 164 ms\n"
     ]
    }
   ],
   "source": [
    "def merge_cat_agg(num_df, cat_df, ):\n",
    "    \"\"\"\n",
    "    merges the categorical and aggregated dataframes together. \n",
    "    \"\"\"\n",
    "    \n",
    "    worst_df=pd.merge(num_df, cat_df, left_on='icustay_id', right_on='icustay_id',how='left')\n",
    "    worst_df['ethnicity']=worst_df['ethnicity'].astype(\"category\")\n",
    "    worst_df['gender']=worst_df['gender'].astype(\"category\")\n",
    "    \n",
    "    return(worst_df)\n",
    "\n",
    "def clin_agg(big_noCat, big_cat,big_df, values=\"standardize\"):\n",
    "    \"\"\"\n",
    "    clincally guided aggregations.\n",
    "    \n",
    "    values= choose here if wanna use standardization or raw values.\n",
    "    \n",
    "    note: getting two minor errors, could use some cleaning up at later date.\n",
    "    \"\"\"\n",
    "    global hi_value, low_value, both_value, important_onetime\n",
    "    #max aggregation for selected variables\n",
    "    big_max= big_noCat.loc[big_noCat.loc[:,'label'].isin(hi_value),:]\n",
    "    table = pd.pivot_table(big_max, values=values, columns='label', index=['icustay_id'],aggfunc=max, dropna=False)\n",
    "    \n",
    "    #min aggregation for selected variables\n",
    "    big_min= big_noCat.loc[big_noCat.loc[:,'label'].isin(low_value),:]\n",
    "    table2 = pd.pivot_table(big_min, values=values, columns='label', index=['icustay_id'],aggfunc=min, dropna=False)\n",
    "    \n",
    "    #max&min aggregation for selected variables\n",
    "    big_both= big_noCat.loc[big_noCat.loc[:,'label'].isin(both_value),:]\n",
    "    table3 = pd.pivot_table(big_both, values=values, columns='label', index=['icustay_id'],aggfunc=[max,min], dropna=False)\n",
    "    \n",
    "    #first left join all different continuous aggregations together. \n",
    "    worst_df=pd.merge(table.reset_index(), table2.reset_index(), how='left')\n",
    "    worst_df=pd.merge(worst_df, table3.reset_index(), left_on='icustay_id', right_on='icustay_id',how='left')\n",
    "    \n",
    "    ### formatting categorical to wide format to match the tables/worst_df\n",
    "    big_cat= big_cat.pivot(\n",
    "    index='icustay_id',\n",
    "    values='value',\n",
    "    columns='label').reset_index() #need to convert to wide format. should be one row per patient per time. \n",
    "    \n",
    "    ## merging the categorical and aggregated dataframes together. \n",
    "    worst_df=merge_cat_agg(worst_df, big_cat) #using max/min aggregates \n",
    "\n",
    "    #adding important one_time values to final aggregated\n",
    "    agg_remaining= big_df.loc[big_df.loc[:,'label'].isin(important_onetime),:]\n",
    "    agg_table2 = pd.pivot_table(agg_remaining, values='value', columns='label', index=['icustay_id'],aggfunc=[max], dropna=False) \n",
    "    agg_table2.columns = agg_table2.columns.get_level_values(1)\n",
    "    agg_table2=agg_table2.reset_index()\n",
    "    agg_table2.head()#.rename(columns={})\n",
    "\n",
    "    worst_df=pd.merge(worst_df, agg_table2, how='left')\n",
    "    return(worst_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/pandas/core/reshape/merge.py:522: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/pandas/core/generic.py:3812: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  new_axis = axis.drop(labels, errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1min 28s\n"
     ]
    }
   ],
   "source": [
    "worst_df_train=clin_agg(noCat_df_train, cat_df_train,big_df_train, values=\"standardize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/pandas/core/reshape/merge.py:522: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n",
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/pandas/core/generic.py:3812: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  new_axis = axis.drop(labels, errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 41.8 s\n"
     ]
    }
   ],
   "source": [
    "worst_df_test=clin_agg(noCat_df_test, cat_df_test, big_df_test, values=\"standardize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>any_vasoactives</th>\n",
       "      <th>bilirubin</th>\n",
       "      <th>bun</th>\n",
       "      <th>cancer_elix</th>\n",
       "      <th>chloride</th>\n",
       "      <th>creatinine</th>\n",
       "      <th>daily_sofa</th>\n",
       "      <th>dobutamine</th>\n",
       "      <th>dopamine</th>\n",
       "      <th>...</th>\n",
       "      <th>(min, calcium)</th>\n",
       "      <th>(min, sodium)</th>\n",
       "      <th>(min, wbc)</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>bands</th>\n",
       "      <th>pao2fio2ratio</th>\n",
       "      <th>pco2</th>\n",
       "      <th>weight</th>\n",
       "      <th>yearsold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.307149</td>\n",
       "      <td>asian</td>\n",
       "      <td>0</td>\n",
       "      <td>&gt;10</td>\n",
       "      <td>(475, 3000]</td>\n",
       "      <td>absent</td>\n",
       "      <td>51.2</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200014.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0407698</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0370891</td>\n",
       "      <td>-0.152003</td>\n",
       "      <td>-0.178747</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030419</td>\n",
       "      <td>unknown/other</td>\n",
       "      <td>1</td>\n",
       "      <td>absent</td>\n",
       "      <td>(200, 333]</td>\n",
       "      <td>&lt;50</td>\n",
       "      <td>62.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200033.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0822292</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0127018</td>\n",
       "      <td>-0.234465</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.505654</td>\n",
       "      <td>-0.020446</td>\n",
       "      <td>-0.208966</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>absent</td>\n",
       "      <td>(475, 3000]</td>\n",
       "      <td>absent</td>\n",
       "      <td>74.0</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200036.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119501</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020977</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.430677</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.008089</td>\n",
       "      <td>-0.360027</td>\n",
       "      <td>white/nonhispanic</td>\n",
       "      <td>1</td>\n",
       "      <td>absent</td>\n",
       "      <td>(475, 3000]</td>\n",
       "      <td>absent</td>\n",
       "      <td>79.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200055.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.345426</td>\n",
       "      <td>0.198543</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.0219907</td>\n",
       "      <td>2.30743</td>\n",
       "      <td>0.503859</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135281</td>\n",
       "      <td>-0.004030</td>\n",
       "      <td>-0.244453</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>absent</td>\n",
       "      <td>(475, 3000]</td>\n",
       "      <td>absent</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   icustay_id any_vasoactives bilirubin        bun cancer_elix   chloride  \\\n",
       "0    200012.0             0.0       NaN        NaN           0        NaN   \n",
       "1    200014.0             0.0       NaN  0.0407698           0  0.0370891   \n",
       "2    200033.0             1.0       NaN -0.0822292           1  0.0127018   \n",
       "3    200036.0             0.0       NaN   0.119501           0   0.020977   \n",
       "4    200055.0             0.0 -0.345426   0.198543           0 -0.0219907   \n",
       "\n",
       "  creatinine daily_sofa dobutamine dopamine  ... (min, calcium) (min, sodium)  \\\n",
       "0        NaN  -0.430677          0        0  ...            NaN           NaN   \n",
       "1  -0.152003  -0.178747          0        0  ...      -0.044882      0.000000   \n",
       "2  -0.234465  -0.430677          0        0  ...      -0.505654     -0.020446   \n",
       "3          0  -0.430677          0        0  ...            NaN     -0.008089   \n",
       "4    2.30743   0.503859          0        0  ...      -0.135281     -0.004030   \n",
       "\n",
       "  (min, wbc)          ethnicity gender   bands pao2fio2ratio    pco2 weight  \\\n",
       "0  -0.307149              asian      0     >10   (475, 3000]  absent   51.2   \n",
       "1   0.030419      unknown/other      1  absent    (200, 333]     <50   62.0   \n",
       "2  -0.208966  white/nonhispanic      1  absent   (475, 3000]  absent   74.0   \n",
       "3  -0.360027  white/nonhispanic      1  absent   (475, 3000]  absent   79.0   \n",
       "4  -0.244453                NaN    NaN  absent   (475, 3000]  absent   56.0   \n",
       "\n",
       "  yearsold  \n",
       "0     32.0  \n",
       "1     84.0  \n",
       "2     67.0  \n",
       "3     74.0  \n",
       "4      NaN  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 48.8 ms\n"
     ]
    }
   ],
   "source": [
    "worst_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count            7205\n",
       "unique              4\n",
       "top       (475, 3000]\n",
       "freq             5124\n",
       "Name: pao2fio2ratio, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 17.5 ms\n"
     ]
    }
   ],
   "source": [
    "worst_df_train['pao2fio2ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['icustay_id',\n",
       " 'any_vasoactives',\n",
       " 'bilirubin',\n",
       " 'bun',\n",
       " 'cancer_elix',\n",
       " 'chloride',\n",
       " 'creatinine',\n",
       " 'daily_sofa',\n",
       " 'dobutamine',\n",
       " 'dopamine',\n",
       " 'epinephrine',\n",
       " 'glucose',\n",
       " 'heartrate',\n",
       " 'inr',\n",
       " 'lactate',\n",
       " 'leukocyte',\n",
       " 'nitrite',\n",
       " 'norepinephrine',\n",
       " 'o2_flow',\n",
       " 'phenylephrine',\n",
       " 'potassium',\n",
       " 'ptt',\n",
       " 'resprate',\n",
       " 'rrt',\n",
       " 'sum_elix',\n",
       " 'temperature',\n",
       " 'vasopressin',\n",
       " 'vent_recieved',\n",
       " 'bicarbonate',\n",
       " 'diasbp',\n",
       " 'hemoglobin',\n",
       " 'meanartpress',\n",
       " 'mingcs',\n",
       " 'ph',\n",
       " 'platelet',\n",
       " 'spo2',\n",
       " 'sysbp',\n",
       " ('max', 'calcium'),\n",
       " ('max', 'sodium'),\n",
       " ('max', 'wbc'),\n",
       " ('min', 'calcium'),\n",
       " ('min', 'sodium'),\n",
       " ('min', 'wbc'),\n",
       " 'ethnicity',\n",
       " 'gender',\n",
       " 'bands',\n",
       " 'pao2fio2ratio',\n",
       " 'pco2',\n",
       " 'weight',\n",
       " 'yearsold']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.28 ms\n"
     ]
    }
   ],
   "source": [
    "list(worst_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    7057\n",
       "1.0     148\n",
       "Name: vasopressin, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.13 ms\n"
     ]
    }
   ],
   "source": [
    "worst_df_train['vasopressin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 708 µs\n"
     ]
    }
   ],
   "source": [
    "#worst_df_train['vasopressin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absent    6156\n",
       "<10        687\n",
       ">10        362\n",
       "Name: bands, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.6 ms\n"
     ]
    }
   ],
   "source": [
    "worst_df_train['bands'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "absent    4699\n",
       "<50       1740\n",
       ">50        766\n",
       "Name: pco2, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 5.79 ms\n"
     ]
    }
   ],
   "source": [
    "worst_df_train['pco2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 806 ms\n"
     ]
    }
   ],
   "source": [
    "save_df(worst_df_train, 'train')\n",
    "save_df(worst_df_test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.5 ms\n"
     ]
    }
   ],
   "source": [
    "del worst_df_train, worst_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 521 µs\n"
     ]
    }
   ],
   "source": [
    "#wd+'/data/processed/merged/{}_worst_df_train_preImp_{}.csv'.format(date,timewindowdays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(wd+'/data/processed/merged/{}_worstdf_preImp{}.csv'.format(date,timewindowdays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class onehot(TransformerMixin):\n",
    "#     def __init__(self, cols_to_transform):\n",
    "#         self.cols_to_transform=cols_to_transform\n",
    "        \n",
    "#     def transform(self,df ):\n",
    "#         data = pd.get_dummies(df, columns = self.cols_to_transform, drop_first=True)\n",
    "#         return(data)\n",
    "    \n",
    "#     def fit(self, *_):\n",
    "#         return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
