{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# designed to be run after 03-clinical_variables_final. this notebook does some data cleaning/processing. run before -___ notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/ipykernel_launcher.py:10: DeprecationWarning: The 'cachedir' parameter has been deprecated in version 0.12 and will be removed in version 0.14.\n",
      "You provided \"cachedir='/tmp'\", use \"location='/tmp'\" instead.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "from sklearn.externals.joblib import Memory\n",
    "memory = Memory(cachedir='/tmp', verbose=0)\n",
    "#@memory.cache above any def fxn.\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1024,\n",
    "        'height': 768,\n",
    "        'scroll': True,\n",
    "})\n",
    "\n",
    "%load_ext autotime\n",
    "%reload_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.1 s\n"
     ]
    }
   ],
   "source": [
    "#patients of interest from rotation_cohort_generation\n",
    "from parameters import final_pt_df_v, date, repository_path\n",
    "\n",
    "#patients of interest from rotation_cohort_generation\n",
    "final_pt_df2 = final_pt_df_v\n",
    "del(final_pt_df_v)\n",
    "\n",
    "patients= list(final_pt_df2['subject_id'].unique())\n",
    "hadm_id= list(final_pt_df2['hadm_id'].unique())\n",
    "icustay_id= list(final_pt_df2['icustay_id'].unique())\n",
    "icustay_id= [int(x) for x in icustay_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C_neg/A_partial    7867\n",
       "C_neg/A_full       7401\n",
       "C_pos/A_full       2438\n",
       "C_pos/A_partial    1927\n",
       "Name: final_bin, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.45 ms\n"
     ]
    }
   ],
   "source": [
    "final_pt_df2['final_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C_neg/A_partial    7867\n",
       "C_neg/A_full       7401\n",
       "C_pos/A_full       2438\n",
       "C_pos/A_partial    1927\n",
       "Name: final_bin, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.81 ms\n"
     ]
    }
   ],
   "source": [
    "final_pt_df2['final_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting clinical data for our patients\n",
    "## IMPORTANT, USE THIS TO TUNE TIMEWINDOW OF EXTRACTION AND FOLDER TO SAVE IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NOTE ON MY DF NAMING CONVENTION:\n",
    "origionally when I coded this workbook, it was for 72 hour timewindows, so every dataframe had _72 at the end. this was changed on 6/5/19 and was made more generalizable by finding name of each corresponding df in the df list and using this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "from parameters import lower_window, upper_window, folder, date, time_col, time_var, patient_df, save_boolean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### begin pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# changing my code structure to be a dictionary of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.27 ms\n"
     ]
    }
   ],
   "source": [
    "#folder to save files to:\n",
    "save_path= str(repository_path)+'/data/cleaned/'\n",
    "#folder=None\n",
    "\n",
    "\n",
    "def save_df(df, df_name='default', save_path=save_path, add_subfolder=False):\n",
    "    #uses the date and supplied df name and saves to the savepath specified above.\n",
    "    if df_name == 'default':\n",
    "        df_name= \"%s\"%(df)\n",
    "    \n",
    "    address=save_path+'%s/'%(folder)\n",
    "    if not os.path.exists(address):\n",
    "        print(address)\n",
    "        os.makedirs(address)\n",
    "    pd.DataFrame(df).to_csv(Path(address+'%s_%s_prepped.csv' %(date, df_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/cleaned/24_hr_window/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.33 ms\n"
     ]
    }
   ],
   "source": [
    "save_path+'%s/'%(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.08 ms\n"
     ]
    }
   ],
   "source": [
    "##folder with all clinical variable csv's\n",
    "allFiles = glob.glob(str(repository_path)+ '/data/raw/%s/'%(folder) + \"{}_*.csv\".format(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/raw/24_hr_window/30102019_vaso_dose.csv',\n",
       " '/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/raw/24_hr_window/30102019_gcs.csv',\n",
       " '/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/raw/24_hr_window/30102019_rrt_merged.csv',\n",
       " '/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/raw/24_hr_window/30102019_sofa.csv',\n",
       " '/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/raw/24_hr_window/30102019_ventcategory.csv',\n",
       " '/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/raw/24_hr_window/30102019_cancer_elix.csv',\n",
       " '/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/raw/24_hr_window/30102019_uti_all.csv',\n",
       " '/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/raw/24_hr_window/30102019_heightfirstday.csv',\n",
       " '/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/raw/24_hr_window/30102019_pt_info.csv',\n",
       " '/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/raw/24_hr_window/30102019_sum_elix.csv',\n",
       " '/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/raw/24_hr_window/30102019_weightfirstday.csv',\n",
       " '/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/raw/24_hr_window/30102019_bg_all_nosummary.csv',\n",
       " '/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/raw/24_hr_window/30102019_labs_all_nosummary.csv',\n",
       " '/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/raw/24_hr_window/30102019_vitals_all_nosummary.csv']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.79 ms\n"
     ]
    }
   ],
   "source": [
    "allFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/anaconda/envs/rpy-env/lib/python3.6/site-packages/numpy/lib/arraysetops.py:569: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.7 s\n"
     ]
    }
   ],
   "source": [
    "#making a dictionary of all my dataframes for easier cycling through\n",
    "\n",
    "df_list=[]\n",
    "for element in allFiles:\n",
    "    df_list.append(element.split('{}_'.format(date))[1].split('.csv')[0]) #making an list of all my dataframes in order they appear in file\n",
    "\n",
    "dfs = {}\n",
    "i=0\n",
    "for name in df_list:\n",
    "    dfs[name] = pd.read_csv(allFiles[i],  index_col=0)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vaso_dose',\n",
       " 'gcs',\n",
       " 'rrt_merged',\n",
       " 'sofa',\n",
       " 'ventcategory',\n",
       " 'cancer_elix',\n",
       " 'uti_all',\n",
       " 'heightfirstday',\n",
       " 'pt_info',\n",
       " 'sum_elix',\n",
       " 'weightfirstday',\n",
       " 'bg_all_nosummary',\n",
       " 'labs_all_nosummary',\n",
       " 'vitals_all_nosummary']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.11 ms\n"
     ]
    }
   ],
   "source": [
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 66.7 ms\n"
     ]
    }
   ],
   "source": [
    "#assigning the appropriate name to each df in a flexible way\n",
    "\n",
    "indices = [i for i, s in enumerate(df_list) if 'bg' in s]\n",
    "bg_df= df_list[indices[0]]\n",
    "\n",
    "indices = [i for i, s in enumerate(df_list) if 'cancer' in s]\n",
    "cancer_elix_df= df_list[indices[0]]\n",
    "\n",
    "indices = [i for i, s in enumerate(df_list) if 'uti' in s]\n",
    "uti_df= df_list[indices[0]]\n",
    "\n",
    "indices = [i for i, s in enumerate(df_list) if 'vent' in s]\n",
    "vent_df= df_list[indices[0]]\n",
    "\n",
    "indices = [i for i, s in enumerate(df_list) if 'vitals' in s]\n",
    "vitals_df= df_list[indices[0]]\n",
    "\n",
    "indices = [i for i, s in enumerate(df_list) if 'vaso' in s]\n",
    "vaso_df= df_list[indices[0]]\n",
    "\n",
    "indices = [i for i, s in enumerate(df_list) if 'pt_info' in s]\n",
    "pt_info_df= df_list[indices[0]]\n",
    "\n",
    "indices = [i for i, s in enumerate(df_list) if 'gcs' in s]\n",
    "gcs_df= df_list[indices[0]]\n",
    "\n",
    "indices = [i for i, s in enumerate(df_list) if 'sum_elix' in s]\n",
    "sum_elix_df = df_list[indices[0]]\n",
    "\n",
    "indices = [i for i, s in enumerate(df_list) if 'sofa' in s]\n",
    "sofa_df= df_list[indices[0]]\n",
    "\n",
    "indices = [i for i, s in enumerate(df_list) if 'weight' in s]\n",
    "weight_df= df_list[indices[0]]\n",
    "\n",
    "indices = [i for i, s in enumerate(df_list) if 'labs' in s]\n",
    "labs_df= df_list[indices[0]]\n",
    "\n",
    "indices = [i for i, s in enumerate(df_list) if 'height' in s]\n",
    "height_df= df_list[indices[0]]\n",
    "\n",
    "indices = [i for i, s in enumerate(df_list) if 'rrt' in s]\n",
    "rrt_df= df_list[indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "false\n",
      "time: 63.9 ms\n"
     ]
    }
   ],
   "source": [
    "#adding a t_0 to each df that doesn't currently have it\n",
    "\n",
    "for element in df_list:\n",
    "    #print(element,':',list(dfs[element]))\n",
    "    if ('t_0' in list(dfs[element]))==False and 'icustay_id' in list(dfs[element]) :\n",
    "        #print(\"true\")\n",
    "        dfs[element]= pd.merge(dfs[element], final_pt_df2[['icustay_id','t_0']], how='left')\n",
    "    elif ('t_0' in list(dfs[element]))==False and 'hadm_id' in list(dfs[element]) :\n",
    "        #print(\"true\")\n",
    "        dfs[element]= pd.merge(dfs[element], final_pt_df2[['hadm_id','t_0']], how='left')\n",
    "    else:\n",
    "        print(\"false\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vaso_dose : ['icustay_id', 'charttime', 'endtime', 'vaso_rate', 'vaso_amount', 'amount_uom', 'rate_uom', 'label', 't_0', 'delta']\n",
      "gcs : ['subject_id', 'hadm_id', 'icustay_id', 'day', 'mingcs', 'gcsmotor', 'gcsverbal', 'gcseyes', 'endotrachflag', 'icu_admit', 't_0', 'approx_charttime', 'admit_plus_day', 'delta', 'uom']\n",
      "rrt_merged : ['icustay_id', 't_0', 'first_charttime', 'rrt', 'uom']\n",
      "sofa : ['subject_id', 'hadm_id', 'icustay_id', 'day', 'sofa', 'respiration', 'pao2fio2_vent_min', 'pao2fio2_novent_min', 'coagulation', 'platelet_min', 'liver', 'bilirubin_max', 'cardiovascular', 'rate_dopamine', 'rate_epinephrine', 'rate_norepinephrine', 'rate_dobutamine', 'meanbp_min', 'cns', 'mingcs', 'renal', 'creatinine_max', 'urineoutput', 't_0', 'icu_admit', 'approx_charttime', 'floor_charttime', 'floor_time_var']\n",
      "ventcategory : ['icustay_id', 'day', 'value', 'uom', 't_0']\n",
      "cancer_elix : ['subject_id', 'hadm_id', 'icustay_id', 'value', 'label', 'delta', 'uom', 't_0']\n",
      "uti_all : ['subject_id', 'hadm_id', 'itemid', 'charttime', 'value', 'valuenum', 'valueuom', 'label', 'fluid', 'category', 'loinc_code', 'icd9_code', 't_0', 'delta']\n",
      "heightfirstday : ['icustay_id', 'height', 'height_chart', 'height_echo', 'uom', 't_0']\n",
      "pt_info : ['icustay_id', 'subject_id', 't_0', 'label', 'value', 'delta', 'uom']\n",
      "sum_elix : ['subject_id', 'hadm_id', 'icustay_id', 'value', 'label', 'delta', 'uom', 't_0']\n",
      "weightfirstday : ['icustay_id', 'weight', 'weight_admit', 'weight_daily', 'weight_echoinhosp', 'weight_echoprehosp', 'uom', 't_0']\n",
      "bg_all_nosummary : ['subject_id', 'hadm_id', 'icustay_id', 'charttime', 'label', 'valuenum', 'value', 'valueuom', 'unique_var', 't_0', 'delta']\n",
      "labs_all_nosummary : ['subject_id', 'hadm_id', 'icustay_id', 'charttime', 'label', 'valuenum', 'uom', 't_0', 'delta']\n",
      "vitals_all_nosummary : ['subject_id', 'hadm_id', 'icustay_id', 'charttime', 'valueuom', 'vitalid', 'valuenum', 't_0', 'delta']\n",
      "time: 3.15 ms\n"
     ]
    }
   ],
   "source": [
    "for element in df_list:\n",
    "    print(element,':',list(dfs[element]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 20.3 ms\n"
     ]
    }
   ],
   "source": [
    "from parameters import time_var, value_fill, delta_fill, uom_fill\n",
    "def yn_convert(df, #df in format where each row corresponds to a test, and a patient can have many rows\n",
    "               label_fill, # value that will be filled to na's\n",
    "               pt= final_pt_df2,\n",
    "               time_var=time_var,#'t_0', #\n",
    "               value_fill=value_fill,#0,\n",
    "               delta_fill=delta_fill,# pd.to_timedelta('0 days'),\n",
    "               uom_fill=uom_fill):#'y/n'):\n",
    "\n",
    "    \"\"\"\n",
    "    description: collapses (binarizes) a dataframe where each row corresponds to a test, and a patient can have many rows -> \n",
    "    1 row per patient where value is binary variable yes or no a patient has any value within the timewindow (specified in data collection).\n",
    "    said a different way, for patient this fxn collapses values down to does pt have a non NA value in the clinical time window y/n? \n",
    "    \n",
    "    label_fill: the variable name in the label column of the specified dataframe that will considered for y/n value within timewindow. if any non NA value is present\n",
    "        it will be considered positive.\n",
    "    pt: the by patient spreadsheet be be used to supply patient information.\n",
    "    time_var: the variable used to create the time window of interest.\n",
    "    value_fill: the variable value that missing values will be filled if the value is not present (default =0) in the origional dataset\n",
    "    delta_fill: the time delta value that will be filled in if a patient doesn't have any instances of the label_fill.  \n",
    "    uom_fill: fills in the unit of measurement to this for missing values.\n",
    "    \n",
    "    returns a flat 1 row per icustay_id of 1 or 0 if any value was present for the patient.\n",
    "    \"\"\"\n",
    "    \n",
    "    yn_df = pd.merge(pt[['icustay_id', time_var]],\n",
    "                      df[['icustay_id','value','label','uom','delta']],\n",
    "                     left_on= 'icustay_id',\n",
    "                     right_on= 'icustay_id',\n",
    "                      how='left') #merging all icustay_id's with time_var, where value,label,uom, and delta are nan's if no value exists for that icustay. \n",
    "    #the idea is that if any value exists then it is pos.\n",
    "\n",
    "    yn_df['value']= yn_df['value'].fillna(value_fill) #converts na to 0 in above na rows.\n",
    "    yn_df.loc[yn_df.loc[:,'value']!=value_fill, 'value']= 1 #squashes all other values into a binary 1 = yes\n",
    "    yn_df['delta']= yn_df['delta'].fillna(delta_fill)\n",
    "    yn_df['delta']= pd.to_timedelta(yn_df['delta']) #filling in the time delta to time =0 for filled rows\n",
    "    yn_df['uom']= yn_df['uom'].fillna(uom_fill)\n",
    "    yn_df.loc[yn_df.loc[:,'uom']!=uom_fill, 'uom']= uom_fill\n",
    "    yn_df['label']= yn_df['label'].fillna(label_fill)\n",
    "    \n",
    "    return(yn_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vaso dose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.1 ms\n"
     ]
    }
   ],
   "source": [
    "# #renaming starttime to charttime and dropping endtime\n",
    "\n",
    "dfs[vaso_df]= dfs[vaso_df].rename(\n",
    "    columns={'starttime':'charttime','label':'vaso_type'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35199"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.79 ms\n"
     ]
    }
   ],
   "source": [
    "len(dfs[vaso_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>endtime</th>\n",
       "      <th>vaso_rate</th>\n",
       "      <th>vaso_amount</th>\n",
       "      <th>amount_uom</th>\n",
       "      <th>rate_uom</th>\n",
       "      <th>vaso_type</th>\n",
       "      <th>t_0</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200349.0</td>\n",
       "      <td>2139-06-02 16:31:00</td>\n",
       "      <td>2139-06-02 18:10:00</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>0.073958</td>\n",
       "      <td>mg</td>\n",
       "      <td>mcg/kg/min</td>\n",
       "      <td>epinephrine</td>\n",
       "      <td>2139-06-02</td>\n",
       "      <td>0 days 16:31:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>200952.0</td>\n",
       "      <td>2139-09-23 15:07:00</td>\n",
       "      <td>2139-09-24 06:43:00</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>1.049601</td>\n",
       "      <td>mg</td>\n",
       "      <td>mcg/kg/min</td>\n",
       "      <td>epinephrine</td>\n",
       "      <td>2139-09-23</td>\n",
       "      <td>0 days 15:07:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200952.0</td>\n",
       "      <td>2139-09-23 23:12:00</td>\n",
       "      <td>2139-09-24 21:54:00</td>\n",
       "      <td>0.149992</td>\n",
       "      <td>7.990853</td>\n",
       "      <td>mg</td>\n",
       "      <td>mcg/kg/min</td>\n",
       "      <td>norepinephrine</td>\n",
       "      <td>2139-09-23</td>\n",
       "      <td>0 days 23:12:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>200952.0</td>\n",
       "      <td>2139-09-23 15:06:00</td>\n",
       "      <td>2139-09-24 00:51:00</td>\n",
       "      <td>2.509001</td>\n",
       "      <td>43.660095</td>\n",
       "      <td>mg</td>\n",
       "      <td>mcg/kg/min</td>\n",
       "      <td>phenylephrine</td>\n",
       "      <td>2139-09-23</td>\n",
       "      <td>0 days 15:06:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>200977.0</td>\n",
       "      <td>2166-12-02 16:59:00</td>\n",
       "      <td>2166-12-03 05:50:00</td>\n",
       "      <td>0.030015</td>\n",
       "      <td>1.590643</td>\n",
       "      <td>mg</td>\n",
       "      <td>mcg/kg/min</td>\n",
       "      <td>epinephrine</td>\n",
       "      <td>2166-12-02</td>\n",
       "      <td>0 days 16:59:00.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    icustay_id            charttime              endtime  vaso_rate  \\\n",
       "4     200349.0  2139-06-02 16:31:00  2139-06-02 18:10:00   0.012030   \n",
       "8     200952.0  2139-09-23 15:07:00  2139-09-24 06:43:00   0.020004   \n",
       "22    200952.0  2139-09-23 23:12:00  2139-09-24 21:54:00   0.149992   \n",
       "34    200952.0  2139-09-23 15:06:00  2139-09-24 00:51:00   2.509001   \n",
       "36    200977.0  2166-12-02 16:59:00  2166-12-03 05:50:00   0.030015   \n",
       "\n",
       "    vaso_amount amount_uom    rate_uom       vaso_type         t_0  \\\n",
       "4      0.073958         mg  mcg/kg/min     epinephrine  2139-06-02   \n",
       "8      1.049601         mg  mcg/kg/min     epinephrine  2139-09-23   \n",
       "22     7.990853         mg  mcg/kg/min  norepinephrine  2139-09-23   \n",
       "34    43.660095         mg  mcg/kg/min   phenylephrine  2139-09-23   \n",
       "36     1.590643         mg  mcg/kg/min     epinephrine  2166-12-02   \n",
       "\n",
       "                        delta  \n",
       "4   0 days 16:31:00.000000000  \n",
       "8   0 days 15:07:00.000000000  \n",
       "22  0 days 23:12:00.000000000  \n",
       "34  0 days 15:06:00.000000000  \n",
       "36  0 days 16:59:00.000000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.1 ms\n"
     ]
    }
   ],
   "source": [
    "dfs[vaso_df].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.9 ms\n"
     ]
    }
   ],
   "source": [
    "#removing units/hour because that is a different use of vasopressin\n",
    "dfs[vaso_df] = dfs[vaso_df].loc[dfs[vaso_df].loc[:,'rate_uom']!= 'units/hour',:]\n",
    "dfs[vaso_df] = dfs[vaso_df].loc[dfs[vaso_df].loc[:,'rate_uom']!= 'Uhr',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35199"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.71 ms\n"
     ]
    }
   ],
   "source": [
    "len(dfs[vaso_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mcg/kg/min', 'mcgkgmin', 'Umin'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.38 ms\n"
     ]
    }
   ],
   "source": [
    "dfs[vaso_df]['rate_uom'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### removing outliers/extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.6 ms\n"
     ]
    }
   ],
   "source": [
    "# Use transform to add a column back to the orig df from a groupby aggregation, transform returns a Series with its index aligned to the orig df:\n",
    "def vaso_outlier_removal(df):\n",
    "    test_group=(dfs[vaso_df][['vaso_rate','rate_uom','amount_uom','vaso_type']]#.groupby('vaso_type', as_index=False)\n",
    "         .groupby(['vaso_type','rate_uom'])\n",
    "             )\n",
    "\n",
    "    dfs[vaso_df]['std']=test_group.transform(lambda x : x.std())\n",
    "    dfs[vaso_df]['mean']=test_group.transform(lambda x : x.mean())\n",
    "\n",
    "    normal_high_value= pd.DataFrame({\n",
    "        'vaso_type' : ['dobutamine','dopamine','epinephrine','norepinephrine','vasopressin','phenylephrine'],\n",
    "        'high_value': [40, 20, 0.5, 1, 0.1, 2] #highest values one might expect to see in a clinic, ie above this is likely erroneous\n",
    "    }) #found from literature, see notes\n",
    "\n",
    "    dfs[vaso_df] = pd.merge(dfs[vaso_df], normal_high_value, left_on='vaso_type', right_on='vaso_type')\n",
    "\n",
    "    vaso_dose_72_rmout =(dfs[vaso_df][\n",
    "        ~((dfs[vaso_df]['vaso_rate'] > dfs[vaso_df]['high_value']) & ((dfs[vaso_df]['vaso_rate']-dfs[vaso_df]['mean'])>= (3*dfs[vaso_df]['std'])))\n",
    "        ])\n",
    "    #ie vaso_dose_72_rmout is a dataframe of all rows that excludes rows where vaso rate > literature high value and where vaso_rate >3sd from teh mean\n",
    "    return(vaso_dose_72_rmout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35010"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "dfs[vaso_df]= vaso_outlier_removal(dfs[vaso_df])\n",
    "len(dfs[vaso_df]) #52976 ->49340"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['epinephrine', 'norepinephrine', 'phenylephrine', 'dopamine',\n",
       "       'dobutamine', 'vasopressin'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.44 ms\n"
     ]
    }
   ],
   "source": [
    "dfs[vaso_df]['vaso_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['epinephrine', 'norepinephrine', 'phenylephrine', 'dopamine',\n",
       "       'dobutamine', 'vasopressin'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31.7 ms\n"
     ]
    }
   ],
   "source": [
    "#standardizing names, dropping unneeded columns for analysis\n",
    "dfs[vaso_df]= dfs[vaso_df].drop(['vaso_amount', 'amount_uom','std','mean','high_value'], axis=1)\n",
    "dfs[vaso_df]= dfs[vaso_df].rename(index=str, columns={'vaso_rate': 'value', 'rate_uom':'uom','vaso_type':'label'})\n",
    "dfs[vaso_df]['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>endtime</th>\n",
       "      <th>value</th>\n",
       "      <th>uom</th>\n",
       "      <th>label</th>\n",
       "      <th>t_0</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200349.0</td>\n",
       "      <td>2139-06-02 16:31:00</td>\n",
       "      <td>2139-06-02 18:10:00</td>\n",
       "      <td>0.012030</td>\n",
       "      <td>mcg/kg/min</td>\n",
       "      <td>epinephrine</td>\n",
       "      <td>2139-06-02</td>\n",
       "      <td>0 days 16:31:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200952.0</td>\n",
       "      <td>2139-09-23 15:07:00</td>\n",
       "      <td>2139-09-24 06:43:00</td>\n",
       "      <td>0.020004</td>\n",
       "      <td>mcg/kg/min</td>\n",
       "      <td>epinephrine</td>\n",
       "      <td>2139-09-23</td>\n",
       "      <td>0 days 15:07:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200977.0</td>\n",
       "      <td>2166-12-02 16:59:00</td>\n",
       "      <td>2166-12-03 05:50:00</td>\n",
       "      <td>0.030015</td>\n",
       "      <td>mcg/kg/min</td>\n",
       "      <td>epinephrine</td>\n",
       "      <td>2166-12-02</td>\n",
       "      <td>0 days 16:59:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201005.0</td>\n",
       "      <td>2169-10-25 17:25:00</td>\n",
       "      <td>2169-10-25 18:00:00</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>mcgkgmin</td>\n",
       "      <td>epinephrine</td>\n",
       "      <td>2169-10-25</td>\n",
       "      <td>0 days 17:25:00.000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201005.0</td>\n",
       "      <td>2169-10-25 18:30:00</td>\n",
       "      <td>2169-10-25 19:00:00</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>mcgkgmin</td>\n",
       "      <td>epinephrine</td>\n",
       "      <td>2169-10-25</td>\n",
       "      <td>0 days 18:30:00.000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   icustay_id            charttime              endtime     value         uom  \\\n",
       "0    200349.0  2139-06-02 16:31:00  2139-06-02 18:10:00  0.012030  mcg/kg/min   \n",
       "1    200952.0  2139-09-23 15:07:00  2139-09-24 06:43:00  0.020004  mcg/kg/min   \n",
       "2    200977.0  2166-12-02 16:59:00  2166-12-03 05:50:00  0.030015  mcg/kg/min   \n",
       "3    201005.0  2169-10-25 17:25:00  2169-10-25 18:00:00  0.020000    mcgkgmin   \n",
       "4    201005.0  2169-10-25 18:30:00  2169-10-25 19:00:00  0.020000    mcgkgmin   \n",
       "\n",
       "         label         t_0                      delta  \n",
       "0  epinephrine  2139-06-02  0 days 16:31:00.000000000  \n",
       "1  epinephrine  2139-09-23  0 days 15:07:00.000000000  \n",
       "2  epinephrine  2166-12-02  0 days 16:59:00.000000000  \n",
       "3  epinephrine  2169-10-25  0 days 17:25:00.000000000  \n",
       "4  epinephrine  2169-10-25  0 days 18:30:00.000000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 10.6 ms\n"
     ]
    }
   ],
   "source": [
    "dfs[vaso_df].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 21.1 ms\n"
     ]
    }
   ],
   "source": [
    "epinephrine_df= dfs[vaso_df][dfs[vaso_df]['label']=='epinephrine']\n",
    "norepinephrine_df= dfs[vaso_df][dfs[vaso_df]['label']=='norepinephrine']\n",
    "phenylephrine_df= dfs[vaso_df][dfs[vaso_df]['label']=='phenylephrine']\n",
    "vasopressin_df= dfs[vaso_df][dfs[vaso_df]['label']=='vasopressin']\n",
    "dopamine_df= dfs[vaso_df][dfs[vaso_df]['label']=='dopamine']\n",
    "dobutamine_df= dfs[vaso_df][dfs[vaso_df]['label']=='dobutamine']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 744 ms\n"
     ]
    }
   ],
   "source": [
    "#(could be transfered to a different spdsheet for collapsing values)\n",
    "#y/n convert, seperating out vaso_dose into 6 constitutient dataframes, and for each am collapsing values down to does pt have in time window y/n? \n",
    "\n",
    "epinephrine_df=yn_convert(epinephrine_df, label_fill='epinephrine', pt= final_pt_df2, value_fill=0, delta_fill=0, uom_fill='y/n', time_var=time_var)\n",
    "norepinephrine_df=yn_convert(norepinephrine_df, label_fill='norepinephrine', pt= final_pt_df2, value_fill=0, delta_fill=0, uom_fill='y/n', time_var=time_var)\n",
    "phenylephrine_df=yn_convert(phenylephrine_df, label_fill='phenylephrine', pt= final_pt_df2, value_fill=0, delta_fill=0, uom_fill='y/n', time_var=time_var)\n",
    "vasopressin_df=yn_convert(vasopressin_df, label_fill='vasopressin', pt= final_pt_df2, value_fill=0, delta_fill=0, uom_fill='y/n', time_var=time_var)\n",
    "dopamine_df=yn_convert(dopamine_df, label_fill='dopamine', pt= final_pt_df2, value_fill=0, delta_fill=0, uom_fill='y/n', time_var=time_var)\n",
    "dobutamine_df=yn_convert(dobutamine_df, label_fill='dobutamine', pt= final_pt_df2, value_fill=0, delta_fill=0, uom_fill='y/n', time_var=time_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/cleaned/24_hr_window/\n",
      "time: 390 ms\n"
     ]
    }
   ],
   "source": [
    "save_df(epinephrine_df, df_name='epinephrine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(epinephrine_df).to_csv(Path(\n",
    "#     save_path+ '/%s_epinephrine_prepped.csv' %(date)))\n",
    "\n",
    "save_df(epinephrine_df, df_name='epinephrine')\n",
    "del(epinephrine_df)\n",
    "\n",
    "save_df(norepinephrine_df, df_name='norepinephrine')\n",
    "del(norepinephrine_df)\n",
    "\n",
    "save_df(phenylephrine_df, df_name='phenylephrine')\n",
    "del(phenylephrine_df)\n",
    "\n",
    "save_df(vasopressin_df, df_name='vasopressin')\n",
    "del(vasopressin_df)\n",
    "\n",
    "save_df(dopamine_df, df_name='dopamine')\n",
    "del(dopamine_df)\n",
    "\n",
    "save_df(dobutamine_df, df_name='dobutamine')\n",
    "del(dobutamine_df)\n",
    "\n",
    "del(dfs[vaso_df])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert cancer elix to y/n:\n",
    "dfs[cancer_elix_df]= yn_convert(dfs[cancer_elix_df], label_fill=0, pt= final_pt_df2, value_fill=0, delta_fill=0, uom_fill='y/n', time_var=time_var)\n",
    "save_df(dfs[cancer_elix_df], df_name='cancer_elix')\n",
    "del(dfs[cancer_elix_df])\n",
    "\n",
    "save_df(dfs[sum_elix_df], 'sum_elix')\n",
    "del(dfs[sum_elix_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vitals -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[vitals_df].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[vitals_df] = dfs[vitals_df].rename(index=str, columns={\"valueuom\":\"uom\",\"vitalid\":'label', 'valuenum':'value'}) #change valueom to uom\n",
    "dfs[vitals_df] = dfs[vitals_df].loc[dfs[vitals_df]['label'].notnull(),:]#.count() #removing null values\n",
    "\n",
    "dfs[vitals_df].loc[dfs[vitals_df].loc[:,'uom']=='BPM','uom']='bpm'\n",
    "\n",
    "#overall the values are extremely similar and are likely the same thing\n",
    "#i will combine them.\n",
    "dfs[vitals_df].loc[\n",
    "    (dfs[vitals_df]['label']=='RespRate') & \n",
    "    (dfs[vitals_df]['uom']=='bpm'),'uom']='insp/min'\n",
    "\n",
    "dfs[vitals_df].loc[\n",
    "    (dfs[vitals_df]['label']=='TempC') & \n",
    "    (dfs[vitals_df]['uom']=='?C'),'uom']='Deg. C'\n",
    "\n",
    "dfs[vitals_df].loc[\n",
    "    (dfs[vitals_df]['label']=='TempF') & \n",
    "    (dfs[vitals_df]['uom']=='Deg. F'),'uom']='Deg. C'\n",
    "\n",
    "dfs[vitals_df].loc[\n",
    "    (dfs[vitals_df]['label']=='TempF') & \n",
    "    (dfs[vitals_df]['uom']=='?F'),'uom']='Deg. C'\n",
    "\n",
    "dfs[vitals_df].loc[\n",
    "    (dfs[vitals_df]['label']=='TempF'),'label']='temperature'\n",
    "\n",
    "dfs[vitals_df].loc[\n",
    "    (dfs[vitals_df]['label']=='TempC'),'label']='temperature'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- glucose max\n",
    "- glucose min\n",
    "- diasBP min\n",
    "- heartrate min\n",
    "- meanart pressure min\n",
    "- RespRate min\n",
    "- SYSbp min\n",
    "- TEMPC min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most likely erroneous value removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#erroneous value cutoff summary\n",
    "## setting a conservative threshold for erroneous values to not skew my data.\n",
    "\n",
    "(dfs[vitals_df].loc[(dfs[vitals_df].loc[:,'icustay_id']==228393.0) &\n",
    "                         (dfs[vitals_df].loc[:,'label']=='Glucose') &\n",
    "                         (dfs[vitals_df].loc[:,'value']>99999), 'value'])=np.nan\n",
    "\n",
    "(dfs[vitals_df].loc[(dfs[vitals_df].loc[:,'label']=='Glucose') &\n",
    "                         (dfs[vitals_df].loc[:,'value']>99998), 'value'])=np.nan\n",
    "\n",
    "(dfs[vitals_df].loc[(dfs[vitals_df].loc[:,'label']=='Glucose') &\n",
    "                         (dfs[vitals_df].loc[:,'value']<15), 'value'])=np.nan\n",
    "\n",
    "(dfs[vitals_df].loc[(dfs[vitals_df].loc[:,'label']=='DiasBP') &\n",
    "                         (dfs[vitals_df].loc[:,'value']<15), 'value'])=np.nan\n",
    "\n",
    "(dfs[vitals_df].loc[(dfs[vitals_df].loc[:,'label']=='HeartRate') &\n",
    "                         (dfs[vitals_df].loc[:,'value'].between(1,29)), 'value'])=np.nan\n",
    "\n",
    "(dfs[vitals_df].loc[(dfs[vitals_df].loc[:,'label']=='RespRate') &\n",
    "                         (dfs[vitals_df].loc[:,'value']<4), 'value'])=np.nan\n",
    "\n",
    "(dfs[vitals_df].loc[(dfs[vitals_df].loc[:,'label']=='SysBP') &\n",
    "                         (dfs[vitals_df].loc[:,'value']<40), 'value'])=np.nan\n",
    "\n",
    "(dfs[vitals_df].loc[(dfs[vitals_df].loc[:,'label']=='TempC') &\n",
    "                         (dfs[vitals_df].loc[:,'value']<28), 'value'])=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[vitals_df] = dfs[vitals_df].loc[dfs[vitals_df]['value'].notnull(),:]#.count() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(dfs[vitals_df], 'vitals')\n",
    "del(dfs[vitals_df])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# labs -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[labs_df]= dfs[labs_df].rename(\n",
    "    columns={'valuenum':'value'}) #changing valuenum to value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[labs_df].groupby('label')['uom'].value_counts() #looks good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most likely erroneous value removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary value removal- was explored and coded adhoc, difficult to automate\n",
    "(dfs[labs_df].loc[\n",
    "    (dfs[labs_df].loc[:,'icustay_id']==261887) & \n",
    "    (dfs[labs_df].loc[:,'label']=='CHLORIDE')\n",
    "    & (dfs[labs_df].loc[:,'value']==3.4),'value'])=np.nan\n",
    "\n",
    "(dfs[labs_df].loc[\n",
    "    (dfs[labs_df].loc[:,'icustay_id']==236290) & \n",
    "    (dfs[labs_df].loc[:,'label']=='CHLORIDE')\n",
    "    & (dfs[labs_df].loc[:,'value']==11.0),'value'])=np.nan\n",
    "\n",
    "(dfs[labs_df].loc[\n",
    "    (dfs[labs_df].loc[:,'icustay_id']==292769) & \n",
    "    (dfs[labs_df].loc[:,'label']=='INR')\n",
    "    & (dfs[labs_df].loc[:,'value']==28.1),'value'])=np.nan\n",
    "\n",
    "(dfs[labs_df].loc[\n",
    "    (dfs[labs_df].loc[:,'icustay_id']==298457) & \n",
    "    (dfs[labs_df].loc[:,'label']=='INR')\n",
    "    & (dfs[labs_df].loc[:,'value']==48.8),'value'])=np.nan\n",
    "\n",
    "(dfs[labs_df].loc[\n",
    "    (dfs[labs_df].loc[:,'icustay_id']==234174) & \n",
    "    (dfs[labs_df].loc[:,'label']=='INR')\n",
    "    & (dfs[labs_df].loc[:,'value']==48.7),'value'])=np.nan\n",
    "\n",
    "(dfs[labs_df].loc[\n",
    "    (dfs[labs_df].loc[:,'icustay_id']==290264) & \n",
    "    (dfs[labs_df].loc[:,'label']=='INR')\n",
    "    & (dfs[labs_df].loc[:,'value']==42.0),'value'])=np.nan\n",
    "\n",
    "(dfs[labs_df].loc[\n",
    "    (dfs[labs_df].loc[:,'icustay_id']==290264) & \n",
    "    (dfs[labs_df].loc[:,'label']=='INR')\n",
    "    & (dfs[labs_df].loc[:,'value']==22.8),'value'])=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[labs_df]= dfs[labs_df].loc[dfs[labs_df].loc[:,'value'].notnull(),:] #removing null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[labs_df].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing unwanted values\n",
    "unwanted_values= ['HEMATOCRIT','ANION GAP','PT','ALBUMIN']\n",
    "dfs[labs_df]= dfs[labs_df].loc[~dfs[labs_df].loc[:,'label'].isin(unwanted_values),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# factorizing bands start \n",
    "* converting bands into a categorical variable since it is very sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# yn_convert_band(max_bands, #df in format where each row corresponds to a test, and a patient can have many rows\n",
    "def yn_convert_band(df,           \n",
    "                    label_fill=\"absent\",\n",
    "                    threshold=10,\n",
    "                    pt= final_pt_df2,\n",
    "                    time_var='t_0',\n",
    "                    value_fill=9999,\n",
    "                    delta_fill=pd.to_timedelta('0 days'),\n",
    "                    uom_fill='y/n'):\n",
    "    \n",
    "    yn_df = pd.merge(pt[['icustay_id','hadm_id','subject_id', time_var]],\n",
    "                      df[['icustay_id','value','label','uom','delta']],\n",
    "                     left_on= 'icustay_id',\n",
    "                     right_on= 'icustay_id',\n",
    "                      how='left') #merging all icustay_id's with time_var, where value,label,uom, and delta are nan's if no value exists for that icustay. \n",
    "    #the idea is that if any value exists then it is pos.\n",
    "\n",
    "    yn_df['value']= yn_df['value'].fillna(value_fill) #converts na to 0 in above na rows.\n",
    "    criteria0=yn_df.loc[:,'value']==value_fill\n",
    "    criteria1=pd.to_numeric(yn_df.loc[:,'value'])<=threshold\n",
    "    criteria2=pd.to_numeric(yn_df.loc[:,'value'])>threshold\n",
    "\n",
    "\n",
    "    yn_df.loc[criteria1, 'value']= \"<{}\".format(threshold) \n",
    "    yn_df.loc[criteria2, 'value']= \">{}\".format(threshold) \n",
    "    yn_df.loc[criteria0, 'value']= \"absent\"\n",
    "\n",
    "    yn_df['delta']= yn_df['delta'].fillna(delta_fill)\n",
    "    yn_df['delta']= pd.to_timedelta(yn_df['delta']) #filling in the time delta to time =0 for filled rows\n",
    "    yn_df['uom']= yn_df['uom'].fillna(uom_fill)\n",
    "    yn_df.loc[yn_df.loc[:,'uom']!=uom_fill, 'uom']= uom_fill\n",
    "    yn_df['label']= yn_df['label'].fillna(label_fill)\n",
    "    \n",
    "    return(yn_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_df=dfs[labs_df][dfs[labs_df]['label']=='BANDS']\n",
    "max_bands=band_df.loc[band_df.groupby('icustay_id', as_index=False)['value'].idxmax(),:]\n",
    "del(band_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_cat=yn_convert_band(df=max_bands,           \n",
    "                    label_fill=\"BANDS\",\n",
    "                    threshold=10,\n",
    "                    pt= final_pt_df2,\n",
    "                    time_var='t_0',\n",
    "                    value_fill=9999,\n",
    "                    delta_fill=pd.to_timedelta('0 days'),\n",
    "                    uom_fill='y/n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop bands from lab_df\n",
    "dfs[labs_df]=dfs[labs_df].drop(dfs[labs_df][dfs[labs_df]['label']=='BANDS'].index)\n",
    "\n",
    "##dropping charttime, may be problematic later.\n",
    "dfs[labs_df]=dfs[labs_df].drop('charttime', axis=1)\n",
    "\n",
    "#appending categorical bands \n",
    "dfs[labs_df]=dfs[labs_df].append(band_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[labs_df].loc[dfs[labs_df]['label']=='BANDS','value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(dfs[labs_df]).to_csv(Path(\n",
    "#     save_path+'/%s_labs_prepped.csv' %(date)))\n",
    "\n",
    "save_df(dfs[labs_df], 'labs')\n",
    "del(dfs[labs_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vent category -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[vent_df]['icustay_id'].nunique()\n",
    "#13978 patients with someform of vent data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[vent_df]['uom']='mech/O2/none category'\n",
    "dfs[vent_df].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[vent_df]=dfs[vent_df].rename(index=str, columns={'day':'delta'})\n",
    "dfs[vent_df]['label']='vent_recieved'\n",
    "dfs[vent_df]['delta']=pd.to_timedelta(dfs[vent_df]['delta'], unit='d')\n",
    "#dfs[vent_df]= dfs[vent_df].drop(columns=['day'], axis=1) #removing day column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[vent_df].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapsing into 1 column for 3 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vent_day_collapser(x):\n",
    "    if 'Mech' in list(x.unique()):\n",
    "        x= 'Mech'\n",
    "    elif 'Oxygen' in list(x.unique()):\n",
    "        x= 'Oxygen'\n",
    "    else:\n",
    "        x='None'\n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collapsing all days into the worst day. \n",
    "ventcategory_1day_df= dfs[vent_df].copy()\n",
    "ventcategory_1day_df['value']=ventcategory_1day_df.groupby('icustay_id',as_index=False)['value'].transform(vent_day_collapser)\n",
    "ventcategory_1day_df= ventcategory_1day_df.drop_duplicates(['icustay_id','value']).sort_values('icustay_id') #\n",
    "ventcategory_1day_df= ventcategory_1day_df.loc[ventcategory_1day_df.loc[:,'icustay_id'].isin(icustay_id),:] #had icustay ids not in final cohort, fail safe mesure\n",
    "#ventcategory_1day_df['label']= 'vent_recieved'\n",
    "ventcategory_1day_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventcategory_1day_df['value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(ventcategory_1day_df).to_csv(Path(\n",
    "#     save_path+'/%s_ventcategory_prepped.csv' %(date)))\n",
    "\n",
    "save_df(ventcategory_1day_df, 'ventcategory')\n",
    "del(ventcategory_1day_df,dfs[vent_df] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## weight and height firstday -\n",
    "i explored weightdurations and it had more missing values than weightfirstday, so i will use that. we can revisit this if we need longitudinal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[weight_df]['uom']='kg'\n",
    "dfs[weight_df].head()  \n",
    "#weight column is the conglomerate of weight_admin>weight_daily> weight_echoinhosp> weight_echoprehosp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[weight_df]= dfs[weight_df][dfs[weight_df]['weight'].notnull()]\n",
    "dfs[weight_df]= dfs[weight_df][['icustay_id','weight','uom']]\n",
    "\n",
    "dfs[weight_df]['label']= 'weight'\n",
    "dfs[weight_df]=dfs[weight_df].rename(index=str, columns={'weight':'value'})\n",
    "\n",
    "#adding the assumed first day delta column to standardize all columns\n",
    "dfs[weight_df]['delta']=pd.to_timedelta(0,'days')\n",
    "\n",
    "#adding t_0\n",
    "dfs[weight_df]= pd.merge(dfs[weight_df], final_pt_df2[['icustay_id',time_var]], left_on='icustay_id', right_on='icustay_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(dfs[weight_df]).to_csv(Path(\n",
    "#     save_path+'/%s_weight_prepped.csv' %(date)))\n",
    "save_df(dfs[weight_df], 'weight')\n",
    "\n",
    "del(dfs[weight_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[height_df]['uom']='cm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[height_df]= dfs[height_df][dfs[height_df]['height'].notnull()]\n",
    "dfs[height_df]= dfs[height_df][['icustay_id','height','uom']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[height_df]['label']= 'height'\n",
    "dfs[height_df]=dfs[height_df].rename(index=str, columns={'height':'value'})\n",
    "\n",
    "#adding the assumed first day delta column to standardize all columns\n",
    "dfs[height_df]['delta']=pd.to_timedelta(0,'days')\n",
    "#adding t_0\n",
    "dfs[height_df]= pd.merge(dfs[height_df], final_pt_df2[['icustay_id',time_var]], left_on='icustay_id', right_on='icustay_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heightfirstday\n",
    "save_df(dfs[height_df], 'height')\n",
    "del(dfs[height_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[uti_df]['value'].unique()#seems good #all uti within clinical timewindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[uti_df]= dfs[uti_df].loc[(dfs[uti_df].loc[:,'value']!='NEG')&\n",
    "               dfs[uti_df].loc[:,'value'].notnull(),:] #filter to only pos rows\n",
    "\n",
    "dfs[uti_df]= dfs[uti_df].loc[(dfs[uti_df].loc[:,'value']!='COMPUTER NETWORK FAILURE. TEST NOT RESULTED.')&\n",
    "               dfs[uti_df].loc[:,'value'].notnull(),:] #filter to only pos rows\n",
    "dfs[uti_df]= dfs[uti_df].drop_duplicates(subset=['hadm_id','value','charttime'])\n",
    "\n",
    "dfs[uti_df].loc[dfs[uti_df].loc[:,'value'].notnull(),'value']= 1\n",
    "dfs[uti_df].loc[dfs[uti_df].loc[:,'value'].isna(),'value']= 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[uti_df].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uti_categorizer(uti_df):\n",
    "    \"useful to get all rows of days with positive values for patients (if multiple pos in a day there will be only 1 row for that day). ie more longitudinal format \"\n",
    "    \n",
    "    #gives the max pos or neg value per day for \n",
    "    df_timewindow_perday=uti_df.groupby(['hadm_id','delta'], as_index=False)['value'].agg({'value':'max'})  \n",
    "    df_timewindow_perday= pd.merge(df_timewindow_perday,final_pt_df2[['icustay_id','hadm_id', time_var]], left_on='hadm_id', right_on='hadm_id', how='left')\n",
    "    df_timewindow_perday=df_timewindow_perday.sort_values(['hadm_id','value','delta'], ascending=[True,False,True])\n",
    "    return(df_timewindow_perday)\n",
    "\n",
    "def uti_collapser(uti_df, label):\n",
    "    \"collapsing longitudinal data into 1 value. will return pos or neg if patient has a positive uti in their stay. one row per icustay_id\"\n",
    "    \n",
    "    df_timewindow_perday=uti_df.groupby(['hadm_id','delta'], as_index=False)['value'].agg({'value':'max'})\n",
    "    first_pos= df_timewindow_perday.drop_duplicates(['hadm_id'])\n",
    "    collapsed= pd.merge(final_pt_df2[['hadm_id','icustay_id','subject_id', time_var]],first_pos, left_on='hadm_id', right_on='hadm_id', how='left')\n",
    "    \n",
    "    collapsed['value']= collapsed['value'].fillna(0)\n",
    "    collapsed.loc[collapsed.loc[:,'value']==1,'value']= 'pos'\n",
    "    collapsed.loc[collapsed.loc[:,'value']==0,'value']= 'Neg/Not_tested'\n",
    "    \n",
    "    collapsed['delta']= collapsed['delta'].fillna(pd.Timedelta(1, unit='d'))\n",
    "    \n",
    "    collapsed['label']= label\n",
    "    \n",
    "    collapsed['uom']='pos/neg category'\n",
    "    return(collapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uti_nit_pos= dfs[uti_df][dfs[uti_df]['label']==\"Nitrite\"]\n",
    "uti_leuk_pos= dfs[uti_df][dfs[uti_df]['label']==\"Leukocytes\"]\n",
    "\n",
    "leuk_collapsed= uti_collapser(uti_leuk_pos, 'leukocyte')\n",
    "nit_collapsed= uti_collapser(uti_nit_pos, 'nitrite')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(leuk_collapsed, 'leuk')\n",
    "del(leuk_collapsed)\n",
    "\n",
    "save_df(nit_collapsed, 'nit')\n",
    "del(nit_collapsed)\n",
    "del(dfs[uti_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bloodgas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[bg_df]= dfs[bg_df].loc[dfs[bg_df]['value'].notnull(),:]\n",
    "dfs[bg_df] = dfs[bg_df].rename(index=str, columns={'valueuom':'uom'})\n",
    "dfs[bg_df]= dfs[bg_df].loc[~(dfs[bg_df].loc[:,'value']=='.'),:]\n",
    "\n",
    "#may need to remove outliers, haven't done as of 10/22/18\n",
    "dfs[bg_df].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most likely erroneous value removal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##calcium\n",
    "#fixing the calcium errors w/o hard coding\n",
    "(dfs[bg_df].loc[\n",
    "    (dfs[bg_df].loc[:,'icustay_id']==249571) & \n",
    "    (dfs[bg_df].loc[:,'label']=='CALCIUM')\n",
    "    & (dfs[bg_df].loc[:,'valuenum']==94.00),'valuenum'])=0.94#.where('valuenum'==94.00))\n",
    "\n",
    "(dfs[bg_df].loc[\n",
    "    (dfs[bg_df].loc[:,'icustay_id']==249571) & \n",
    "    (dfs[bg_df].loc[:,'label']=='CALCIUM')\n",
    "    & (dfs[bg_df].loc[:,'value']=='094'),'value'])=0.94#.where('valuenum'==94.00))\n",
    "\n",
    "\n",
    "(dfs[bg_df].loc[\n",
    "    (dfs[bg_df].loc[:,'icustay_id']==219600) & \n",
    "    (dfs[bg_df].loc[:,'label']=='CALCIUM')\n",
    "    & (dfs[bg_df].loc[:,'valuenum']==97.00),'valuenum'])=0.97#.where('valuenum'==94.00))\n",
    "\n",
    "(dfs[bg_df].loc[\n",
    "    (dfs[bg_df].loc[:,'icustay_id']==219600) & \n",
    "    (dfs[bg_df].loc[:,'label']=='CALCIUM')\n",
    "    & (dfs[bg_df].loc[:,'value']=='097'),'value'])=0.97#.where('valuenum'==94.00))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##min chloride\n",
    "#converting it to a null value without hard coding\n",
    "(dfs[bg_df].loc[(dfs[bg_df].loc[:,'icustay_id']==261887.0) &\n",
    "                         (dfs[bg_df].loc[:,'label']=='CHLORIDE') &\n",
    "                         (dfs[bg_df].loc[:,'valuenum']==3.4),'value'])=np.nan\n",
    "#converting it to a null value without hard coding\n",
    "(dfs[bg_df].loc[(dfs[bg_df].loc[:,'icustay_id']==261887.0) &\n",
    "                         (dfs[bg_df].loc[:,'label']=='CHLORIDE') &\n",
    "                         (dfs[bg_df].loc[:,'valuenum']==3.4),'valuenum'])=np.nan\n",
    "\n",
    "#changing the values without hard coding. \n",
    "(dfs[bg_df].loc[(dfs[bg_df].loc[:,'icustay_id']==236290.0) &\n",
    "                         (dfs[bg_df].loc[:,'label']=='CHLORIDE') &\n",
    "                         (dfs[bg_df].loc[:,'valuenum']==11.0),'valuenum'])=np.nan\n",
    "\n",
    "(dfs[bg_df].loc[(dfs[bg_df].loc[:,'icustay_id']==236290.0) &\n",
    "                         (dfs[bg_df].loc[:,'label']=='CHLORIDE') &\n",
    "                         (dfs[bg_df].loc[:,'valuenum']==11.0),'value'])=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#peep changes summary: \n",
    "dfs[bg_df].loc[(dfs[bg_df].loc[:,'label']=='PEEP')&\n",
    "                        (dfs[bg_df]['valuenum']>38),'valuenum']=np.nan #remove this or set to 50?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp changes summary:\n",
    "\n",
    "dfs[bg_df].loc[(dfs[bg_df].loc[:,'label']=='TEMPERATURE')&\n",
    "                        (dfs[bg_df]['icustay_id']==253821)&\n",
    "                        (dfs[bg_df]['valuenum']==18.9),\n",
    "                        'value']= np.nan\n",
    "\n",
    "dfs[bg_df].loc[(dfs[bg_df].loc[:,'label']=='TEMPERATURE')&\n",
    "                        (dfs[bg_df]['icustay_id']==253821)&\n",
    "                        (dfs[bg_df]['valuenum']==18.9),\n",
    "                        'valuenum']= np.nan\n",
    "\n",
    "dfs[bg_df].loc[(dfs[bg_df].loc[:,'label']=='TEMPERATURE')&\n",
    "                        (dfs[bg_df]['icustay_id']==251788)&\n",
    "                        (dfs[bg_df]['valuenum']==10.0),\n",
    "                        'value']= np.nan\n",
    "\n",
    "dfs[bg_df].loc[(dfs[bg_df].loc[:,'label']=='TEMPERATURE')&\n",
    "                        (dfs[bg_df]['icustay_id']==251788)&\n",
    "                        (dfs[bg_df]['valuenum']==10.0),\n",
    "                        'valuenum']= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fio2 changes summary:\n",
    "\n",
    "##converting a few values to null, thus removing them from the dataset\n",
    "dfs[bg_df].loc[(dfs[bg_df].loc[:,'label']=='FIO2') &\n",
    "                        (dfs[bg_df].loc[:,'value']=='0'),'value']=np.nan\n",
    "\n",
    "dfs[bg_df].loc[(dfs[bg_df].loc[:,'label']=='FIO2') &\n",
    "                        (dfs[bg_df].loc[:,'value']=='-'),'value']=np.nan\n",
    "\n",
    "\n",
    "##removing all fio2 values between 1-20.9\n",
    "\n",
    "dfs[bg_df].loc[(dfs[bg_df].loc[:,'label'].isin(['FIO2']))&\n",
    "                        (dfs[bg_df]['valuenum'].between(1.0,20.9)),'valuenum']=np.nan\n",
    "\n",
    "\n",
    "##values between 0-1 were found to be ratios, not %, so converting these to % \n",
    "\n",
    "dfs[bg_df].loc[(dfs[bg_df].loc[:,'label'].isin(['FIO2']))&\n",
    "                        (dfs[bg_df]['valuenum'].between(1.0,20.9)),'valuenum']=np.nan\n",
    "\n",
    "fio2_dec= dfs[bg_df].loc[(dfs[bg_df].loc[:,'label'].isin(['FIO2']))&\n",
    "                        (dfs[bg_df]['valuenum'].between(0.0,1.0)),'valuenum']\n",
    "\n",
    "dfs[bg_df].loc[(dfs[bg_df].loc[:,'label'].isin(['FIO2']))&\n",
    "                        (dfs[bg_df]['valuenum'].between(0.0,1.0)),'valuenum'] = fio2_dec *100\n",
    "\n",
    "del(fio2_dec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### removing null values annotated abov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[bg_df]= dfs[bg_df].loc[dfs[bg_df]['value'].notnull(),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### splitting specimen out for vent vs non-vent bg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding specimen tag to filter only arterial samples for vent data. \n",
    "specimen_df= dfs[bg_df].loc[dfs[bg_df].loc[:,'label']=='SPECIMEN',['unique_var','label','value']]#unique()\n",
    "specimen_df=specimen_df.rename(index=str, columns={'value':'specimen'})\n",
    "specimen_df=specimen_df.loc[specimen_df.loc[:,\"specimen\"]=='ART',:]\n",
    "\n",
    "dfs[bg_df]= pd.merge(dfs[bg_df],specimen_df[['unique_var','specimen']], left_on='unique_var', right_on='unique_var', how='left')\n",
    "bg_ART_nosummary=dfs[bg_df].loc[dfs[bg_df].loc[:,'specimen']=='ART',:]\n",
    "del(specimen_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_labels=['PH','LACTATE','CALCIUM','TEMPERATURE','POTASSIUM',\n",
    "           'GLUCOSE','HEMOGLOBIN','SODIUM','CHLORIDE','BICARBONATE']\n",
    "bg_vent_labels=['PCO2','PaO2','PO2','FIO2','PEEP','O2FLOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restricting to tests that were chosen to be analysed based on %missingness and clinical relevance\n",
    "dfs[bg_df]= dfs[bg_df].loc[dfs[bg_df].loc[:,'label'].isin(bg_labels),:]\n",
    "bg_ART_nosummary= bg_ART_nosummary.loc[bg_ART_nosummary.loc[:,'label'].isin(bg_vent_labels),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[bg_df].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_col=['subject_id','hadm_id','icustay_id','charttime','delta',time_var,'label','valuenum','uom']\n",
    "bg_ART_nosummary= bg_ART_nosummary[bg_col]\n",
    "dfs[bg_df]= dfs[bg_df][bg_col]\n",
    "del(bg_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_ART_nosummary['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting O2 to y/n\n",
    "o2_flow_df= bg_ART_nosummary.loc[bg_ART_nosummary.loc[:,'label']=='O2FLOW',:]\n",
    "o2_flow_df=o2_flow_df.rename(index=str, columns={'valuenum':'value'})\n",
    "o2_flow_df= yn_convert(o2_flow_df, label_fill='o2_flow', time_var=time_var)\n",
    "o2_flow_df['label']=\"o2_flow\" #fixing label\n",
    "\n",
    "#removing o2_flow from bg_ART\n",
    "bg_ART_nosummary= bg_ART_nosummary.loc[bg_ART_nosummary.loc[:,'label']!='O2FLOW',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_ART_nosummary= bg_ART_nosummary.loc[bg_ART_nosummary.loc[:,'label']!='PEEP',:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PaO2/FiO2 ratio should be calculated using values that are recorded either at the same time stamp, or when the FIO2 occurs within 2 hours BEFORE the PaO2, not the other way around.\n",
    "For those with no FiO2 recorded within that time frame, you can assume it’s 0.21 (=21%). The worse ratio will be the lowest PaO2 recorded with FiO2 of 1.0 (=100%). So if that is 12, then it will be 12/1 = 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to groupby icustay_id and charttime for both. pan\n",
    "pao2= bg_ART_nosummary.loc[bg_ART_nosummary.loc[:,'label']=='PaO2',:].copy() #n=41799 non-null\n",
    "fio2= bg_ART_nosummary.loc[bg_ART_nosummary.loc[:,'label']=='FIO2',:].copy() #n=12311 non-null\n",
    "pao2['delta']=pd.to_timedelta(pao2['delta'])\n",
    "fio2['delta']=pd.to_timedelta(fio2['delta'])\n",
    "pao2['offset']=pao2['delta'] - pd.to_timedelta(2, unit='h') #pao2 should have the offset, not fio2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing pao2 and fio2 from bg_ART_nosummary\n",
    "bg_ART_nosummary= bg_ART_nosummary.loc[bg_ART_nosummary.loc[:,'label']!='PaO2',:]\n",
    "bg_ART_nosummary= bg_ART_nosummary.loc[bg_ART_nosummary.loc[:,'label']!='FIO2',:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* need to find the fio2 values that occur between(delta-2hr, delta) of pao2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## testing new shit\n",
    "pao2_fio2_windowed= pd.merge(pao2,\n",
    "              fio2[['icustay_id','valuenum','label','charttime','delta']].rename(index=str, columns={'valuenum':'valuenum2','label':'label2','charttime':'charttime2','delta':'delta2'}),\n",
    "              left_on='icustay_id',\n",
    "              right_on='icustay_id',\n",
    "              how='left') #\n",
    "\n",
    "pao2_fio2_windowed= pao2_fio2_windowed[pd.to_timedelta(pao2_fio2_windowed['delta2']).between(pd.to_timedelta(pao2_fio2_windowed['offset']),pd.to_timedelta(pao2_fio2_windowed['delta']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grabes from both\n",
    "pao2_fio2_windowed['delta']=pd.to_timedelta(pao2_fio2_windowed['delta'])\n",
    "pao2_fio2_windowed['offset']=pd.to_timedelta(pao2_fio2_windowed['delta'])\n",
    "ratio_df= pd.merge(pao2, pao2_fio2_windowed[['icustay_id','delta','valuenum2', 'charttime2']], on=['icustay_id','delta'], how='left')\n",
    "del(pao2_fio2_windowed, pao2,fio2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i merged in all rows that matched the 2hr criteria\n",
    "## For those with no FiO2 recorded within that time frame, you can assume it’s 0.21 (=21%). \n",
    "ratio_df.loc[ratio_df.loc[:,'valuenum2'].isnull(),'valuenum2']= 21\n",
    "ratio_df['ratio']= ratio_df['valuenum']/(ratio_df['valuenum2']/100)\n",
    "ratio_df.loc[ratio_df['charttime2'].isnull(),'charttime2']= ratio_df.loc[ratio_df['charttime2'].isnull(),'charttime']\n",
    "ratio_df['deltadelta']=pd.to_datetime(ratio_df['charttime'])-pd.to_datetime(ratio_df['charttime2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df['ratio'].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df['valuenum'].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df['valuenum'].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### all of the duplicate PaO2 with different FIo2. if a pao2 value has 2 fio2 values that match the 2 hour window, then the one closest time to the fio2 value is chosen. \n",
    "ratio_df=ratio_df.sort_values(['icustay_id','delta','deltadelta']).drop_duplicates(['icustay_id','delta','ratio'])\n",
    "#43715 ->42455"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df['ratio'].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df['valuenum'].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.99])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_df['valuenum'].describe(percentiles=[0.1, 0.25, 0.5, 0.75, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding worst value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#QC & finding worst value:\n",
    "ratio_df[ratio_df['icustay_id']==200014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio_df.groupby(['icustay_id'], as_index=False)['ratio'].min() #is this what i want for my pao2/fio2 ratio?\n",
    "\n",
    "f = {'ratio': 'min','delta':'first'}\n",
    "ratio_min_df=ratio_df.sort_values(['icustay_id','ratio'],ascending=True).groupby('icustay_id', as_index=False).agg(f)\n",
    "\n",
    "##it's likely that this variable will not explain any additional variation in y than the ventilation category variable we already have. \n",
    "##maybe we can stratify patients with a few categories:\n",
    "\n",
    "##not on vent\n",
    "##being on vent with normal pao2/fio2 ratio\n",
    "## being on vent with low pao2/fio2 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_min_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_min_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pt_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ratio_min_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_min_df= pd.merge(final_pt_df2[['icustay_id','hadm_id','t_0',]],ratio_min_df, left_on='icustay_id',right_on='icustay_id', how='left')\n",
    "ratio_min_df= ratio_min_df.rename(index=str, columns={'ratio':'value'})\n",
    "\n",
    "ratio_min_df.loc[ratio_min_df.loc[:,'value'].isnull(),'value']=476\n",
    "\n",
    "ratio_min_df['uom']= 'PaO2/FIO2 ratio'\n",
    "ratio_min_df['label']= 'pao2fio2Ratio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_min_df.loc[:,'delta']=ratio_min_df.loc[:,'delta'].fillna(pd.to_timedelta('0 days'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_min_df['value'].describe()#100 PaO2 on 21% FiO2 = 476 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_min_df.head() #100 PaO2 on 21% FiO2 = 476 ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# factorizing pco2 start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# yn_convert_band(max_bands, #df in format where each row corresponds to a test, and a patient can have many rows\n",
    "def yn_convert_pco2(df=max_bands,           \n",
    "                    label_fill=\"absent\",\n",
    "                    threshold=10,\n",
    "                    pt= final_pt_df2,\n",
    "                    time_var='t_0',\n",
    "                    value_fill=9999,\n",
    "                    delta_fill=pd.to_timedelta('0 days'),\n",
    "                    uom_fill='y/n'):\n",
    "    \n",
    "    yn_df = pd.merge(pt[['icustay_id','hadm_id','subject_id', time_var]],\n",
    "                      df[['icustay_id','value','label','uom','delta']],\n",
    "                     left_on= 'icustay_id',\n",
    "                     right_on= 'icustay_id',\n",
    "                      how='left') #merging all icustay_id's with time_var, where value,label,uom, and delta are nan's if no value exists for that icustay. \n",
    "    #the idea is that if any value exists then it is pos.\n",
    "\n",
    "    yn_df['value']= yn_df['value'].fillna(value_fill) #converts na to 0 in above na rows.\n",
    "    criteria0=yn_df.loc[:,'value']==value_fill\n",
    "    criteria1=pd.to_numeric(yn_df.loc[:,'value'])<=threshold\n",
    "    criteria2=pd.to_numeric(yn_df.loc[:,'value'])>threshold\n",
    "\n",
    "\n",
    "    yn_df.loc[criteria1, 'value']= \"<{}\".format(threshold) \n",
    "    yn_df.loc[criteria2, 'value']= \">{}\".format(threshold) \n",
    "    yn_df.loc[criteria0, 'value']= \"absent\"\n",
    "\n",
    "    yn_df['delta']= yn_df['delta'].fillna(delta_fill)\n",
    "    yn_df['delta']= pd.to_timedelta(yn_df['delta']) #filling in the time delta to time =0 for filled rows\n",
    "    yn_df['uom']= yn_df['uom'].fillna(uom_fill)\n",
    "    yn_df.loc[yn_df.loc[:,'uom']!=uom_fill, 'uom']= uom_fill\n",
    "    yn_df['label']= yn_df['label'].fillna(label_fill)\n",
    "    \n",
    "    return(yn_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_ART_nosummary= bg_ART_nosummary.rename(\n",
    "    columns={'valuenum':'value'}) #changing valuenum to value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pco2_df=bg_ART_nosummary[bg_ART_nosummary['label']=='PCO2']\n",
    "max_bands=pco2_df.loc[pco2_df.groupby('icustay_id', as_index=False)['value'].idxmax(),:]\n",
    "del(pco2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pco2_cat=yn_convert_band(df=max_bands,           \n",
    "                    label_fill=\"PCO2\",\n",
    "                    threshold=50,\n",
    "                    pt= final_pt_df2,\n",
    "                    time_var='t_0',\n",
    "                    value_fill=9999,\n",
    "                    delta_fill=pd.to_timedelta('0 days'),\n",
    "                    uom_fill='y/n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop bands from lab_df\n",
    "bg_ART_nosummary=bg_ART_nosummary.drop(bg_ART_nosummary[bg_ART_nosummary['label']=='PCO2'].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##dropping charttime, may be problematic later. 06/13/19\n",
    "bg_ART_nosummary=bg_ART_nosummary.drop('charttime', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_ART_nosummary=bg_ART_nosummary.append(pco2_cat, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_ART_nosummary.loc[bg_ART_nosummary['label']=='PCO2','value'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# factorizing bands end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(ratio_min_df,'pafaRatio') # minimum pao2:fio2 ratio during a stay\n",
    "del(ratio_min_df)\n",
    "\n",
    "save_df(dfs[bg_df],'bg_all') #all bloodgas\n",
    "del(dfs[bg_df])\n",
    "\n",
    "save_df(bg_ART_nosummary,'bg_ART') #only ARTERIAL bloodgas\n",
    "del(bg_ART_nosummary)\n",
    "\n",
    "save_df(o2_flow_df,'o2_flow') #need to investigate this more\n",
    "del(o2_flow_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing null values\n",
    "dfs[rrt_df] = dfs[rrt_df].loc[dfs[rrt_df]['rrt'].notnull(),:]\n",
    "dfs[rrt_df]['uom']='category'\n",
    "dfs[rrt_df]['delta']=pd.to_timedelta(\n",
    "    pd.to_datetime(dfs[rrt_df]['first_charttime'])-\n",
    "    pd.to_datetime(dfs[rrt_df][time_var]),\n",
    "    'days')\n",
    "dfs[rrt_df]['label']= 'rrt'\n",
    "dfs[rrt_df]=dfs[rrt_df].rename(index=str, columns={'rrt':'value'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### converting to yes/no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[rrt_df].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[rrt_df]['icustay_id'].nunique() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrt_yn= yn_convert(dfs[rrt_df],label_fill='rrt', time_var=time_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(rrt_yn, 'rrt')\n",
    "del(rrt_yn, dfs[rrt_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCS_72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[gcs_df]['uom']='GCS_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(dfs[gcs_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[gcs_df]['label']= 'mingcs'\n",
    "dfs[gcs_df]['uom']='gcs_score'\n",
    "dfs[gcs_df]=dfs[gcs_df].rename(index=str, columns={'mingcs':'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[gcs_df]=dfs[gcs_df][['subject_id','hadm_id','icustay_id','delta','label','value',time_var,'uom']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(dfs[gcs_df], 'gcs')\n",
    "del(dfs[gcs_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOFA\n",
    "i'm going to remove all sofa variables except daily score, as we have other markers for those in our above data\n",
    "i may later use this as qc check.\n",
    "also added delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[sofa_df]['uom']='daily_sofa_score'\n",
    "\n",
    "#adding day delta column\n",
    "dfs[sofa_df]=dfs[sofa_df].sort_values(['hadm_id','day',time_var]) #good\n",
    "dfs[sofa_df]['day_rank']=dfs[sofa_df].groupby('icustay_id')['day'].rank()\n",
    "dfs[sofa_df]['delta']=pd.to_timedelta((dfs[sofa_df]['day_rank']-1), 'days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[sofa_df]['label']= 'daily_sofa'\n",
    "dfs[sofa_df]=dfs[sofa_df].rename(index=str, columns={'sofa':'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[sofa_df]= dfs[sofa_df][['subject_id','hadm_id','icustay_id','delta','label','value',time_var,'uom']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[sofa_df].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df(dfs[sofa_df], 'sofa')\n",
    "del(dfs[sofa_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# patient Demographic variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#completed in 03.01 clinical_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[pt_info_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##adjusting ages over 90 (which were set to 300 to deidentify) to 90\n",
    "admit_index=dfs[pt_info_df].loc[(dfs[pt_info_df]['label']=='age')].index\n",
    "age_tf=pd.to_numeric(dfs[pt_info_df].loc[admit_index,'value'])>90\n",
    "dfs[pt_info_df].loc[(dfs[pt_info_df]['label']=='age')&(age_tf),'value']=90.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[pt_info_df].loc[admit_index,'value'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfs[pt_info_df].loc[(dfs[pt_info_df]['label']=='first_admit_age') & (dfs[pt_info_df]['value']>90)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#date= '22102018'\n",
    "save_df(dfs[pt_info_df], 'pt_info')\n",
    "\n",
    "del(dfs[pt_info_df] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
