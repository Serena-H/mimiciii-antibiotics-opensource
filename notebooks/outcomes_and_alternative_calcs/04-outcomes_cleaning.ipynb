{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# designed to be run after 03-clinical_variables_final. this notebook does some data cleaning/processing. run before -___ notebook.\n",
    "\n",
    "## cleans many aspects of the raw clinical variables.\n",
    "## collapses and formats all of the various categorical variables into discrete variables as well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "time: 5.44 ms\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1024,\n",
    "        'height': 768,\n",
    "        'scroll': True,\n",
    "})\n",
    "\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 673 µs\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/notebooks/')\n",
    "sys.path.append('/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/notebooks/parameters.py')\n",
    "sys.path.append('/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/notebooks/Exploratory/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.1 ms\n"
     ]
    }
   ],
   "source": [
    "#patients of interest from rotation_cohort_generation\n",
    "from parameters import final_pt_df_v, date, repository_path\n",
    "\n",
    "#patients of interest from rotation_cohort_generation\n",
    "final_pt_df2 = final_pt_df_v.copy()\n",
    "del(final_pt_df_v)\n",
    "\n",
    "patients= list(final_pt_df2['subject_id'].unique())\n",
    "hadm_id= list(final_pt_df2['hadm_id'].unique())\n",
    "icustay_id= list(final_pt_df2['icustay_id'].unique())\n",
    "icustay_id= [int(x) for x in icustay_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C_neg/A_partial    7867\n",
       "C_neg/A_full       7401\n",
       "C_pos/A_full       2438\n",
       "C_pos/A_partial    1927\n",
       "Name: final_bin, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.04 ms\n"
     ]
    }
   ],
   "source": [
    "final_pt_df2['final_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting clinical data for our patients\n",
    "## IMPORTANT, USE THIS TO TUNE TIMEWINDOW OF EXTRACTION AND FOLDER TO SAVE IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#NOTE ON MY DF NAMING CONVENTION:\n",
    "origionally when I coded this workbook, it was for 72 hour timewindows, so every dataframe had _72 at the end. this was changed on 6/5/19 and was made more generalizable by finding name of each corresponding df in the df list and using this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 574 µs\n"
     ]
    }
   ],
   "source": [
    "from parameters import date, time_col, time_var, patient_df, save_boolean\n",
    "folder='30_day_window'\n",
    "lower_window=0\n",
    "upper_window=30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### begin pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# changing my code structure to be a dictionary of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.17 ms\n"
     ]
    }
   ],
   "source": [
    "#folder to save files to:\n",
    "save_path= str(repository_path)+'/data/cleaned/'\n",
    "#folder=None\n",
    "\n",
    "\n",
    "def save_df(df, df_name='default', save_path=save_path, add_subfolder=False):\n",
    "    #uses the date and supplied df name and saves to the savepath specified above.\n",
    "    if df_name == 'default':\n",
    "        df_name= \"%s\"%(df)\n",
    "    \n",
    "    address=save_path+'%s/'%(folder)\n",
    "    if not os.path.exists(address):\n",
    "        print(address)\n",
    "        os.makedirs(address)\n",
    "    pd.DataFrame(df).to_csv(Path(address+'%s_%s_prepped.csv' %(date, df_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/cleaned/30_day_window/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.74 ms\n"
     ]
    }
   ],
   "source": [
    "save_path+'%s/'%(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.27 ms\n"
     ]
    }
   ],
   "source": [
    "##folder with all clinical variable csv's\n",
    "allFiles = glob.glob(str(repository_path)+ '/data/raw/%s/'%(folder) + \"{}_*.csv\".format(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/geickelb1/Documents/GitHub/mimiciii-antibiotics-opensource/data/raw/30_day_window/16122019_sofa.csv']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.63 ms\n"
     ]
    }
   ],
   "source": [
    "allFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 452 ms\n"
     ]
    }
   ],
   "source": [
    "#making a dictionary of all my dataframes for easier cycling through\n",
    "\n",
    "df_list=[]\n",
    "for element in allFiles:\n",
    "    df_list.append(element.split('{}_'.format(date))[1].split('.csv')[0]) #making an list of all my dataframes in order they appear in file\n",
    "\n",
    "dfs = {}\n",
    "i=0\n",
    "for name in df_list:\n",
    "    dfs[name] = pd.read_csv(allFiles[i],  index_col=0)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sofa']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.52 ms\n"
     ]
    }
   ],
   "source": [
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 607 µs\n"
     ]
    }
   ],
   "source": [
    "#assigning the appropriate name to each df in a flexible way\n",
    "\n",
    "indices = [i for i, s in enumerate(df_list) if 'sofa' in s]\n",
    "sofa_df= df_list[indices[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n",
      "time: 1.6 ms\n"
     ]
    }
   ],
   "source": [
    "#adding a t_0 to each df that doesn't currently have it\n",
    "\n",
    "for element in df_list:\n",
    "    #print(element,':',list(dfs[element]))\n",
    "    if ('t_0' in list(dfs[element]))==False and 'icustay_id' in list(dfs[element]) :\n",
    "        #print(\"true\")\n",
    "        dfs[element]= pd.merge(dfs[element], final_pt_df2[['icustay_id','t_0']], how='left')\n",
    "    elif ('t_0' in list(dfs[element]))==False and 'hadm_id' in list(dfs[element]) :\n",
    "        #print(\"true\")\n",
    "        dfs[element]= pd.merge(dfs[element], final_pt_df2[['hadm_id','t_0']], how='left')\n",
    "    else:\n",
    "        print(\"false\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sofa : ['subject_id', 'hadm_id', 'icustay_id', 'day', 'sofa', 'respiration', 'pao2fio2_vent_min', 'pao2fio2_novent_min', 'coagulation', 'platelet_min', 'liver', 'bilirubin_max', 'cardiovascular', 'rate_dopamine', 'rate_epinephrine', 'rate_norepinephrine', 'rate_dobutamine', 'meanbp_min', 'cns', 'mingcs', 'renal', 'creatinine_max', 'urineoutput', 't_0', 'icu_admit', 'approx_charttime', 'floor_charttime', 'floor_time_var']\n",
      "time: 661 µs\n"
     ]
    }
   ],
   "source": [
    "for element in df_list:\n",
    "    print(element,':',list(dfs[element]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.52 ms\n"
     ]
    }
   ],
   "source": [
    "from parameters import time_var, value_fill, delta_fill, uom_fill\n",
    "def yn_convert(df, #df in format where each row corresponds to a test, and a patient can have many rows\n",
    "               label_fill, # value that will be filled to na's\n",
    "               pt= final_pt_df2,\n",
    "               time_var=time_var,#'t_0', #\n",
    "               value_fill=value_fill,#0,\n",
    "               delta_fill=delta_fill,# pd.to_timedelta('0 days'),\n",
    "               uom_fill=uom_fill):#'y/n'):\n",
    "\n",
    "    \"\"\"\n",
    "    description: collapses (binarizes) a dataframe where each row corresponds to a test, and a patient can have many rows -> \n",
    "    1 row per patient where value is binary variable yes or no a patient has any value within the timewindow (specified in data collection).\n",
    "    said a different way, for patient this fxn collapses values down to does pt have a non NA value in the clinical time window y/n? \n",
    "    \n",
    "    label_fill: the variable name in the label column of the specified dataframe that will considered for y/n value within timewindow. if any non NA value is present\n",
    "        it will be considered positive.\n",
    "    pt: the by patient spreadsheet be be used to supply patient information.\n",
    "    time_var: the variable used to create the time window of interest.\n",
    "    value_fill: the variable value that missing values will be filled if the value is not present (default =0) in the origional dataset\n",
    "    delta_fill: the time delta value that will be filled in if a patient doesn't have any instances of the label_fill.  \n",
    "    uom_fill: fills in the unit of measurement to this for missing values.\n",
    "    \n",
    "    returns a flat 1 row per icustay_id of 1 or 0 if any value was present for the patient.\n",
    "    \"\"\"\n",
    "    \n",
    "    yn_df = pd.merge(pt[['icustay_id', time_var]],\n",
    "                      df[['icustay_id','value','label','uom','delta']],\n",
    "                     left_on= 'icustay_id',\n",
    "                     right_on= 'icustay_id',\n",
    "                      how='left') #merging all icustay_id's with time_var, where value,label,uom, and delta are nan's if no value exists for that icustay. \n",
    "    #the idea is that if any value exists then it is pos.\n",
    "\n",
    "    yn_df['value']= yn_df['value'].fillna(value_fill) #converts na to 0 in above na rows.\n",
    "    yn_df.loc[yn_df.loc[:,'value']!=value_fill, 'value']= 1 #squashes all other values into a binary 1 = yes\n",
    "    yn_df['delta']= yn_df['delta'].fillna(delta_fill)\n",
    "    yn_df['delta']= pd.to_timedelta(yn_df['delta']) #filling in the time delta to time =0 for filled rows\n",
    "    yn_df['uom']= yn_df['uom'].fillna(uom_fill)\n",
    "    yn_df.loc[yn_df.loc[:,'uom']!=uom_fill, 'uom']= uom_fill\n",
    "    yn_df['label']= yn_df['label'].fillna(label_fill)\n",
    "    ##this is new as of 12-12-19L i think i wasn't truely converting to 1row per icustay id by not droping duplicates filtered on value first (desc) then delta (asc)\n",
    "    yn_df= yn_df.sort_values(['value','delta'], ascending=[False, True]).drop_duplicates(subset='icustay_id',keep='first')\n",
    "    \n",
    "    return(yn_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOFA\n",
    "i'm going to remove all sofa variables except daily score, as we have other markers for those in our above data\n",
    "i may later use this as qc check.\n",
    "also added delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 205 ms\n"
     ]
    }
   ],
   "source": [
    "dfs[sofa_df]['uom']='daily_sofa_score'\n",
    "\n",
    "#adding day delta column\n",
    "dfs[sofa_df]=dfs[sofa_df].sort_values(['hadm_id','day',time_var]) #good\n",
    "dfs[sofa_df]['day_rank']=dfs[sofa_df].groupby('icustay_id')['day'].rank()\n",
    "dfs[sofa_df]['delta']=pd.to_timedelta((dfs[sofa_df]['day_rank']-1), 'days')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 291 ms\n"
     ]
    }
   ],
   "source": [
    "dfs[sofa_df]['label']= 'daily_sofa'\n",
    "dfs[sofa_df]=dfs[sofa_df].rename(index=str, columns={'sofa':'value'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 33.1 ms\n"
     ]
    }
   ],
   "source": [
    "dfs[sofa_df]= dfs[sofa_df][['subject_id','hadm_id','icustay_id','delta','label','value',time_var,'uom']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now to code organ dysfunction free days:\n",
    "\n",
    "algorithm:\n",
    "* sum # of days where daily sofa <1 and a person is alive starting at t_0 and ending at t_0+30.\n",
    "\n",
    "* If the leave the ICU before 30 days and there is no data and they are not dead, you assume their SOFA is 0 until day 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>ssc_charttime</th>\n",
       "      <th>ssc_id</th>\n",
       "      <th>icu_admit</th>\n",
       "      <th>ab_id</th>\n",
       "      <th>ab_start</th>\n",
       "      <th>ab_end</th>\n",
       "      <th>ab_ssc_delta</th>\n",
       "      <th>t_0</th>\n",
       "      <th>t_end</th>\n",
       "      <th>...</th>\n",
       "      <th>dod_ssn</th>\n",
       "      <th>ab_course</th>\n",
       "      <th>org_list</th>\n",
       "      <th>spec_type_list</th>\n",
       "      <th>first_pos_else_neg_ssc</th>\n",
       "      <th>sc_result</th>\n",
       "      <th>final_bin</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>delta</th>\n",
       "      <th>dod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>294638</td>\n",
       "      <td>2191-03-16 00:00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>2191-03-16 00:29:31</td>\n",
       "      <td>1213116</td>\n",
       "      <td>2191-03-16</td>\n",
       "      <td>2191-03-22</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>2191-03-16</td>\n",
       "      <td>2191-03-22</td>\n",
       "      <td>...</td>\n",
       "      <td>NaT</td>\n",
       "      <td>full</td>\n",
       "      <td>STAPH AUREUS COAG +</td>\n",
       "      <td>BLOOD CULTURE</td>\n",
       "      <td>2191-03-16 00:00:00</td>\n",
       "      <td>positive</td>\n",
       "      <td>C_pos/A_full</td>\n",
       "      <td>185777</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220597</td>\n",
       "      <td>2149-11-10 09:40:00</td>\n",
       "      <td>45</td>\n",
       "      <td>2149-11-09 13:07:02</td>\n",
       "      <td>2089126</td>\n",
       "      <td>2149-11-10</td>\n",
       "      <td>2149-11-15</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>2149-11-10</td>\n",
       "      <td>2149-11-15</td>\n",
       "      <td>...</td>\n",
       "      <td>2149-11-14</td>\n",
       "      <td>full</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2149-11-10 09:40:00</td>\n",
       "      <td>negative</td>\n",
       "      <td>C_neg/A_full</td>\n",
       "      <td>150750</td>\n",
       "      <td>0 days</td>\n",
       "      <td>2149-11-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232669</td>\n",
       "      <td>2104-08-11 00:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>2104-08-08 02:08:17</td>\n",
       "      <td>616189</td>\n",
       "      <td>2104-08-11</td>\n",
       "      <td>2104-08-12</td>\n",
       "      <td>0 days 00:00:00.000000000</td>\n",
       "      <td>2104-08-11</td>\n",
       "      <td>2104-08-12</td>\n",
       "      <td>...</td>\n",
       "      <td>2104-08-20</td>\n",
       "      <td>partial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2104-08-11 00:00:00</td>\n",
       "      <td>negative</td>\n",
       "      <td>C_neg/A_partial</td>\n",
       "      <td>112213</td>\n",
       "      <td>0 days</td>\n",
       "      <td>2104-08-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>273430</td>\n",
       "      <td>2108-08-05 20:42:00</td>\n",
       "      <td>69</td>\n",
       "      <td>2108-08-05 16:26:09</td>\n",
       "      <td>2572274</td>\n",
       "      <td>2108-08-06</td>\n",
       "      <td>2108-08-08</td>\n",
       "      <td>1 days 00:00:00.000000000</td>\n",
       "      <td>2108-08-06</td>\n",
       "      <td>2108-08-08</td>\n",
       "      <td>...</td>\n",
       "      <td>2109-08-18</td>\n",
       "      <td>partial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2108-08-05 20:42:00</td>\n",
       "      <td>negative</td>\n",
       "      <td>C_neg/A_partial</td>\n",
       "      <td>109235</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2109-08-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>217847</td>\n",
       "      <td>2134-09-11 09:35:00</td>\n",
       "      <td>70</td>\n",
       "      <td>2134-09-11 20:50:04</td>\n",
       "      <td>1388217</td>\n",
       "      <td>2134-09-12</td>\n",
       "      <td>2134-09-13</td>\n",
       "      <td>1 days 00:00:00.000000000</td>\n",
       "      <td>2134-09-12</td>\n",
       "      <td>2134-09-13</td>\n",
       "      <td>...</td>\n",
       "      <td>2135-02-08</td>\n",
       "      <td>full</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2134-09-11 09:35:00</td>\n",
       "      <td>negative</td>\n",
       "      <td>C_neg/A_full</td>\n",
       "      <td>109451</td>\n",
       "      <td>0 days</td>\n",
       "      <td>2135-02-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   icustay_id        ssc_charttime  ssc_id            icu_admit    ab_id  \\\n",
       "0      294638  2191-03-16 00:00:00      22  2191-03-16 00:29:31  1213116   \n",
       "1      220597  2149-11-10 09:40:00      45  2149-11-09 13:07:02  2089126   \n",
       "2      232669  2104-08-11 00:00:00      60  2104-08-08 02:08:17   616189   \n",
       "3      273430  2108-08-05 20:42:00      69  2108-08-05 16:26:09  2572274   \n",
       "4      217847  2134-09-11 09:35:00      70  2134-09-11 20:50:04  1388217   \n",
       "\n",
       "     ab_start      ab_end               ab_ssc_delta         t_0       t_end  \\\n",
       "0  2191-03-16  2191-03-22  0 days 00:00:00.000000000  2191-03-16  2191-03-22   \n",
       "1  2149-11-10  2149-11-15  0 days 00:00:00.000000000  2149-11-10  2149-11-15   \n",
       "2  2104-08-11  2104-08-12  0 days 00:00:00.000000000  2104-08-11  2104-08-12   \n",
       "3  2108-08-06  2108-08-08  1 days 00:00:00.000000000  2108-08-06  2108-08-08   \n",
       "4  2134-09-12  2134-09-13  1 days 00:00:00.000000000  2134-09-12  2134-09-13   \n",
       "\n",
       "   ...    dod_ssn ab_course             org_list  spec_type_list  \\\n",
       "0  ...        NaT      full  STAPH AUREUS COAG +   BLOOD CULTURE   \n",
       "1  ... 2149-11-14      full                  NaN             NaN   \n",
       "2  ... 2104-08-20   partial                  NaN             NaN   \n",
       "3  ... 2109-08-18   partial                  NaN             NaN   \n",
       "4  ... 2135-02-08      full                  NaN             NaN   \n",
       "\n",
       "  first_pos_else_neg_ssc sc_result        final_bin hadm_id  delta        dod  \n",
       "0    2191-03-16 00:00:00  positive     C_pos/A_full  185777    NaT        NaT  \n",
       "1    2149-11-10 09:40:00  negative     C_neg/A_full  150750 0 days 2149-11-14  \n",
       "2    2104-08-11 00:00:00  negative  C_neg/A_partial  112213 0 days 2104-08-20  \n",
       "3    2108-08-05 20:42:00  negative  C_neg/A_partial  109235    NaT 2109-08-18  \n",
       "4    2134-09-11 09:35:00  negative     C_neg/A_full  109451 0 days 2135-02-08  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 23 ms\n"
     ]
    }
   ],
   "source": [
    "final_pt_df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 461 µs\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssc_t0ab_t0ssc.loc[\n",
    "#     ((pd.to_datetime(ssc_t0ab_t0ssc['t_end_consec'])+ pd.DateOffset(1)) \n",
    "#      >= pd.to_datetime(ssc_t0ab_t0ssc['dod_hosp'])),\n",
    "#     'ab_course']='full'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 15.2 ms\n"
     ]
    }
   ],
   "source": [
    "#dod col is now the min date of death between hospital and ssn (about 150 discrepencies)\n",
    "final_pt_df2['dod_hosp']=pd.to_datetime(final_pt_df2['dod_hosp'])\n",
    "final_pt_df2['dod_ssn']=pd.to_datetime(final_pt_df2['dod_ssn'])\n",
    "\n",
    "final_pt_df2['dod']=pd.to_datetime(final_pt_df2[['dod_hosp','dod_ssn']].min(axis=1))\n",
    "\n",
    "#making a delta col between dod and t_0\n",
    "final_pt_df2['dod_t0_delta']= (pd.to_datetime(final_pt_df2['dod_hosp'])-\n",
    "                               pd.to_datetime(final_pt_df2['t_0']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595      -1 days\n",
       "2         0 days\n",
       "0         1 days\n",
       "1         2 days\n",
       "3         3 days\n",
       "          ...   \n",
       "760    3304 days\n",
       "865    3313 days\n",
       "1023   3357 days\n",
       "1190   3420 days\n",
       "925    3535 days\n",
       "Name: index, Length: 1299, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.41 ms\n"
     ]
    }
   ],
   "source": [
    "final_pt_df2['dod_t0_delta'].value_counts().reset_index()['index'].sort_values()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dod_hosp    dod_ssn        dod         t_0       t_end\n",
      "13767 2165-02-06 2165-02-06 2165-02-06  2165-02-07  2165-02-08\n",
      "15075 2190-12-10 2190-12-10 2190-12-10  2190-12-11  2190-12-12\n",
      "time: 12.3 ms\n"
     ]
    }
   ],
   "source": [
    "print(final_pt_df2.loc[final_pt_df2['dod_t0_delta']=='-1 days',['dod_hosp','dod_ssn','dod','t_0','t_end']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13767    209071\n",
       "15075    281048\n",
       "Name: icustay_id, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.8 ms\n"
     ]
    }
   ],
   "source": [
    "final_pt_df2.loc[final_pt_df2['dod_t0_delta']=='-1 days','icustay_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### found weird result: two patints have t_0 AFTER dod, need to explore??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subject_id= 57518,66774\n",
    "hadm_id=105024, 199087\n",
    "icustay_id= 209071, 281048\n",
    "\n",
    "        dod_hosp    dod_ssn        dod         t_0\n",
    "13767 2165-02-06 2165-02-06 2165-02-06  2165-02-07\n",
    "15075 2190-12-10 2190-12-10 2190-12-10  2190-12-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['icustay_id',\n",
       " 'ssc_charttime',\n",
       " 'ssc_id',\n",
       " 'icu_admit',\n",
       " 'ab_id',\n",
       " 'ab_start',\n",
       " 'ab_end',\n",
       " 'ab_ssc_delta',\n",
       " 't_0',\n",
       " 't_end',\n",
       " 't_0_sc',\n",
       " 'abduration',\n",
       " 't_end_consec',\n",
       " 'subject_id',\n",
       " 'dod_hosp',\n",
       " 'dod_ssn',\n",
       " 'ab_course',\n",
       " 'org_list',\n",
       " 'spec_type_list',\n",
       " 'first_pos_else_neg_ssc',\n",
       " 'sc_result',\n",
       " 'final_bin',\n",
       " 'hadm_id',\n",
       " 'delta',\n",
       " 'dod',\n",
       " 'dod_t0_delta']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.46 ms\n"
     ]
    }
   ],
   "source": [
    "list(final_pt_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('1970-01-01 00:00:00')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.34 ms\n"
     ]
    }
   ],
   "source": [
    "pd.to_datetime(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.4 ms\n"
     ]
    }
   ],
   "source": [
    "#final_pt_df2['dod_hosp']- \n",
    "final_pt_df2['dod_t0_delta']= pd.to_datetime(final_pt_df2['dod_hosp'])- pd.to_datetime(final_pt_df2['t_0'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          0\n",
       "1        2149-11-14 00:00:00\n",
       "2        2104-08-20 00:00:00\n",
       "3                          0\n",
       "4        2135-02-08 00:00:00\n",
       "                ...         \n",
       "19628                      0\n",
       "19629                      0\n",
       "19630                      0\n",
       "19631                      0\n",
       "19632                      0\n",
       "Name: dod_hosp, Length: 19633, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3.77 ms\n"
     ]
    }
   ],
   "source": [
    "final_pt_df2['dod_hosp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>delta</th>\n",
       "      <th>label</th>\n",
       "      <th>value</th>\n",
       "      <th>t_0</th>\n",
       "      <th>uom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>88189</th>\n",
       "      <td>54610</td>\n",
       "      <td>100003</td>\n",
       "      <td>209281</td>\n",
       "      <td>0 days</td>\n",
       "      <td>daily_sofa</td>\n",
       "      <td>4</td>\n",
       "      <td>2150-04-18</td>\n",
       "      <td>daily_sofa_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52007</th>\n",
       "      <td>23018</td>\n",
       "      <td>100007</td>\n",
       "      <td>217937</td>\n",
       "      <td>0 days</td>\n",
       "      <td>daily_sofa</td>\n",
       "      <td>1</td>\n",
       "      <td>2145-03-31</td>\n",
       "      <td>daily_sofa_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52008</th>\n",
       "      <td>23018</td>\n",
       "      <td>100007</td>\n",
       "      <td>217937</td>\n",
       "      <td>1 days</td>\n",
       "      <td>daily_sofa</td>\n",
       "      <td>4</td>\n",
       "      <td>2145-03-31</td>\n",
       "      <td>daily_sofa_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52009</th>\n",
       "      <td>23018</td>\n",
       "      <td>100007</td>\n",
       "      <td>217937</td>\n",
       "      <td>2 days</td>\n",
       "      <td>daily_sofa</td>\n",
       "      <td>0</td>\n",
       "      <td>2145-03-31</td>\n",
       "      <td>daily_sofa_score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52010</th>\n",
       "      <td>23018</td>\n",
       "      <td>100007</td>\n",
       "      <td>217937</td>\n",
       "      <td>3 days</td>\n",
       "      <td>daily_sofa</td>\n",
       "      <td>3</td>\n",
       "      <td>2145-03-31</td>\n",
       "      <td>daily_sofa_score</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       subject_id  hadm_id  icustay_id  delta       label  value         t_0  \\\n",
       "88189       54610   100003      209281 0 days  daily_sofa      4  2150-04-18   \n",
       "52007       23018   100007      217937 0 days  daily_sofa      1  2145-03-31   \n",
       "52008       23018   100007      217937 1 days  daily_sofa      4  2145-03-31   \n",
       "52009       23018   100007      217937 2 days  daily_sofa      0  2145-03-31   \n",
       "52010       23018   100007      217937 3 days  daily_sofa      3  2145-03-31   \n",
       "\n",
       "                    uom  \n",
       "88189  daily_sofa_score  \n",
       "52007  daily_sofa_score  \n",
       "52008  daily_sofa_score  \n",
       "52009  daily_sofa_score  \n",
       "52010  daily_sofa_score  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 14.8 ms\n"
     ]
    }
   ],
   "source": [
    "dfs[sofa_df].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88189   0 days\n",
       "52007   0 days\n",
       "52008   1 days\n",
       "52009   2 days\n",
       "52010   3 days\n",
       "         ...  \n",
       "58368   0 days\n",
       "58369   1 days\n",
       "44337   0 days\n",
       "44338   1 days\n",
       "62076   0 days\n",
       "Name: delta, Length: 106097, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 26 ms\n"
     ]
    }
   ],
   "source": [
    "dfs[sofa_df]['delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.23 s\n"
     ]
    }
   ],
   "source": [
    "save_df(dfs[sofa_df], 'sofa')\n",
    "del(dfs[sofa_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
